#!/usr/bin/env python3
"""
çº¹ç†è½¬æ¢å™¨
ä¸»è¦åŠŸèƒ½ï¼š
1. å°†ROIå›¾åƒè½¬æ¢ä¸ºçº¹ç†å›¾
2. ä½¿ç”¨å¤šç§çº¹ç†åˆ†ææ–¹æ³•ï¼ˆLBPã€GLCMã€Gaboræ»¤æ³¢å™¨ç­‰ï¼‰
3. ç”Ÿæˆçº¹ç†ç‰¹å¾å¯è§†åŒ–
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage import feature, filters, measure
from skimage.feature import local_binary_pattern, graycomatrix, graycoprops
from scipy import ndimage
import os
from typing import Dict, Any, Tuple, Optional
import json
import platform

# è®¾ç½®ä¸­æ–‡å­—ä½“
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    import matplotlib.font_manager as fm
    
    system = platform.system()
    
    if system == "Darwin":  # macOS
        # æŸ¥æ‰¾å¯ç”¨çš„ä¸­æ–‡å­—ä½“
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        chinese_fonts = []
        
        # ä¼˜å…ˆé€‰æ‹©çš„ä¸­æ–‡å­—ä½“
        preferred_fonts = ['PingFang SC', 'Hiragino Sans GB', 'STHeiti', 'Arial Unicode MS']
        
        for font in preferred_fonts:
            if font in available_fonts:
                chinese_fonts.append(font)
        
        if chinese_fonts:
            plt.rcParams['font.sans-serif'] = chinese_fonts + ['DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            print(f"è®¾ç½®ä¸­æ–‡å­—ä½“: {chinese_fonts[0]}")
            return True
    
    elif system == "Windows":
        # Windows ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        print("è®¾ç½®Windowsä¸­æ–‡å­—ä½“")
        return True
    
    else:  # Linux
        # Linux ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'Droid Sans Fallback', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        print("è®¾ç½®Linuxä¸­æ–‡å­—ä½“")
        return True
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨è‹±æ–‡æ ‡ç­¾
    print("æ— æ³•è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ ‡ç­¾")
    return False

class TextureConverter:
    """çº¹ç†è½¬æ¢å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–çº¹ç†è½¬æ¢å™¨"""
        self.texture_methods = {
            'lbp': self._compute_lbp_texture,
            'glcm': self._compute_glcm_texture,
            'gabor': self._compute_gabor_texture,
            'gradient': self._compute_gradient_texture,
            'laplacian': self._compute_laplacian_texture,
            'sobel': self._compute_sobel_texture,
            'haralick': self._compute_haralick_texture
        }
    
    def convert_to_texture(self, image_path: str, output_dir: str = "output", 
                          methods: list = None) -> Dict[str, Any]:
        """
        å°†å›¾åƒè½¬æ¢ä¸ºçº¹ç†å›¾
        
        Args:
            image_path: è¾“å…¥å›¾åƒè·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            methods: çº¹ç†åˆ†ææ–¹æ³•åˆ—è¡¨
            
        Returns:
            çº¹ç†è½¬æ¢ç»“æœ
        """
        if methods is None:
            methods = ['lbp', 'glcm', 'gabor', 'gradient', 'laplacian', 'sobel']
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        print(f"å›¾åƒå°ºå¯¸: {gray.shape}")
        print(f"åƒç´ å€¼èŒƒå›´: {gray.min()} - {gray.max()}")
        
        results = {}
        texture_images = {}
        
        # åº”ç”¨å„ç§çº¹ç†åˆ†ææ–¹æ³•
        for method in methods:
            if method in self.texture_methods:
                print(f"æ­£åœ¨è®¡ç®— {method} çº¹ç†...")
                try:
                    texture_img, features = self.texture_methods[method](gray)
                    texture_images[method] = texture_img
                    results[method] = features
                    
                    # ä¿å­˜çº¹ç†å›¾åƒ
                    output_path = os.path.join(output_dir, f"texture_{method}.png")
                    cv2.imwrite(output_path, texture_img)
                    print(f"ä¿å­˜çº¹ç†å›¾åƒ: {output_path}")
                    
                except Exception as e:
                    print(f"è®¡ç®— {method} çº¹ç†æ—¶å‡ºé”™: {e}")
                    continue
        
        # ç”Ÿæˆç»¼åˆçº¹ç†å›¾
        if texture_images:
            combined_texture = self._create_combined_texture(texture_images)
            combined_path = os.path.join(output_dir, "texture_combined.png")
            cv2.imwrite(combined_path, combined_texture)
            print(f"ä¿å­˜ç»¼åˆçº¹ç†å›¾: {combined_path}")
            results['combined'] = {'path': combined_path}
        
        # ç”Ÿæˆçº¹ç†åˆ†ææŠ¥å‘Š
        report_path = os.path.join(output_dir, "texture_analysis_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"ä¿å­˜çº¹ç†åˆ†ææŠ¥å‘Š: {report_path}")
        
        # ç”Ÿæˆå¯è§†åŒ–
        self._create_visualization(gray, texture_images, output_dir)
        
        return {
            'success': True,
            'texture_images': texture_images,
            'results': results,
            'output_dir': output_dir
        }
    
    def _compute_lbp_texture(self, gray: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        è®¡ç®—å±€éƒ¨äºŒå€¼æ¨¡å¼(LBP)çº¹ç†
        
        Args:
            gray: ç°åº¦å›¾åƒ
            
        Returns:
            çº¹ç†å›¾åƒå’Œç‰¹å¾
        """
        # LBPå‚æ•°
        radius = 3
        n_points = 8 * radius
        
        # è®¡ç®—LBP
        lbp = local_binary_pattern(gray, n_points, radius, method='uniform')
        
        # å½’ä¸€åŒ–åˆ°0-255
        lbp_normalized = ((lbp - lbp.min()) / (lbp.max() - lbp.min()) * 255).astype(np.uint8)
        
        # è®¡ç®—LBPç›´æ–¹å›¾ç‰¹å¾
        hist, _ = np.histogram(lbp.ravel(), bins=n_points + 2, range=(0, n_points + 2))
        hist = hist.astype(float)
        hist /= (hist.sum() + 1e-7)
        
        features = {
            'lbp_histogram': hist.tolist(),
            'lbp_mean': float(np.mean(lbp)),
            'lbp_std': float(np.std(lbp)),
            'lbp_entropy': float(-np.sum(hist * np.log2(hist + 1e-7)))
        }
        
        return lbp_normalized, features
    
    def _compute_glcm_texture(self, gray: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        è®¡ç®—ç°åº¦å…±ç”ŸçŸ©é˜µ(GLCM)çº¹ç†
        
        Args:
            gray: ç°åº¦å›¾åƒ
            
        Returns:
            çº¹ç†å›¾åƒå’Œç‰¹å¾
        """
        # é‡åŒ–å›¾åƒåˆ°è¾ƒå°‘ç°åº¦çº§
        gray_quantized = (gray // 32) * 32
        
        # è®¡ç®—GLCM
        distances = [1, 2]
        angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]
        
        glcm = graycomatrix(gray_quantized, distances=distances, angles=angles, 
                           levels=8, symmetric=True, normed=True)
        
        # è®¡ç®—GLCMå±æ€§
        contrast = graycoprops(glcm, 'contrast').mean()
        dissimilarity = graycoprops(glcm, 'dissimilarity').mean()
        homogeneity = graycoprops(glcm, 'homogeneity').mean()
        energy = graycoprops(glcm, 'energy').mean()
        correlation = graycoprops(glcm, 'correlation').mean()
        
        # åˆ›å»ºçº¹ç†å›¾åƒï¼ˆä½¿ç”¨å¯¹æ¯”åº¦ï¼‰
        texture_img = np.zeros_like(gray)
        for i in range(gray.shape[0]):
            for j in range(gray.shape[1]):
                # è®¡ç®—å±€éƒ¨å¯¹æ¯”åº¦
                local_region = gray[max(0, i-2):min(gray.shape[0], i+3),
                                  max(0, j-2):min(gray.shape[1], j+3)]
                if local_region.size > 0:
                    texture_img[i, j] = np.std(local_region)
        
        # å½’ä¸€åŒ–
        texture_img = ((texture_img - texture_img.min()) / 
                      (texture_img.max() - texture_img.min()) * 255).astype(np.uint8)
        
        features = {
            'glcm_contrast': float(contrast),
            'glcm_dissimilarity': float(dissimilarity),
            'glcm_homogeneity': float(homogeneity),
            'glcm_energy': float(energy),
            'glcm_correlation': float(correlation)
        }
        
        return texture_img, features
    
    def _compute_gabor_texture(self, gray: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        è®¡ç®—Gaboræ»¤æ³¢å™¨çº¹ç†
        
        Args:
            gray: ç°åº¦å›¾åƒ
            
        Returns:
            çº¹ç†å›¾åƒå’Œç‰¹å¾
        """
        # Gaboræ»¤æ³¢å™¨å‚æ•°
        frequencies = [0.1, 0.2, 0.3]
        orientations = [0, np.pi/4, np.pi/2, 3*np.pi/4]
        
        gabor_responses = []
        
        for freq in frequencies:
            for theta in orientations:
                # åˆ›å»ºGaboræ»¤æ³¢å™¨
                kernel = cv2.getGaborKernel((21, 21), 5, theta, 2*np.pi*freq, 0.5, 0, ktype=cv2.CV_32F)
                
                # åº”ç”¨æ»¤æ³¢å™¨
                filtered = cv2.filter2D(gray.astype(np.float32), -1, kernel)
                gabor_responses.append(np.abs(filtered))
        
        # ç»„åˆæ‰€æœ‰å“åº”
        combined_response = np.mean(gabor_responses, axis=0)
        
        # å½’ä¸€åŒ–
        texture_img = ((combined_response - combined_response.min()) / 
                      (combined_response.max() - combined_response.min()) * 255).astype(np.uint8)
        
        features = {
            'gabor_mean': float(np.mean(combined_response)),
            'gabor_std': float(np.std(combined_response)),
            'gabor_energy': float(np.sum(combined_response**2))
        }
        
        return texture_img, features
    
    def _compute_gradient_texture(self, gray: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        è®¡ç®—æ¢¯åº¦çº¹ç†
        
        Args:
            gray: ç°åº¦å›¾åƒ
            
        Returns:
            çº¹ç†å›¾åƒå’Œç‰¹å¾
        """
        # è®¡ç®—æ¢¯åº¦
        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        
        # è®¡ç®—æ¢¯åº¦å¹…åº¦
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        # å½’ä¸€åŒ–
        texture_img = ((gradient_magnitude - gradient_magnitude.min()) / 
                      (gradient_magnitude.max() - gradient_magnitude.min()) * 255).astype(np.uint8)
        
        features = {
            'gradient_mean': float(np.mean(gradient_magnitude)),
            'gradient_std': float(np.std(gradient_magnitude)),
            'gradient_max': float(np.max(gradient_magnitude))
        }
        
        return texture_img, features
    
    def _compute_laplacian_texture(self, gray: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        è®¡ç®—æ‹‰æ™®æ‹‰æ–¯çº¹ç†
        
        Args:
            gray: ç°åº¦å›¾åƒ
            
        Returns:
            çº¹ç†å›¾åƒå’Œç‰¹å¾
        """
        # è®¡ç®—æ‹‰æ™®æ‹‰æ–¯
        laplacian = cv2.Laplacian(gray, cv2.CV_64F, ksize=3)
        laplacian = np.abs(laplacian)
        
        # å½’ä¸€åŒ–
        texture_img = ((laplacian - laplacian.min()) / 
                      (laplacian.max() - laplacian.min()) * 255).astype(np.uint8)
        
        features = {
            'laplacian_mean': float(np.mean(laplacian)),
            'laplacian_std': float(np.std(laplacian)),
            'laplacian_max': float(np.max(laplacian))
        }
        
        return texture_img, features
    
    def _compute_sobel_texture(self, gray: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        è®¡ç®—Sobelçº¹ç†
        
        Args:
            gray: ç°åº¦å›¾åƒ
            
        Returns:
            çº¹ç†å›¾åƒå’Œç‰¹å¾
        """
        # è®¡ç®—Sobel
        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        
        # è®¡ç®—Sobelå¹…åº¦
        sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        
        # å½’ä¸€åŒ–
        texture_img = ((sobel_magnitude - sobel_magnitude.min()) / 
                      (sobel_magnitude.max() - sobel_magnitude.min()) * 255).astype(np.uint8)
        
        features = {
            'sobel_mean': float(np.mean(sobel_magnitude)),
            'sobel_std': float(np.std(sobel_magnitude)),
            'sobel_max': float(np.max(sobel_magnitude))
        }
        
        return texture_img, features
    
    def _compute_haralick_texture(self, gray: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        è®¡ç®—Haralickçº¹ç†ç‰¹å¾
        
        Args:
            gray: ç°åº¦å›¾åƒ
            
        Returns:
            çº¹ç†å›¾åƒå’Œç‰¹å¾
        """
        # é‡åŒ–å›¾åƒ
        gray_quantized = (gray // 32) * 32
        
        # è®¡ç®—GLCM
        glcm = graycomatrix(gray_quantized, distances=[1], angles=[0], 
                           levels=8, symmetric=True, normed=True)
        
        # è®¡ç®—Haralickç‰¹å¾
        contrast = graycoprops(glcm, 'contrast')[0, 0]
        dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]
        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]
        energy = graycoprops(glcm, 'energy')[0, 0]
        correlation = graycoprops(glcm, 'correlation')[0, 0]
        
        # åˆ›å»ºçº¹ç†å›¾åƒï¼ˆä½¿ç”¨å±€éƒ¨æ–¹å·®ï¼‰
        texture_img = np.zeros_like(gray)
        for i in range(gray.shape[0]):
            for j in range(gray.shape[1]):
                local_region = gray[max(0, i-2):min(gray.shape[0], i+3),
                                  max(0, j-2):min(gray.shape[1], j+3)]
                if local_region.size > 0:
                    texture_img[i, j] = np.var(local_region)
        
        # å½’ä¸€åŒ–
        texture_img = ((texture_img - texture_img.min()) / 
                      (texture_img.max() - texture_img.min()) * 255).astype(np.uint8)
        
        features = {
            'haralick_contrast': float(contrast),
            'haralick_dissimilarity': float(dissimilarity),
            'haralick_homogeneity': float(homogeneity),
            'haralick_energy': float(energy),
            'haralick_correlation': float(correlation)
        }
        
        return texture_img, features
    
    def _create_combined_texture(self, texture_images: Dict[str, np.ndarray]) -> np.ndarray:
        """
        åˆ›å»ºç»¼åˆçº¹ç†å›¾
        
        Args:
            texture_images: å„ç§çº¹ç†å›¾åƒå­—å…¸
            
        Returns:
            ç»¼åˆçº¹ç†å›¾åƒ
        """
        if not texture_images:
            return np.zeros((100, 100), dtype=np.uint8)
        
        # å°†æ‰€æœ‰çº¹ç†å›¾åƒå¹³å‡
        combined = np.zeros_like(list(texture_images.values())[0], dtype=np.float32)
        
        for texture_img in texture_images.values():
            combined += texture_img.astype(np.float32)
        
        combined /= len(texture_images)
        
        return combined.astype(np.uint8)
    
    def _create_visualization(self, original: np.ndarray, texture_images: Dict[str, np.ndarray], 
                            output_dir: str):
        """
        åˆ›å»ºçº¹ç†åˆ†æå¯è§†åŒ–
        
        Args:
            original: åŸå§‹å›¾åƒ
            texture_images: çº¹ç†å›¾åƒå­—å…¸
            output_dir: è¾“å‡ºç›®å½•
        """
        # è®¾ç½®ä¸­æ–‡å­—ä½“å¹¶é€‰æ‹©æ ‡ç­¾è¯­è¨€
        font_success = setup_chinese_font()
        
        if font_success:
            method_names = {
                'lbp': 'LBPçº¹ç†',
                'glcm': 'GLCMçº¹ç†',
                'gabor': 'Gaborçº¹ç†',
                'gradient': 'æ¢¯åº¦çº¹ç†',
                'laplacian': 'æ‹‰æ™®æ‹‰æ–¯çº¹ç†',
                'sobel': 'Sobelçº¹ç†',
                'haralick': 'Haralickçº¹ç†'
            }
            original_title = 'åŸå§‹å›¾åƒ'
        else:
            method_names = {
                'lbp': 'LBP Texture',
                'glcm': 'GLCM Texture',
                'gabor': 'Gabor Texture',
                'gradient': 'Gradient Texture',
                'laplacian': 'Laplacian Texture',
                'sobel': 'Sobel Texture',
                'haralick': 'Haralick Texture'
            }
            original_title = 'Original Image'
        
        n_methods = len(texture_images)
        if n_methods == 0:
            return
        
        # è®¡ç®—å­å›¾å¸ƒå±€
        cols = min(4, n_methods + 1)  # +1 for original image
        rows = (n_methods + 1 + cols - 1) // cols
        
        fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3))
        if rows == 1:
            axes = axes.reshape(1, -1)
        
        # æ˜¾ç¤ºåŸå§‹å›¾åƒ
        axes[0, 0].imshow(original, cmap='gray')
        axes[0, 0].set_title(original_title, fontsize=12)
        axes[0, 0].axis('off')
        
        idx = 1
        for method, texture_img in texture_images.items():
            row = idx // cols
            col = idx % cols
            
            if row < rows and col < cols:
                axes[row, col].imshow(texture_img, cmap='hot')
                title = method_names.get(method, method.upper())
                axes[row, col].set_title(title, fontsize=12)
                axes[row, col].axis('off')
            
            idx += 1
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(idx, rows * cols):
            row = i // cols
            col = i % cols
            if row < rows and col < cols:
                axes[row, col].axis('off')
        
        plt.tight_layout()
        
        # ä¿å­˜å¯è§†åŒ–å›¾åƒ
        vis_path = os.path.join(output_dir, "texture_visualization.png")
        plt.savefig(vis_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ä¿å­˜çº¹ç†å¯è§†åŒ–: {vis_path}")


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–çº¹ç†è½¬æ¢å™¨
    converter = TextureConverter()
    
    # è¾“å…¥å›¾åƒè·¯å¾„
    input_image = "data/extracted_roi_image.png"
    
    # æ£€æŸ¥è¾“å…¥å›¾åƒæ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_image):
        print(f"é”™è¯¯ï¼šè¾“å…¥å›¾åƒä¸å­˜åœ¨: {input_image}")
        return
    
    print("=== çº¹ç†è½¬æ¢å™¨ ===")
    print(f"è¾“å…¥å›¾åƒ: {input_image}")
    
    try:
        # æ‰§è¡Œçº¹ç†è½¬æ¢
        result = converter.convert_to_texture(
            image_path=input_image,
            output_dir="output/texture_analysis",
            methods=['lbp', 'glcm', 'gabor', 'gradient', 'laplacian', 'sobel']
        )
        
        if result['success']:
            print("\nâœ… çº¹ç†è½¬æ¢å®Œæˆï¼")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {result['output_dir']}")
            print(f"ğŸ–¼ï¸ ç”Ÿæˆçš„çº¹ç†å›¾åƒæ•°é‡: {len(result['texture_images'])}")
            
            # æ˜¾ç¤ºä¸»è¦ç‰¹å¾
            print("\n=== ä¸»è¦çº¹ç†ç‰¹å¾ ===")
            for method, features in result['results'].items():
                if isinstance(features, dict):
                    print(f"\n{method.upper()} ç‰¹å¾:")
                    for key, value in features.items():
                        if isinstance(value, (int, float)):
                            print(f"  {key}: {value:.4f}")
        else:
            print("âŒ çº¹ç†è½¬æ¢å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ çº¹ç†è½¬æ¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
