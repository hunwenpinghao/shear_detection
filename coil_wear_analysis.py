"""
é€šç”¨çš„å‰ªåˆ€ç£¨æŸæŒ‰å·åˆ†æè„šæœ¬
è‡ªåŠ¨æ£€æµ‹é’¢å·è¾¹ç•Œï¼Œæ”¯æŒä»»æ„è§†é¢‘æ•°æ®çš„ç‰¹å¾æå–å’ŒæŒ‰å·åˆ†æ

ç”¨æ³•:
    python coil_wear_analysis.py --roi_dir <ROIå›¾åƒç›®å½•> --output_dir <è¾“å‡ºç›®å½•> [é€‰é¡¹]

ç¤ºä¾‹:
    python coil_wear_analysis.py --roi_dir data/roi_imgs --output_dir data/analysis --name "ç¬¬ä¸€å‘¨æœŸ"
    
ç‰¹ç‚¹:
    - åŸºäºç»Ÿè®¡å˜åŒ–ç‚¹æ£€æµ‹ï¼Œè‡ªåŠ¨è¯†åˆ«é’¢å·åˆ‡æ¢è¾¹ç•Œ
    - æ— éœ€æ‰‹åŠ¨æŒ‡å®šé’¢å·æ•°é‡
    - å¤šç‰¹å¾èåˆæé«˜æ£€æµ‹å‡†ç¡®æ€§
"""
import os
import sys
import argparse
import glob
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
from scipy.signal import find_peaks, savgol_filter
from scipy.ndimage import uniform_filter1d, maximum_filter1d, minimum_filter1d
from scipy.interpolate import UnivariateSpline
from datetime import datetime
from tqdm import tqdm
from math import pi
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import ruptures as rp  # ç”¨äºå˜åŒ–ç‚¹æ£€æµ‹

# æ·»åŠ ä¸»é¡¹ç›®çš„æ¨¡å—åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'wear_degree_analysis', 'src'))

from preprocessor import ImagePreprocessor
from geometry_features import GeometryFeatureExtractor
from visualizer import WearVisualizer
from composite_indicator import CompositeWearIndicator
from utils import ensure_dir
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“ - å¤šä¸ªå¤‡é€‰æ–¹æ¡ˆç¡®ä¿å…¼å®¹æ€§
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Songti SC', 'STSong', 'SimHei', 'DejaVu Sans', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False
matplotlib.rcParams['font.size'] = 11
# å¼ºåˆ¶ä½¿ç”¨TrueTypeå­—ä½“ï¼Œé¿å…å­—ç¬¦ä¸¢å¤±
matplotlib.rcParams['pdf.fonttype'] = 42
matplotlib.rcParams['ps.fonttype'] = 42


class UniversalWearAnalyzer:
    """é€šç”¨çš„ç£¨æŸåˆ†æå™¨"""
    
    def __init__(self, roi_dir: str, output_dir: str, analysis_name: str = "è§†é¢‘åˆ†æ", 
                 min_coils: int = 5, max_coils: int = 15,
                 diagnosis_interval: int = 100, marker_interval: int = 100,
                 n_coils: int = None, detection_method: str = "valley"):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            roi_dir: ROIå›¾åƒç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            analysis_name: åˆ†æåç§°
            min_coils: æœ€å°é’¢å·æ•°ï¼ˆè‡ªåŠ¨æ£€æµ‹æ—¶ä½¿ç”¨ï¼‰
            max_coils: æœ€å¤§é’¢å·æ•°ï¼ˆè‡ªåŠ¨æ£€æµ‹æ—¶ä½¿ç”¨ï¼‰
            diagnosis_interval: å¸§è¯Šæ–­å›¾é‡‡æ ·é—´éš”ï¼ˆé»˜è®¤100ï¼‰
            marker_interval: ç™½æ–‘æ ‡æ³¨å›¾é‡‡æ ·é—´éš”ï¼ˆé»˜è®¤100ï¼‰
            n_coils: ç›´æ¥æŒ‡å®šé’¢å·æ•°ï¼ˆå¦‚æœæŒ‡å®šï¼Œåˆ™è·³è¿‡è‡ªåŠ¨æ£€æµ‹ï¼Œé€Ÿåº¦å¿«10å€ï¼‰
            detection_method: æ£€æµ‹æ–¹æ³• ("valley"=æ³¢è°·æ£€æµ‹æ³•[æ¨è], "pelt"=Peltç®—æ³•)
        """
        self.roi_dir = os.path.abspath(roi_dir)
        self.output_dir = os.path.abspath(output_dir)
        self.analysis_name = analysis_name
        self.min_coils = min_coils
        self.max_coils = max_coils
        self.diagnosis_interval = diagnosis_interval
        self.marker_interval = marker_interval
        self.n_coils = n_coils  # ç›´æ¥æŒ‡å®šé’¢å·æ•°ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
        self.detection_method = detection_method  # æ£€æµ‹æ–¹æ³•é€‰æ‹©
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        ensure_dir(output_dir)
        
        # ç»Ÿè®¡å¸§æ•°
        import glob
        self.image_files = sorted(glob.glob(os.path.join(roi_dir, 'frame_*_roi.png')))
        self.total_frames = len(self.image_files)
        
        print(f"\n{'='*80}")
        print(f"{analysis_name} - åˆ†æåˆå§‹åŒ–")
        print(f"{'='*80}")
        print(f"ROIç›®å½•: {roi_dir}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print(f"æ£€æµ‹åˆ°å¸§æ•°: {self.total_frames}")
        
        # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        self.preprocessor = ImagePreprocessor()
        self.feature_extractor = GeometryFeatureExtractor()
        self.visualizer = WearVisualizer(output_dir)
        self.composite_indicator = CompositeWearIndicator()
    
    @staticmethod
    def compute_envelope(signal: np.ndarray, window: int = 15):
        """
        è®¡ç®—ä¿¡å·çš„ä¸Šä¸‹åŒ…ç»œçº¿
        
        Args:
            signal: è¾“å…¥ä¿¡å·
            window: æ»‘åŠ¨çª—å£å¤§å°
            
        Returns:
            upper_envelope: ä¸ŠåŒ…ç»œçº¿
            lower_envelope: ä¸‹åŒ…ç»œçº¿
        """
        if len(signal) < window:
            return signal.copy(), signal.copy()
        
        upper_envelope = maximum_filter1d(signal, size=window, mode='nearest')
        lower_envelope = minimum_filter1d(signal, size=window, mode='nearest')
        
        return upper_envelope, lower_envelope
    
    @staticmethod
    def robust_curve_fit(signal: np.ndarray, percentile_range=(5, 95), smoothing=None, 
                        use_local_filter=True, local_window=None):
        """
        é²æ£’æ›²çº¿æ‹Ÿåˆï¼šå»é™¤ç¦»ç¾¤ç‚¹åç”¨æ ·æ¡æ›²çº¿æ‹Ÿåˆ
        
        ä¼˜åŒ–ç­–ç•¥ï¼ˆ2025-10-14æ›´æ–°ï¼‰ï¼š
        - è‡ªé€‚åº”å¹³æ»‘å‚æ•°ï¼ˆæ ¹æ®æ•°æ®å˜å¼‚ç³»æ•°è°ƒæ•´ï¼‰
        - å¯¹ç¨€ç–å³°å€¼æ•°æ®ä½¿ç”¨æ›´å°çš„å¹³æ»‘å‚æ•°
        - **æ»‘åŠ¨çª—å£å±€éƒ¨ç¦»ç¾¤ç‚¹æ£€æµ‹**ï¼ˆé¿å…å°†å±€éƒ¨å‡¹é™·åŒºåŸŸçš„æ‰€æœ‰ç‚¹æ ‡è®°ä¸ºç¦»ç¾¤ç‚¹ï¼‰
        
        Args:
            signal: è¾“å…¥ä¿¡å·
            percentile_range: ä¿ç•™æ•°æ®çš„ç™¾åˆ†ä½èŒƒå›´ï¼ˆç”¨äºå…¨å±€ç²—ç­›é€‰ï¼‰
            smoothing: æ ·æ¡å¹³æ»‘å‚æ•°ï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨ï¼‰
            use_local_filter: æ˜¯å¦ä½¿ç”¨å±€éƒ¨æ»‘åŠ¨çª—å£è¿‡æ»¤ï¼ˆæ¨èTrueï¼‰
            local_window: å±€éƒ¨çª—å£å¤§å°ï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨ï¼Œå»ºè®®ä¸ºæ•°æ®é•¿åº¦çš„5%-10%ï¼‰
            
        Returns:
            fitted_curve: æ‹Ÿåˆæ›²çº¿
            inlier_mask: å†…ç‚¹æ©ç ï¼ˆTrueè¡¨ç¤ºéç¦»ç¾¤ç‚¹ï¼‰
        """
        if len(signal) < 10:
            return signal.copy(), np.ones(len(signal), dtype=bool)
        
        # === ç¬¬1é˜¶æ®µï¼šå…¨å±€ç²—ç­›é€‰ï¼ˆå»é™¤æç«¯ç¦»ç¾¤ç‚¹ï¼‰ ===
        lower_bound = np.percentile(signal, percentile_range[0])
        upper_bound = np.percentile(signal, percentile_range[1])
        global_inlier_mask = (signal >= lower_bound) & (signal <= upper_bound)
        
        # === ç¬¬2é˜¶æ®µï¼šå±€éƒ¨æ»‘åŠ¨çª—å£ç²¾ç»†è¿‡æ»¤ ===
        if use_local_filter:
            # è‡ªåŠ¨ç¡®å®šçª—å£å¤§å°ï¼ˆå»ºè®®ä¸ºæ•°æ®é•¿åº¦çš„5%-10%ï¼‰
            if local_window is None:
                local_window = max(min(len(signal) // 15, 101), 21)  # 21åˆ°101ä¹‹é—´
                if local_window % 2 == 0:
                    local_window += 1  # ç¡®ä¿æ˜¯å¥‡æ•°
            
            # åˆå§‹åŒ–å±€éƒ¨å†…ç‚¹æ©ç 
            local_inlier_mask = np.ones(len(signal), dtype=bool)
            
            # æ»‘åŠ¨çª—å£æ£€æµ‹
            half_window = local_window // 2
            for i in range(len(signal)):
                # å®šä¹‰çª—å£èŒƒå›´
                start = max(0, i - half_window)
                end = min(len(signal), i + half_window + 1)
                
                # è·å–çª—å£å†…çš„æ•°æ®ï¼ˆåªè€ƒè™‘å…¨å±€å†…ç‚¹ï¼‰
                window_indices = np.arange(start, end)
                window_mask = global_inlier_mask[start:end]
                window_data = signal[start:end][window_mask]
                
                if len(window_data) < 3:
                    continue
                
                # è®¡ç®—çª—å£å†…çš„å±€éƒ¨ç»Ÿè®¡é‡
                local_mean = np.mean(window_data)
                local_std = np.std(window_data)
                
                # å±€éƒ¨ç¦»ç¾¤ç‚¹åˆ¤æ–­ï¼šå½“å‰ç‚¹æ˜¯å¦åç¦»å±€éƒ¨å‡å€¼è¶…è¿‡3å€æ ‡å‡†å·®
                if local_std > 0:
                    z_score = abs(signal[i] - local_mean) / local_std
                    if z_score > 3.0:  # 3-sigmaè§„åˆ™
                        local_inlier_mask[i] = False
            
            # ç»¼åˆå…¨å±€å’Œå±€éƒ¨æ©ç 
            inlier_mask = global_inlier_mask & local_inlier_mask
        else:
            # ä¸ä½¿ç”¨å±€éƒ¨è¿‡æ»¤ï¼Œç›´æ¥ä½¿ç”¨å…¨å±€æ©ç 
            inlier_mask = global_inlier_mask
        
        # === ç¬¬3é˜¶æ®µï¼šæ ·æ¡æ›²çº¿æ‹Ÿåˆ ===
        x_inliers = np.where(inlier_mask)[0]
        y_inliers = signal[inlier_mask]
        
        if len(x_inliers) < 4:
            fitted_curve = np.full(len(signal), np.mean(signal))
            return fitted_curve, inlier_mask
        
        # è‡ªåŠ¨è®¡ç®—å¹³æ»‘å‚æ•°ï¼ˆè‡ªé€‚åº”ç­–ç•¥ï¼‰
        if smoothing is None:
            # è®¡ç®—æ•°æ®çš„å˜å¼‚ç³»æ•°ï¼ˆCV = std / meanï¼‰
            mean_val = np.abs(np.mean(y_inliers)) + 1e-10
            std_val = np.std(y_inliers)
            cv = std_val / mean_val
            
            # æ ¹æ®å˜å¼‚ç³»æ•°è°ƒæ•´å¹³æ»‘å‚æ•°
            # CVè¶Šå¤§ï¼ˆæ•°æ®æ³¢åŠ¨è¶Šå¤§ï¼‰ï¼Œå¹³æ»‘å‚æ•°è¶Šå°ï¼ˆæ‹Ÿåˆè¶Šçµæ´»ï¼‰
            if cv > 0.5:  # é«˜å˜å¼‚ï¼ˆå¦‚ç¨€ç–å³°å€¼æ•°æ®ï¼‰
                smoothing = len(x_inliers) * 0.05  # æ›´æ•æ„Ÿ
            elif cv > 0.2:  # ä¸­ç­‰å˜å¼‚
                smoothing = len(x_inliers) * 0.15
            else:  # ä½å˜å¼‚ï¼ˆç¨³å®šæ•°æ®ï¼‰
                smoothing = len(x_inliers) * 0.3
        
        try:
            # ä½¿ç”¨ä¸‰æ¬¡æ ·æ¡æ‹Ÿåˆ
            spline = UnivariateSpline(x_inliers, y_inliers, s=smoothing, k=3)
            x_full = np.arange(len(signal))
            fitted_curve = spline(x_full)
        except:
            # å¦‚æœæ ·æ¡å¤±è´¥ï¼Œä½¿ç”¨å¤šé¡¹å¼æ‹Ÿåˆ
            degree = min(3, len(x_inliers) - 1)
            coeffs = np.polyfit(x_inliers, y_inliers, degree)
            poly = np.poly1d(coeffs)
            x_full = np.arange(len(signal))
            fitted_curve = poly(x_full)
        
        return fitted_curve, inlier_mask
    
    def extract_features(self, save_diagnosis: bool = True) -> pd.DataFrame:
        """
        æå–æ‰€æœ‰å¸§çš„ç‰¹å¾
        
        Args:
            save_diagnosis: æ˜¯å¦ä¿å­˜å¸§è¯Šæ–­å›¾ï¼ˆæŒ‰é‡‡æ ·é—´éš”ï¼‰
        """
        print(f"\nå¼€å§‹æå–{self.analysis_name}çš„ç‰¹å¾...")
        print(f"è¯Šæ–­å›¾é‡‡æ ·é—´éš”: æ¯ {self.diagnosis_interval} å¸§")
        
        # æ‰«æå®é™…å­˜åœ¨çš„ROIæ–‡ä»¶
        roi_files = sorted(glob.glob(os.path.join(self.roi_dir, "frame_*_roi.png")))
        print(f"å®é™…æ‰¾åˆ° {len(roi_files)} ä¸ªROIæ–‡ä»¶")
        
        # åˆ›å»ºè¯Šæ–­å›¾ç›®å½•
        if save_diagnosis:
            diagnosis_dir = os.path.join(self.output_dir, 'visualizations', 'frame_diagnosis')
            ensure_dir(diagnosis_dir)
            diagnosis_count = 0
        
        all_features = []
        read_fail_count = 0
        preprocess_fail_count = 0
        extract_fail_count = 0
        
        for idx, filepath in enumerate(tqdm(roi_files, desc=f"æå–ç‰¹å¾")):
            try:
                # ä»æ–‡ä»¶åä¸­æå–å¸§ID
                basename = os.path.basename(filepath)
                frame_id = int(basename.split('_')[1])
                
                # è¯»å–å›¾åƒ
                image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
                if image is None:
                    read_fail_count += 1
                    if read_fail_count <= 3:
                        print(f"\nè­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {filepath}")
                    continue
                
                # é¢„å¤„ç†
                preprocessed = self.preprocessor.process(image)
                
                if not preprocessed['success']:
                    preprocess_fail_count += 1
                    if preprocess_fail_count <= 3:
                        print(f"\nè­¦å‘Š: é¢„å¤„ç†å¤±è´¥ frame {frame_id}: {preprocessed.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    continue
                
                # æå–ç‰¹å¾
                try:
                    features = self.feature_extractor.extract_features(preprocessed)
                    features['frame_id'] = frame_id
                    all_features.append(features)
                except Exception as e:
                    extract_fail_count += 1
                    if extract_fail_count <= 3:
                        print(f"\nè­¦å‘Š: ç‰¹å¾æå–å¤±è´¥ frame {frame_id}: {e}")
                    continue
                
                # ä¿å­˜è¯Šæ–­å›¾ï¼ˆæŒ‰é‡‡æ ·é—´éš”ï¼ŒåŸºäºframe_idè€Œéç´¢å¼•ï¼‰
                if save_diagnosis and frame_id % self.diagnosis_interval == 0:
                    diagnosis_path = os.path.join(diagnosis_dir, f"frame_{frame_id:06d}_diagnosis.png")
                    self.visualizer.visualize_single_frame_diagnosis(
                        image, preprocessed, features, frame_id, diagnosis_path
                    )
                    diagnosis_count += 1
                
            except Exception as e:
                print(f"\nè­¦å‘Š: å¤„ç†æ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}")
                continue
        
        # æ‰“å°è¯Šæ–­ä¿¡æ¯
        print(f"\nç‰¹å¾æå–è¯Šæ–­:")
        print(f"  æ€»æ–‡ä»¶æ•°: {len(roi_files)}")
        print(f"  æˆåŠŸæå–: {len(all_features)}")
        print(f"  è¯»å–å¤±è´¥: {read_fail_count} å¸§")
        print(f"  é¢„å¤„ç†å¤±è´¥: {preprocess_fail_count} å¸§")
        print(f"  ç‰¹å¾æå–å¤±è´¥: {extract_fail_count} å¸§")
        if save_diagnosis:
            print(f"  å·²ä¿å­˜è¯Šæ–­å›¾: {diagnosis_count} å¼ ï¼ˆé‡‡æ ·é—´éš”: {self.diagnosis_interval}ï¼‰")
        
        if len(all_features) == 0:
            raise RuntimeError("æ²¡æœ‰æˆåŠŸæå–ä»»ä½•ç‰¹å¾")
        
        df = pd.DataFrame(all_features)
        print(f"æˆåŠŸæå– {len(df)} / {self.total_frames} å¸§çš„ç‰¹å¾")
        
        # éªŒè¯å’Œä¿®æ­£æ’•è£‚é¢å æ¯”æ•°æ®
        if 'tear_shear_area_ratio' in df.columns:
            original_ratio = df['tear_shear_area_ratio']
            invalid_count = (original_ratio < 0).sum() + (original_ratio > 1).sum()
            
            if invalid_count > 0:
                print(f"âš ï¸  å‘ç° {invalid_count} ä¸ªæ’•è£‚é¢å æ¯”å€¼è¶…å‡º0-1èŒƒå›´ï¼Œæ­£åœ¨ä¿®æ­£...")
                
                # å¦‚æœæœ‰å¾ˆå¤šå€¼>1ï¼Œå¯èƒ½æ˜¯æ¯”å€¼å½¢å¼ï¼Œä½¿ç”¨è½¬æ¢å…¬å¼
                if (original_ratio > 1).sum() > len(original_ratio) * 0.1:
                    print("   ä½¿ç”¨è½¬æ¢å…¬å¼: new_ratio = old_ratio / (old_ratio + 1)")
                    df['tear_shear_area_ratio'] = original_ratio / (original_ratio + 1)
                else:
                    print("   ç›´æ¥æˆªæ–­åˆ°0-1èŒƒå›´")
                    df['tear_shear_area_ratio'] = np.clip(original_ratio, 0.0, 1.0)
                
                # éªŒè¯ä¿®æ­£ç»“æœ
                corrected_ratio = df['tear_shear_area_ratio']
                print(f"âœ… ä¿®æ­£å®Œæˆ: æœ€å°å€¼={corrected_ratio.min():.4f}, æœ€å¤§å€¼={corrected_ratio.max():.4f}")
                print(f"   æ‰€æœ‰å€¼åœ¨0-1èŒƒå›´å†…: {(corrected_ratio >= 0).all() and (corrected_ratio <= 1).all()}")
            else:
                print("âœ… æ’•è£‚é¢å æ¯”æ•°æ®æ­£å¸¸ï¼ˆ0-1èŒƒå›´ï¼‰")
        
        # ä¿å­˜ç‰¹å¾
        features_dir = os.path.join(self.output_dir, 'features')
        ensure_dir(features_dir)
        
        csv_path = os.path.join(features_dir, 'wear_features.csv')
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"å·²ä¿å­˜ç‰¹å¾æ–‡ä»¶: {csv_path}")
        
        return df
    
    def _evaluate_segmentation_quality(self, signal: np.ndarray, boundaries: list) -> float:
        """
        å¿«é€Ÿè¯„ä¼°åˆ†å‰²è´¨é‡çš„ç»¼åˆè¯„åˆ†å‡½æ•°
        
        Args:
            signal: ç”¨äºåˆ†å‰²çš„ä¿¡å·
            boundaries: åˆ†å‰²è¾¹ç•Œç‚¹åˆ—è¡¨
            
        Returns:
            float: ç»¼åˆè¯„åˆ†ï¼Œè¶Šé«˜è¶Šå¥½
        """
        if len(boundaries) < 2:
            return -float('inf')
        
        # å¿«é€Ÿè®¡ç®—æ®µå‡å€¼ï¼ˆé¿å…åˆ›å»ºsegmentsåˆ—è¡¨ï¼‰
        segment_means = []
        segment_lengths = []
        
        for i in range(len(boundaries)):
            start = boundaries[i-1] if i > 0 else 0
            end = boundaries[i] if i < len(boundaries) else len(signal)
            
            if end > start:
                segment_mean = np.mean(signal[start:end])
                segment_means.append(segment_mean)
                segment_lengths.append(end - start)
        
        if len(segment_means) < 2:
            return -float('inf')
        
        # ç®€åŒ–çš„è¯„åˆ†è®¡ç®—ï¼ˆåªä¿ç•™æœ€é‡è¦çš„æŒ‡æ ‡ï¼‰
        # 1. æ®µé—´å·®å¼‚æ€§ï¼ˆæœ€é‡è¦ï¼‰
        between_variance = np.var(segment_means)
        
        # 2. é•¿åº¦å‡åŒ€æ€§ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
        length_std = np.std(segment_lengths)
        length_mean = np.mean(segment_lengths)
        length_uniformity = 1.0 / (1.0 + length_std / length_mean) if length_mean > 0 else 0
        
        # 3. è¾¹ç•Œå¼ºåº¦ï¼ˆç®€åŒ–è®¡ç®—ï¼Œåªæ£€æŸ¥éƒ¨åˆ†è¾¹ç•Œï¼‰
        boundary_strength = 0.0
        check_boundaries = boundaries[1:-1][::2]  # åªæ£€æŸ¥ä¸€åŠçš„è¾¹ç•Œç‚¹
        for boundary in check_boundaries:
            if 1 <= boundary < len(signal) - 1:
                gradient = abs(signal[boundary] - signal[boundary-1])
                boundary_strength += gradient
        boundary_strength /= max(1, len(check_boundaries))
        
        # ç®€åŒ–çš„ç»¼åˆè¯„åˆ†
        score = between_variance * 3.0 + boundary_strength * 1.0 + length_uniformity * 0.5
        
        return score
    
    def _detect_by_valley_method(self, df: pd.DataFrame) -> list:
        """
        æ³¢è°·æ£€æµ‹æ³•ï¼šé€šè¿‡äºŒæ¬¡æ»¤æ³¢ + æ³¢è°·æ£€æµ‹æ¥è¯†åˆ«é’¢å·è¾¹ç•Œ
        
        åŸç†ï¼š
        1. å¯¹ä¿¡å·è¿›è¡ŒäºŒæ¬¡å¹³æ»‘æ»¤æ³¢ï¼Œè¿‡æ»¤å‡æ³¢è°·
        2. æ£€æµ‹æ³¢è°·ï¼ˆå±€éƒ¨æœ€å°å€¼ç‚¹ï¼‰
        3. ç›¸é‚»æ³¢è°·ä¹‹é—´ä¸ºä¸€ä¸ªé’¢å·
        
        ä¼˜åŠ¿ï¼šé€Ÿåº¦å¿«ã€é€»è¾‘æ¸…æ™°ã€ç‰©ç†æ„ä¹‰æ˜ç¡®
        
        Args:
            df: ç‰¹å¾æ•°æ®
            
        Returns:
            é’¢å·è¾¹ç•Œç´¢å¼•åˆ—è¡¨
        """
        print("ğŸŒŠ ä½¿ç”¨æ³¢è°·æ£€æµ‹æ³•è¯†åˆ«é’¢å·è¾¹ç•Œ...")
        
        # è·å–ä¿¡å·
        if 'weighted_score' in df.columns:
            signal = df['weighted_score'].values
            print("ä½¿ç”¨ç»¼åˆç£¨æŸæŒ‡æ•°")
        else:
            key_features = ['avg_gradient_energy', 'max_notch_depth', 'avg_rms_roughness']
            scaler = StandardScaler()
            features_for_detection = []
            
            for feature in key_features:
                if feature in df.columns:
                    features_for_detection.append(df[feature].values)
            
            if len(features_for_detection) == 0:
                print("è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾ç”¨äºæ£€æµ‹")
                return None
            
            combined_signal = np.column_stack(features_for_detection)
            signal = scaler.fit_transform(combined_signal).mean(axis=1)
            print("ä½¿ç”¨å¤šç‰¹å¾ç»„åˆ")
        
        # ç¬¬ä¸€æ¬¡å¹³æ»‘ï¼šå¤§çª—å£æ»¤æ³¢
        window1 = min(201, len(signal)//4*2+1)
        if window1 >= 5:
            signal_smooth1 = savgol_filter(signal, window_length=window1, polyorder=3)
            print(f"ç¬¬ä¸€æ¬¡å¹³æ»‘ï¼šçª—å£å¤§å° {window1}")
        else:
            signal_smooth1 = signal
        
        # ç¬¬äºŒæ¬¡å¹³æ»‘ï¼šè¿›ä¸€æ­¥å¹³æ»‘
        window2 = min(151, len(signal_smooth1)//6*2+1)
        if window2 >= 5:
            signal_smooth2 = savgol_filter(signal_smooth1, window_length=window2, polyorder=3)
            print(f"ç¬¬äºŒæ¬¡å¹³æ»‘ï¼šçª—å£å¤§å° {window2}")
        else:
            signal_smooth2 = signal_smooth1
        
        # æ£€æµ‹æ³¢è°·ï¼ˆå±€éƒ¨æœ€å°å€¼ï¼‰
        # distance: ç›¸é‚»æ³¢è°·çš„æœ€å°è·ç¦»ï¼ˆé¿å…æ£€æµ‹åˆ°å‡æ³¢è°·ï¼‰
        min_distance = max(100, len(signal_smooth2) // (self.max_coils + 5))
        
        # åè½¬ä¿¡å·æ¥æ£€æµ‹æ³¢è°·ï¼ˆfind_peaks æ£€æµ‹æ³¢å³°ï¼‰
        inverted_signal = -signal_smooth2
        
        # prominence: æ³¢å³°æ˜¾è‘—æ€§ï¼ˆè¿‡æ»¤ä¸æ˜æ˜¾çš„æ³¢å³°ï¼‰
        prominence = np.std(signal_smooth2) * 0.3  # æ³¢åŠ¨å¹…åº¦çš„30%
        
        print(f"æ³¢è°·æ£€æµ‹å‚æ•°ï¼šæœ€å°è·ç¦»={min_distance}å¸§, æ˜¾è‘—æ€§é˜ˆå€¼={prominence:.3f}")
        
        valleys, properties = find_peaks(
            inverted_signal, 
            distance=min_distance,
            prominence=prominence,
            width=20  # æ³¢è°·æœ€å°å®½åº¦
        )
        
        print(f"æ£€æµ‹åˆ° {len(valleys)} ä¸ªæ³¢è°·")
        
        if len(valleys) == 0:
            print("âš ï¸ æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„æ³¢è°·ï¼Œä½¿ç”¨é»˜è®¤å‡åŒ€åˆ†å‰²")
            default_coils = (self.min_coils + self.max_coils) // 2
            coil_size = len(df) // default_coils
            boundaries = [i * coil_size for i in range(default_coils)]
            boundaries[0] = 0
            return boundaries
        
        # æ³¢è°·æ•°é‡ = é’¢å·æ•° - 1ï¼ˆä¸¤ä¸ªé’¢å·ä¹‹é—´æœ‰ä¸€ä¸ªæ³¢è°·ï¼‰
        n_coils = len(valleys) + 1
        
        # æ£€æŸ¥æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
        if n_coils < self.min_coils:
            print(f"âš ï¸ æ£€æµ‹åˆ°çš„é’¢å·æ•° ({n_coils}) å°‘äºæœ€å°å€¼ ({self.min_coils})")
            print("æç¤ºï¼šå¯èƒ½éœ€è¦è°ƒæ•´ --min_coils å‚æ•°")
        elif n_coils > self.max_coils:
            print(f"âš ï¸ æ£€æµ‹åˆ°çš„é’¢å·æ•° ({n_coils}) å¤šäºæœ€å¤§å€¼ ({self.max_coils})")
            print("æç¤ºï¼šå¯èƒ½éœ€è¦è°ƒæ•´ --max_coils å‚æ•°æˆ–å¢åŠ å¹³æ»‘å¼ºåº¦")
            # åªä¿ç•™æœ€æ˜¾è‘—çš„æ³¢è°·
            n_valleys_to_keep = self.max_coils - 1
            prominences = properties['prominences']
            top_indices = np.argsort(prominences)[-n_valleys_to_keep:]
            valleys = valleys[sorted(top_indices)]
            n_coils = len(valleys) + 1
            print(f"ä¿ç•™æœ€æ˜¾è‘—çš„ {len(valleys)} ä¸ªæ³¢è°·ï¼Œè°ƒæ•´ä¸º {n_coils} ä¸ªé’¢å·")
        
        # æ„å»ºè¾¹ç•Œåˆ—è¡¨ï¼š[0, æ³¢è°·1, æ³¢è°·2, ..., æ³¢è°·n]
        boundaries = [0] + valleys.tolist()
        
        print(f"âœ“ æ£€æµ‹åˆ° {n_coils} ä¸ªé’¢å·")
        print(f"è¾¹ç•Œä½ç½®ï¼ˆæ³¢è°·ï¼‰: {valleys.tolist()}")
        
        # è¾“å‡ºæ¯ä¸ªé’¢å·çš„é•¿åº¦
        segment_lengths = []
        for i in range(len(boundaries)):
            start = boundaries[i]
            end = boundaries[i+1] if i+1 < len(boundaries) else len(signal)
            length = end - start
            segment_lengths.append(length)
            print(f"  ç¬¬{i+1}å·: {length}å¸§ (å¸§ {start} â†’ {end})")
        
        # éªŒè¯åˆ†å‰²è´¨é‡
        self._validate_segmentation(signal_smooth2, boundaries, n_coils)
        
        return boundaries
    
    def _detect_with_fixed_n_coils(self, df: pd.DataFrame, n_coils: int) -> list:
        """
        å¿«é€Ÿæ¨¡å¼ï¼šç›´æ¥æŒ‡å®šé’¢å·æ•°è¿›è¡Œæ£€æµ‹ï¼ˆé€Ÿåº¦å¿«10å€ï¼‰
        
        Args:
            df: ç‰¹å¾æ•°æ®
            n_coils: é’¢å·æ•°é‡
            
        Returns:
            é’¢å·è¾¹ç•Œç´¢å¼•åˆ—è¡¨
        """
        # ä¼˜å…ˆä½¿ç”¨ç»¼åˆç£¨æŸæŒ‡æ•°
        if 'weighted_score' in df.columns:
            signal = df['weighted_score'].values
        else:
            # ä½¿ç”¨å…³é”®ç‰¹å¾ç»„åˆ
            key_features = ['avg_gradient_energy', 'max_notch_depth', 'avg_rms_roughness']
            scaler = StandardScaler()
            features_for_detection = []
            
            for feature in key_features:
                if feature in df.columns:
                    features_for_detection.append(df[feature].values)
            
            if len(features_for_detection) == 0:
                print("è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾ç”¨äºæ£€æµ‹ï¼Œä½¿ç”¨å‡åŒ€åˆ†å‰²")
                coil_size = len(df) // n_coils
                boundaries = [i * coil_size for i in range(n_coils)]
                boundaries[0] = 0
                return boundaries
            
            combined_signal = np.column_stack(features_for_detection)
            signal = scaler.fit_transform(combined_signal).mean(axis=1)
        
        # å¹³æ»‘ä¿¡å·
        window = min(151, len(signal)//6*2+1)
        if window >= 5:
            signal_smooth = savgol_filter(signal, window_length=window, polyorder=3)
        else:
            signal_smooth = signal
        
        # ä½¿ç”¨Peltç®—æ³•ç›´æ¥æŒ‡å®šæ–­ç‚¹æ•°
        try:
            model = "l2"
            min_segment_size = max(len(df)//(n_coils * 2), 50)
            jump_size = max(20, min(100, len(signal_smooth) // 100))
            
            print(f"æœ€å°æ®µé•¿åº¦: {min_segment_size} å¸§, è·³è·ƒæ­¥é•¿: {jump_size}")
            print("æ‹Ÿåˆæ¨¡å‹ä¸­...")
            
            algo = rp.Pelt(model=model, min_size=int(min_segment_size), jump=jump_size)
            algo.fit(signal_smooth.reshape(-1, 1))
            
            # ç›´æ¥æŒ‡å®šæ–­ç‚¹æ•°ï¼ˆæ¯”æœç´¢penaltyå¿«10å€ï¼‰
            print(f"æ£€æµ‹ {n_coils} ä¸ªé’¢å·çš„è¾¹ç•Œ...")
            boundaries = algo.predict(n_bkps=n_coils-1)
            
            # å»æ‰æœ€åçš„è¾¹ç•Œç‚¹
            boundaries = [0] + boundaries[:-1]
            
            print(f"âœ“ å¿«é€Ÿæ£€æµ‹å®Œæˆï¼Œå…± {len(boundaries)} ä¸ªé’¢å·")
            print(f"è¾¹ç•Œä½ç½®: {boundaries}")
            
            # éªŒè¯åˆ†å‰²è´¨é‡
            self._validate_segmentation(signal_smooth, boundaries, len(boundaries))
            
            return boundaries
            
        except Exception as e:
            print(f"å¿«é€Ÿæ£€æµ‹å¤±è´¥: {e}")
            print("ä½¿ç”¨å‡åŒ€åˆ†å‰²ä½œä¸ºå¤‡é€‰")
            coil_size = len(df) // n_coils
            boundaries = [i * coil_size for i in range(n_coils)]
            boundaries[0] = 0
            return boundaries
    
    def _validate_segmentation(self, signal: np.ndarray, boundaries: list, n_coils: int):
        """
        å¿«é€ŸéªŒè¯åˆ†å‰²è´¨é‡å¹¶è¾“å‡ºå…³é”®ä¿¡æ¯
        
        Args:
            signal: ç”¨äºåˆ†å‰²çš„ä¿¡å·
            boundaries: åˆ†å‰²è¾¹ç•Œç‚¹åˆ—è¡¨
            n_coils: é’¢å·æ•°é‡
        """
        print(f"\n=== åˆ†å‰²è´¨é‡éªŒè¯ ===")
        
        # å¿«é€Ÿè®¡ç®—æ®µé•¿åº¦ç»Ÿè®¡
        segment_lengths = []
        for i in range(len(boundaries)):
            start = boundaries[i-1] if i > 0 else 0
            end = boundaries[i] if i < len(boundaries) else len(signal)
            segment_lengths.append(end - start)
        
        min_len, max_len = min(segment_lengths), max(segment_lengths)
        avg_len = np.mean(segment_lengths)
        std_len = np.std(segment_lengths)
        
        print(f"æ®µé•¿åº¦: æœ€çŸ­{min_len}å¸§, æœ€é•¿{max_len}å¸§, å¹³å‡{avg_len:.1f}å¸§")
        print(f"é•¿åº¦å‡åŒ€æ€§: {std_len/avg_len:.3f} ({'å‡åŒ€' if std_len/avg_len < 0.3 else 'ä¸å‡åŒ€'})")
        
        # ç®€åŒ–çš„è´¨é‡è¯„ä»·ï¼ˆå¤ç”¨å·²è®¡ç®—çš„è¯„åˆ†ï¼‰
        quality_score = self._evaluate_segmentation_quality(signal, boundaries)
        if quality_score > 2.0:
            quality_level = "ä¼˜ç§€"
        elif quality_score > 1.0:
            quality_level = "è‰¯å¥½"
        elif quality_score > 0.5:
            quality_level = "ä¸€èˆ¬"
        else:
            quality_level = "è¾ƒå·®"
        
        print(f"åˆ†å‰²è´¨é‡: {quality_level} (è¯„åˆ†: {quality_score:.3f})")
        print(f"{'='*30}")
    
    def detect_coil_boundaries(self, df: pd.DataFrame) -> list:
        """
        è‡ªåŠ¨æ£€æµ‹é’¢å·è¾¹ç•Œï¼ˆæ”¹è¿›ç‰ˆï¼šä½¿ç”¨ç»¼åˆç£¨æŸæŒ‡æ•°ï¼‰
        
        Args:
            df: ç‰¹å¾æ•°æ®
            
        Returns:
            é’¢å·è¾¹ç•Œç´¢å¼•åˆ—è¡¨
        """
        print(f"\næ£€æµ‹é’¢å·è¾¹ç•Œ...")
        
        # å¿«é€Ÿæ¨¡å¼ï¼šç›´æ¥æŒ‡å®šé’¢å·æ•°
        if self.n_coils is not None:
            print(f"âš¡ å¿«é€Ÿæ¨¡å¼ï¼šä½¿ç”¨æŒ‡å®šçš„é’¢å·æ•° {self.n_coils}")
            return self._detect_with_fixed_n_coils(df, self.n_coils)
        
        # è‡ªåŠ¨æ£€æµ‹æ¨¡å¼
        print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹æ¨¡å¼ï¼šé’¢å·æ•°èŒƒå›´ {self.min_coils}-{self.max_coils}ä¸ª")
        
        # æ–¹æ³•é€‰æ‹©
        if self.detection_method == "valley":
            print("ğŸ“Š ä½¿ç”¨æ³¢è°·æ£€æµ‹æ³•ï¼ˆæ¨èï¼Œå¿«é€Ÿä¸”ç›´è§‚ï¼‰")
            return self._detect_by_valley_method(df)
        elif self.detection_method == "pelt":
            print("ğŸ“Š ä½¿ç”¨Peltå˜åŒ–ç‚¹æ£€æµ‹æ³•")
            return self._detect_by_pelt_method(df)
        else:
            print(f"âš ï¸ æœªçŸ¥çš„æ£€æµ‹æ–¹æ³•: {self.detection_method}ï¼Œä½¿ç”¨é»˜è®¤æ³¢è°·æ£€æµ‹æ³•")
            return self._detect_by_valley_method(df)
    
    def _detect_by_pelt_method(self, df: pd.DataFrame) -> list:
        """
        Peltç®—æ³•æ£€æµ‹æ³•ï¼ˆåŸè‡ªåŠ¨æ£€æµ‹é€»è¾‘ï¼‰
        
        Args:
            df: ç‰¹å¾æ•°æ®
            
        Returns:
            é’¢å·è¾¹ç•Œç´¢å¼•åˆ—è¡¨
        """
        
        # ä¼˜å…ˆä½¿ç”¨ç»¼åˆç£¨æŸæŒ‡æ•°ï¼ˆå¦‚æœå·²ç»è®¡ç®—ï¼‰
        if 'weighted_score' in df.columns:
            print("ä½¿ç”¨ç»¼åˆç£¨æŸæŒ‡æ•°è¿›è¡Œæ£€æµ‹")
            signal = df['weighted_score'].values
        else:
            # å¦åˆ™ä½¿ç”¨å¤šä¸ªå…³é”®ç‰¹å¾çš„ç»„åˆ
            print("ä½¿ç”¨å¤šç‰¹å¾ç»„åˆè¿›è¡Œæ£€æµ‹")
            key_features = ['avg_gradient_energy', 'max_notch_depth', 'avg_rms_roughness']
            
            scaler = StandardScaler()
            features_for_detection = []
            
            for feature in key_features:
                if feature in df.columns:
                    features_for_detection.append(df[feature].values)
            
            if len(features_for_detection) == 0:
                print("è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾ç”¨äºæ£€æµ‹ï¼Œä½¿ç”¨é»˜è®¤åˆ†å‰²")
                return None
            
            combined_signal = np.column_stack(features_for_detection)
            signal = scaler.fit_transform(combined_signal).mean(axis=1)
        
        # å¼ºåŠ›å¹³æ»‘ï¼Œé™ä½å™ªå£°
        window = min(151, len(signal)//6*2+1)  # æ›´å¤§çš„çª—å£
        if window >= 5:
            signal_smooth = savgol_filter(signal, window_length=window, polyorder=3)
        else:
            signal_smooth = signal
        
        # ä½¿ç”¨Peltç®—æ³•æ£€æµ‹å˜åŒ–ç‚¹
        try:
            model = "l2"  # ä½¿ç”¨L2æ¨¡å‹ï¼ˆæ¯”RBFå¿«3-5å€ï¼‰
            # å¤§å¹…å¢å¤§ min_sizeï¼Œé¿å…è¿‡åº¦åˆ†å‰²
            min_segment_size = max(len(df)//(self.max_coils * 2), 50)  # æ›´çµæ´»çš„æœ€å°æ®µé•¿åº¦
            # è‡ªé€‚åº”è°ƒæ•´ jump å‚æ•°ï¼šæ•°æ®é‡å¤§æ—¶ç”¨æ›´å¤§çš„è·³è·ƒæ­¥é•¿
            jump_size = max(20, min(100, len(signal_smooth) // 100))  # æ ¹æ®æ•°æ®é‡è‡ªé€‚åº”
            print(f"æœ€å°æ®µé•¿åº¦: {min_segment_size} å¸§, è·³è·ƒæ­¥é•¿: {jump_size}")
            
            algo = rp.Pelt(model=model, min_size=int(min_segment_size), jump=jump_size)
            print("æ‹Ÿåˆæ¨¡å‹ä¸­...")
            algo.fit(signal_smooth.reshape(-1, 1))
            print("âœ“ æ¨¡å‹æ‹Ÿåˆå®Œæˆ")
            
            # è‡ªé€‚åº”é’¢å·æ•°é‡æ£€æµ‹ - ä¸é¢„è®¾ç›®æ ‡æ•°é‡
            best_boundaries = None
            best_n_coils = 0
            best_score = -float('inf')  # ä½¿ç”¨ç»¼åˆè¯„åˆ†è€Œéè·ç¦»
            all_results = {}  # ç”¨å­—å…¸è®°å½•æ¯ä¸ªnå€¼å¯¹åº”çš„penaltyå’Œè¯„åˆ†
            
            # å¿«é€Ÿè‡ªé€‚åº”penaltyæœç´¢ç­–ç•¥ï¼ˆä¸¤é˜¶æ®µæœç´¢ï¼‰
            print(f"æ­£åœ¨æœç´¢æœ€ä¼˜penaltyå‚æ•°ï¼ˆä¸¤é˜¶æ®µå¿«é€Ÿæ£€æµ‹ï¼‰...")
            
            # ç¬¬ä¸€é˜¶æ®µï¼šç²—æœç´¢ï¼ˆ8ä¸ªç‚¹ï¼‰
            penalties_coarse = np.logspace(-1, 2.5, 8)  # ä»0.1åˆ°316ï¼Œåªç”¨8ä¸ªç‚¹
            
            print(f"é˜¶æ®µ1ï¼šç²—æœç´¢ {len(penalties_coarse)} ä¸ªpenaltyå€¼...")
            good_enough_score = 1.5  # é™ä½é˜ˆå€¼ï¼Œæ›´å®¹æ˜“è§¦å‘æ—©æœŸåœæ­¢
            min_search_points = 5    # è‡³å°‘æœç´¢5ä¸ªç‚¹
            penalties = penalties_coarse  # é»˜è®¤ä½¿ç”¨ç²—æœç´¢ç»“æœ
            
            for i, penalty in enumerate(penalties):
                try:
                    boundaries = algo.predict(pen=penalty)
                    n_segments = len(boundaries)
                    
                    # åªè€ƒè™‘åˆç†èŒƒå›´å†…çš„åˆ†å‰²æ•°
                    if not (self.min_coils <= n_segments <= self.max_coils):
                        continue
                    
                    # è®¡ç®—åˆ†å‰²è´¨é‡è¯„åˆ†
                    segment_score = self._evaluate_segmentation_quality(signal_smooth, boundaries)
                    
                    # è®°å½•æ¯ä¸ªåˆ†å‰²æ•°çš„æœ€ä½³ç»“æœ
                    if n_segments not in all_results or segment_score > all_results[n_segments][2]:
                        all_results[n_segments] = (penalty, boundaries, segment_score)
                    
                    # æ›´æ–°å…¨å±€æœ€ä½³ç»“æœ
                    if segment_score > best_score:
                        best_score = segment_score
                        best_boundaries = boundaries
                        best_n_coils = n_segments
                        print(f"  [{i+1}/{len(penalties)}] {n_segments}ä¸ªé’¢å· (penalty={penalty:.2f}, score={segment_score:.3f}) âœ“")
                        
                        # æ›´ç§¯æçš„æ—©æœŸåœæ­¢ç­–ç•¥
                        if segment_score > good_enough_score and i >= min_search_points:
                            print(f"âœ“ æ‰¾åˆ°è¶³å¤Ÿå¥½çš„ç»“æœï¼Œæå‰ç»“æŸæœç´¢")
                            break
                    else:
                        # ä¸æ˜¯æœ€ä¼˜ä½†ä¹Ÿæ˜¾ç¤ºè¿›åº¦
                        if i % 2 == 0:  # æ¯éš”ä¸€ä¸ªæ˜¾ç¤º
                            print(f"  [{i+1}/{len(penalties)}] {n_segments}ä¸ªé’¢å· (penalty={penalty:.2f}, score={segment_score:.3f})")
                        
                except:
                    continue
            
            # æ‰“å°æœç´¢ç»“æœæ‘˜è¦
            print(f"æœç´¢åˆ°çš„æ‰€æœ‰åˆ†å‰²æ•°: {sorted(all_results.keys())}")
            if all_results:
                print("å„åˆ†å‰²æ•°çš„æœ€ä½³è¯„åˆ†:")
                for n_seg in sorted(all_results.keys()):
                    penalty, _, score = all_results[n_seg]
                    print(f"  {n_seg}ä¸ªé’¢å·: score={score:.3f} (penalty={penalty:.2f})")
            
            if best_boundaries is None:
                print(f"æœªæ‰¾åˆ°æœ€ä¼˜åˆ†å‰²")
                if all_results:
                    # ä»æ‰€æœ‰ç»“æœä¸­é€‰æ‹©è¯„åˆ†æœ€é«˜çš„
                    best_result = max(all_results.values(), key=lambda x: x[2])
                    best_boundaries = best_result[1]
                    best_n_coils = len(best_result[1])
                    print(f"ä½¿ç”¨è¯„åˆ†æœ€é«˜çš„åˆ†å‰²: {best_n_coils}ä¸ªé’¢å· (score={best_result[2]:.3f})")
                else:
                    return None
            
            # å»æ‰æœ€åçš„è¾¹ç•Œç‚¹ï¼ˆæ€»æ˜¯ç­‰äºæ•°æ®é•¿åº¦ï¼‰
            boundaries = [0] + best_boundaries[:-1]
            
            print(f"âœ“ æ£€æµ‹åˆ° {len(boundaries)} ä¸ªé’¢å· (ç»¼åˆè¯„åˆ†: {best_score:.3f})")
            print(f"è¾¹ç•Œä½ç½®: {boundaries}")
            
            # æ·»åŠ åˆ†å‰²è´¨é‡éªŒè¯
            self._validate_segmentation(signal_smooth, boundaries, len(boundaries))
            
            return boundaries
            
        except Exception as e:
            print(f"å˜åŒ–ç‚¹æ£€æµ‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            print("ä½¿ç”¨é»˜è®¤å‡åŒ€åˆ†å‰²")
            return None
    
    def analyze_by_coil(self, df: pd.DataFrame):
        """
        æŒ‰å·åˆ†æï¼ˆè‡ªåŠ¨æ£€æµ‹é’¢å·è¾¹ç•Œï¼‰
        
        Args:
            df: ç‰¹å¾æ•°æ®
        """
        print(f"\n{'='*80}")
        
        # === å…ˆè®¡ç®—ç®€å•çš„ç»¼åˆæŒ‡æ ‡ç”¨äºè¾¹ç•Œæ£€æµ‹ ===
        print("\né¢„è®¡ç®—ç®€å•ç»¼åˆæŒ‡æ ‡ç”¨äºé’¢å·æ£€æµ‹...")
        # ä½¿ç”¨å‡ ä¸ªå…³é”®ç‰¹å¾çš„å½’ä¸€åŒ–å‡å€¼
        key_features = ['avg_rms_roughness', 'max_notch_depth', 'right_peak_density']
        temp_scores = []
        for feat in key_features:
            if feat in df.columns:
                # MinMaxå½’ä¸€åŒ–
                vals = df[feat].values
                if vals.max() > vals.min():
                    normalized = (vals - vals.min()) / (vals.max() - vals.min())
                    temp_scores.append(normalized)
        
        if len(temp_scores) > 0:
            df['weighted_score'] = np.mean(temp_scores, axis=0)
            print("âœ“ ä¸´æ—¶ç»¼åˆæŒ‡æ ‡å·²è®¡ç®—")
        
        # è‡ªåŠ¨æ£€æµ‹é’¢å·è¾¹ç•Œ
        boundaries = self.detect_coil_boundaries(df)
        
        if boundaries is not None:
            # ä½¿ç”¨æ£€æµ‹åˆ°çš„è¾¹ç•Œåˆ†é…å·å·
            df['coil_id'] = 0
            for i, boundary in enumerate(boundaries):
                if i < len(boundaries) - 1:
                    df.loc[boundary:boundaries[i+1]-1, 'coil_id'] = i + 1
                else:
                    df.loc[boundary:, 'coil_id'] = i + 1
            
            n_coils = len(boundaries)
        else:
            # æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‡åŒ€åˆ†å‰²ï¼ˆåŸºäºä¸­ä½æ•°é’¢å·æ•°ï¼‰
            default_coils = (self.min_coils + self.max_coils) // 2
            print(f"âš ï¸ è‡ªåŠ¨æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‡åŒ€åˆ†å‰²ï¼ˆ{default_coils}ä¸ªé’¢å·ï¼‰")
            n_coils = default_coils
            coil_size = len(df) // n_coils
            df['coil_id'] = df.index // coil_size + 1
            df.loc[df['coil_id'] > n_coils, 'coil_id'] = n_coils
        
        print(f"{self.analysis_name} - æŒ‰å·åˆ†æï¼ˆå…±{n_coils}ä¸ªé’¢å·ï¼‰")
        print(f"{'='*80}")
        
        print("\næ¯å·å¸§æ•°åˆ†å¸ƒ:")
        coil_counts = df['coil_id'].value_counts().sort_index()
        for coil_id, count in coil_counts.items():
            print(f"  ç¬¬{int(coil_id)}å·: {count}å¸§")
        
        # === è®¡ç®—å®Œæ•´çš„ç»¼åˆç£¨æŸæŒ‡æ ‡ï¼ˆä¼šè¦†ç›–ä¸´æ—¶çš„ï¼‰ ===
        print("\nè®¡ç®—å®Œæ•´ç»¼åˆç£¨æŸæŒ‡æ ‡...")
        df, analysis_results = self.composite_indicator.compute_all_indicators(df)
        print("âœ“ ç»¼åˆæŒ‡æ ‡è®¡ç®—å®Œæˆ")
        
        # ä¿å­˜å¸¦å·å·å’Œç»¼åˆæŒ‡æ ‡çš„ç‰¹å¾æ–‡ä»¶
        features_dir = os.path.join(self.output_dir, 'features')
        csv_with_coils = os.path.join(features_dir, 'wear_features_with_coils.csv')
        df.to_csv(csv_with_coils, index=False, encoding='utf-8-sig')
        
        # ä¿å­˜ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœ
        importance_df = analysis_results['importance_df']
        importance_csv = os.path.join(features_dir, 'feature_importance.csv')
        importance_df.to_csv(importance_csv, index=False, encoding='utf-8-sig')
        print(f"âœ“ ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜: {importance_csv}")
        
        # ä¿å­˜PCAè½½è·çŸ©é˜µ
        pca_result = analysis_results['pca_result']
        if len(pca_result['loadings']) > 0:
            pca_loadings_csv = os.path.join(features_dir, 'pca_loadings.csv')
            pca_result['loadings'].to_csv(pca_loadings_csv, encoding='utf-8-sig')
            print(f"âœ“ PCAè½½è·å·²ä¿å­˜: {pca_loadings_csv}")
        
        # åˆ›å»ºå¯è§†åŒ–ç›®å½•
        viz_dir = os.path.join(self.output_dir, 'visualizations')
        ensure_dir(viz_dir)
        
        # æ ¸å¿ƒç‰¹å¾
        key_features = {
            'avg_rms_roughness': 'RMSç²—ç³™åº¦',
            'max_notch_depth': 'æœ€å¤§ç¼ºå£æ·±åº¦',
            'right_peak_density': 'å³ä¾§å³°å¯†åº¦ï¼ˆå‰ªåˆ‡é¢ï¼‰',
            'avg_gradient_energy': 'æ¢¯åº¦èƒ½é‡ï¼ˆé”åº¦ï¼‰',
            'tear_shear_area_ratio': 'æ’•è£‚é¢å æ¯”'
        }
        
        # ç”Ÿæˆå¯è§†åŒ–
        self._plot_boxplot(df, key_features, viz_dir)
        self._plot_bars(df, key_features, viz_dir)
        self._plot_heatmap(df, key_features, viz_dir)
        self._plot_radar(df, key_features, viz_dir, n_coils)
        self._plot_progression(df, key_features, viz_dir)
        
        # ç”Ÿæˆé¢å¤–çš„åˆ†æå›¾
        print("\nç”Ÿæˆé¢å¤–åˆ†æå›¾...")
        self._plot_temporal_trends(df, os.path.join(viz_dir, 'temporal_trends.png'))
        self._plot_feature_correlations(df, os.path.join(viz_dir, 'feature_correlations.png'))
        self._plot_wear_progression(df, os.path.join(viz_dir, 'wear_progression.png'))
        self._plot_longterm_trend(df, os.path.join(viz_dir, 'longterm_trend.png'))
        self._plot_individual_longterm_trends(df, viz_dir)
        self._plot_combined_trends_6x1(df, viz_dir)
        self._plot_recommended_indicators(df, os.path.join(viz_dir, 'recommended_indicators.png'))
        
        # ç”Ÿæˆæ°´å¹³æ¢¯åº¦èƒ½é‡å¯¹æ¯”å›¾
        if 'avg_horizontal_gradient' in df.columns:
            self._plot_horizontal_gradient_comparison(df, os.path.join(viz_dir, 'horizontal_gradient_comparison.png'))
        
        # ç”Ÿæˆå¹³æ»‘é•¿æœŸè¶‹åŠ¿åˆ†æ
        self._plot_smooth_longterm_trends(df, os.path.join(viz_dir, 'smooth_longterm_trends.png'))
        
        # ç”Ÿæˆæ·±åº¦è¶‹åŠ¿åˆ†æ
        self._plot_deep_trend_analysis(df, viz_dir)
        
        # ç”Ÿæˆæ’•è£‚é¢ç™½æ–‘åˆ†æ
        self._plot_white_patch_analysis(df, os.path.join(viz_dir, 'white_patch_analysis.png'))
        
        # ç”Ÿæˆç™½æ–‘æ ‡æ³¨å›¾ï¼ˆå¸¦ç›´æ–¹å›¾ï¼‰
        self._generate_white_patch_markers(df, viz_dir, sample_interval=self.marker_interval)
        
        # ç”Ÿæˆç™½æ–‘æ—¶åºæ›²çº¿ï¼ˆ8Ã—4å®Œæ•´ç‰ˆï¼‰
        self._plot_white_patch_temporal_curves(df, os.path.join(viz_dir, 'white_patch_temporal_curves_4x8.png'))
        
        # ç”Ÿæˆç™½æ–‘æ–¹æ³•æ¨èæŠ¥å‘Š
        self._generate_white_patch_recommendation(df, viz_dir)
        
        print("âœ“ é¢å¤–åˆ†æå›¾ç”Ÿæˆå®Œæˆ")
        
        # ç”Ÿæˆç»¼åˆæŒ‡æ ‡ç›¸å…³å¯è§†åŒ–
        print("\nç”Ÿæˆç»¼åˆæŒ‡æ ‡å¯è§†åŒ–...")
        self._plot_feature_importance(importance_df, os.path.join(viz_dir, 'feature_importance.png'))
        self._plot_composite_indicators_comparison(df, os.path.join(viz_dir, 'composite_indicators_comparison.png'))
        self._plot_multi_dimension_evolution(df, n_coils, os.path.join(viz_dir, 'multi_dimension_evolution.png'))
        self._plot_feature_contribution_heatmap(pca_result, os.path.join(viz_dir, 'feature_contribution_heatmap.png'))
        
        # å…³é”®ç‰¹å¾æŠ½æ ·å±•ç¤º
        key_features_dir = os.path.join(viz_dir, 'key_features_samples')
        ensure_dir(key_features_dir)
        self._plot_key_features_samples(df, importance_df, key_features_dir)
        print("âœ“ ç»¼åˆæŒ‡æ ‡å¯è§†åŒ–å®Œæˆ")
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self._generate_report(df, key_features, n_coils, analysis_results)
    
    def _plot_boxplot(self, df, key_features, viz_dir):
        """ç»˜åˆ¶ç®±çº¿å›¾"""
        print("\nç”Ÿæˆå¯è§†åŒ–: ç®±çº¿å›¾...")
        
        fig, axes = plt.subplots(3, 2, figsize=(20, 16))
        axes = axes.flatten()
        
        for idx, (feature, label) in enumerate(list(key_features.items())[:5]):
            ax = axes[idx]
            
            coil_data = []
            coil_labels = []
            
            # è¿‡æ»¤æ‰ NaN å€¼
            valid_coil_ids = df['coil_id'].dropna().unique()
            for coil_id in sorted(valid_coil_ids):
                coil_df = df[df['coil_id'] == coil_id]
                coil_data.append(coil_df[feature].values)
                coil_labels.append(f'å·{int(coil_id)}')
            
            bp = ax.boxplot(coil_data, labels=coil_labels, patch_artist=True,
                           widths=0.6, boxprops=dict(linewidth=1.5),
                           whiskerprops=dict(linewidth=1.5),
                           capprops=dict(linewidth=1.5),
                           medianprops=dict(linewidth=2, color='red'))
            
            colors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.9, len(coil_data)))
            for patch, color in zip(bp['boxes'], colors):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)
            
            means = [np.mean(data) for data in coil_data]
            ax.plot(range(1, len(means)+1), means, 'bo-', linewidth=3,
                   markersize=8, label='å‡å€¼è¶‹åŠ¿', zorder=10)
            
            x = np.arange(len(means))
            z = np.polyfit(x, means, 1)
            trend = np.poly1d(z)
            ax.plot(range(1, len(means)+1), trend(x), 'g--', linewidth=3,
                   label=f'çº¿æ€§è¶‹åŠ¿(æ–œç‡={z[0]:.4f})', alpha=0.8)
            
            change_pct = ((means[-1] - means[0]) / (means[0] + 1e-8)) * 100
            
            if change_pct > 5:
                trend_text = f'âœ“ æ˜¾è‘—é€’å¢ +{change_pct:.1f}%'
                box_color = 'lightgreen'
            elif change_pct > 0:
                trend_text = f'è½»å¾®é€’å¢ +{change_pct:.1f}%'
                box_color = 'lightyellow'
            elif change_pct > -5:
                trend_text = f'åŸºæœ¬å¹³ç¨³ {change_pct:.1f}%'
                box_color = 'lightgray'
            else:
                trend_text = f'é€’å‡ {change_pct:.1f}%'
                box_color = 'lightcoral'
            
            ax.text(0.5, 0.98, trend_text, transform=ax.transAxes,
                   fontsize=14, fontweight='bold', ha='center', va='top',
                   bbox=dict(boxstyle='round,pad=1', facecolor=box_color,
                            alpha=0.8, edgecolor='black', linewidth=2))
            
            ax.set_xlabel('é’¢å·ç¼–å·', fontweight='bold', fontsize=13)
            ax.set_ylabel(label, fontweight='bold', fontsize=13)
            ax.set_title(f'{label}\næŒ‰å·æ¼”å˜è¶‹åŠ¿', fontsize=14, fontweight='bold')
            ax.legend(fontsize=11)
            ax.grid(True, alpha=0.3, axis='y')
        
        axes[-1].axis('off')
        
        plt.suptitle(f'{self.analysis_name} - å‰ªåˆ€ç£¨æŸæŒ‰å·åˆ†æï¼ˆç®±çº¿å›¾ï¼‰',
                    fontsize=20, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'coil_by_coil_boxplot.png'), dpi=300, bbox_inches='tight')
        print(f"å·²ä¿å­˜: {viz_dir}/coil_by_coil_boxplot.png")
    
    def _plot_bars(self, df, key_features, viz_dir):
        """ç»˜åˆ¶æŸ±çŠ¶å›¾"""
        print("\nç”Ÿæˆå¯è§†åŒ–: æŸ±çŠ¶å›¾...")
        
        fig, axes = plt.subplots(3, 2, figsize=(20, 16))
        axes = axes.flatten()
        
        for idx, (feature, label) in enumerate(list(key_features.items())[:5]):
            ax = axes[idx]
            
            coil_ids = []
            coil_means = []
            coil_maxes = []
            
            # è¿‡æ»¤æ‰ NaN å€¼
            valid_coil_ids = df['coil_id'].dropna().unique()
            for coil_id in sorted(valid_coil_ids):
                coil_df = df[df['coil_id'] == coil_id]
                coil_ids.append(int(coil_id))
                coil_means.append(coil_df[feature].mean())
                coil_maxes.append(coil_df[feature].max())
            
            x = np.arange(len(coil_ids))
            width = 0.35
            
            bars1 = ax.bar(x - width/2, coil_means, width, label='å‡å€¼',
                          color='steelblue', edgecolor='navy', linewidth=2, alpha=0.8)
            bars2 = ax.bar(x + width/2, coil_maxes, width, label='æœ€å¤§å€¼',
                          color='coral', edgecolor='darkred', linewidth=2, alpha=0.8)
            
            for bar1, bar2 in zip(bars1, bars2):
                height1 = bar1.get_height()
                height2 = bar2.get_height()
                ax.text(bar1.get_x() + bar1.get_width()/2, height1,
                       f'{height1:.2f}', ha='center', va='bottom', fontsize=9)
                ax.text(bar2.get_x() + bar2.get_width()/2, height2,
                       f'{height2:.2f}', ha='center', va='bottom', fontsize=9)
            
            ax.plot(x, coil_means, 'b--', linewidth=2, alpha=0.6)
            ax.plot(x, coil_maxes, 'r--', linewidth=2, alpha=0.6)
            
            z_mean = np.polyfit(x, coil_means, 1)
            change_pct = ((coil_means[-1] - coil_means[0]) / (coil_means[0] + 1e-8)) * 100
            
            trend_text = f'å‡å€¼å˜åŒ–: {change_pct:+.1f}%\næ–œç‡: {z_mean[0]:.4f}'
            box_color = 'lightgreen' if change_pct > 0 else 'lightcoral'
            
            ax.text(0.02, 0.98, trend_text, transform=ax.transAxes,
                   fontsize=12, fontweight='bold', va='top',
                   bbox=dict(boxstyle='round,pad=0.8', facecolor=box_color, alpha=0.7))
            
            ax.set_xlabel('é’¢å·ç¼–å·', fontweight='bold', fontsize=13)
            ax.set_ylabel(label, fontweight='bold', fontsize=13)
            ax.set_title(f'{label}\nå„å·ç»Ÿè®¡å¯¹æ¯”', fontsize=14, fontweight='bold')
            ax.set_xticks(x)
            ax.set_xticklabels([f'å·{cid}' for cid in coil_ids])
            ax.legend(fontsize=11)
            ax.grid(True, alpha=0.3, axis='y')
        
        axes[-1].axis('off')
        
        plt.suptitle(f'{self.analysis_name} - å‰ªåˆ€ç£¨æŸæŒ‰å·ç»Ÿè®¡åˆ†æ',
                    fontsize=20, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'coil_by_coil_bars.png'), dpi=300, bbox_inches='tight')
        print(f"å·²ä¿å­˜: {viz_dir}/coil_by_coil_bars.png")
    
    def _plot_heatmap(self, df, key_features, viz_dir):
        """ç»˜åˆ¶çƒ­åŠ›å›¾"""
        print("\nç”Ÿæˆå¯è§†åŒ–: çƒ­åŠ›å›¾...")
        
        fig, ax = plt.subplots(figsize=(14, 8))
        
        feature_names = list(key_features.values())
        matrix_data = []
        
        # è¿‡æ»¤æ‰ NaN å€¼
        valid_coil_ids = df['coil_id'].dropna().unique()
        for feature in key_features.keys():
            row = []
            for coil_id in sorted(valid_coil_ids):
                coil_df = df[df['coil_id'] == coil_id]
                row.append(coil_df[feature].mean())
            matrix_data.append(row)
        
        matrix = np.array(matrix_data)
        
        # å½’ä¸€åŒ–
        matrix_norm = np.zeros_like(matrix)
        for i in range(matrix.shape[0]):
            row = matrix[i, :]
            matrix_norm[i, :] = (row - row.min()) / (row.max() - row.min() + 1e-8)
        
        im = ax.imshow(matrix_norm, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
        
        coil_ids = sorted(df['coil_id'].unique())
        ax.set_xticks(np.arange(len(coil_ids)))
        ax.set_yticks(np.arange(len(feature_names)))
        ax.set_xticklabels([f'ç¬¬{int(cid)}å·' for cid in coil_ids], fontsize=12)
        ax.set_yticklabels(feature_names, fontsize=12)
        
        for i in range(len(feature_names)):
            for j in range(len(coil_ids)):
                text = ax.text(j, i, f'{matrix_norm[i, j]:.2f}',
                             ha="center", va="center", color="black",
                             fontsize=10, fontweight='bold')
        
        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        cbar.set_label('å½’ä¸€åŒ–ç‰¹å¾å€¼ (0=æœ€å°, 1=æœ€å¤§)', fontsize=12, fontweight='bold')
        
        ax.set_title(f'{self.analysis_name} - å„å·ç£¨æŸç‰¹å¾çƒ­åŠ›å›¾\nï¼ˆé¢œè‰²è¶Šçº¢=è¯¥ç‰¹å¾åœ¨è¯¥å·çš„å€¼è¶Šå¤§ï¼‰',
                    fontsize=16, fontweight='bold', pad=20)
        ax.set_xlabel('é’¢å·ç¼–å·', fontsize=13, fontweight='bold')
        ax.set_ylabel('ç£¨æŸç‰¹å¾', fontsize=13, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'coil_heatmap.png'), dpi=300, bbox_inches='tight')
        print(f"å·²ä¿å­˜: {viz_dir}/coil_heatmap.png")
    
    def _plot_radar(self, df, key_features, viz_dir, n_coils):
        """ç»˜åˆ¶é›·è¾¾å›¾"""
        print("\nç”Ÿæˆå¯è§†åŒ–: é›·è¾¾å›¾...")
        
        # é€‰æ‹©å¼€å§‹ã€ä¸­æœŸã€ç»“æŸä¸‰ä¸ªå·
        coil_ids = sorted(df['coil_id'].unique())
        if len(coil_ids) >= 3:
            representative_coils = [coil_ids[0], coil_ids[len(coil_ids)//2], coil_ids[-1]]
            coil_labels = [f'ç¬¬{int(representative_coils[0])}å·(å¼€å§‹)',
                          f'ç¬¬{int(representative_coils[1])}å·(ä¸­æœŸ)',
                          f'ç¬¬{int(representative_coils[2])}å·(ç»“æŸ)']
        else:
            representative_coils = coil_ids
            coil_labels = [f'ç¬¬{int(cid)}å·' for cid in coil_ids]
        
        colors = ['blue', 'orange', 'red']
        
        fig, axes = plt.subplots(1, len(representative_coils), figsize=(20, 7),
                                subplot_kw=dict(projection='polar'))
        
        if len(representative_coils) == 1:
            axes = [axes]
        
        for plot_idx, (coil_id, coil_label, color) in enumerate(zip(representative_coils, coil_labels, colors)):
            ax = axes[plot_idx]
            
            coil_df = df[df['coil_id'] == coil_id]
            
            if len(coil_df) == 0:
                ax.text(0.5, 0.5, f'{coil_label}\næ— æ•°æ®',
                       transform=ax.transAxes, ha='center', va='center')
                continue
            
            categories = list(key_features.values())
            values = []
            
            for feature in key_features.keys():
                values.append(coil_df[feature].mean())
            
            # å½’ä¸€åŒ–
            global_max = []
            global_min = []
            for feature in key_features.keys():
                global_max.append(df[feature].max())
                global_min.append(df[feature].min())
            
            values_norm = [(v - vmin) / (vmax - vmin + 1e-8)
                          for v, vmin, vmax in zip(values, global_min, global_max)]
            
            values_norm += values_norm[:1]
            
            angles = [n / float(len(categories)) * 2 * pi for n in range(len(categories))]
            angles += angles[:1]
            
            ax.plot(angles, values_norm, 'o-', linewidth=3, color=color,
                   label=coil_label, markersize=8)
            ax.fill(angles, values_norm, alpha=0.25, color=color)
            
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(categories, fontsize=10)
            ax.set_ylim(0, 1)
            ax.set_yticks([0.25, 0.5, 0.75, 1.0])
            ax.set_yticklabels(['0.25', '0.5', '0.75', '1.0'], fontsize=9)
            ax.grid(True, alpha=0.3)
            
            ax.set_title(coil_label, fontsize=15, fontweight='bold', pad=20)
        
        plt.suptitle(f'{self.analysis_name} - é›·è¾¾å›¾å¯¹æ¯”ï¼šå¼€å§‹ã€ä¸­æœŸã€ç»“æŸå·çš„ç£¨æŸç‰¹å¾',
                    fontsize=18, fontweight='bold', y=1.02)
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'coil_radar_comparison.png'), dpi=300, bbox_inches='tight')
        print(f"å·²ä¿å­˜: {viz_dir}/coil_radar_comparison.png")
    
    def _plot_progression(self, df, key_features, viz_dir):
        """ç»˜åˆ¶é€å·é€’è¿›è¶‹åŠ¿å›¾"""
        print("\nç”Ÿæˆå¯è§†åŒ–: é€å·é€’è¿›è¶‹åŠ¿å›¾...")
        
        fig = plt.figure(figsize=(18, 12))
        gs = fig.add_gridspec(3, 1, hspace=0.3)
        
        focus_features = {
            'right_peak_density': 'å³ä¾§å³°å¯†åº¦ï¼ˆå‰ªåˆ‡é¢å¾®ç¼ºå£ï¼‰',
            'avg_gradient_energy': 'æ¢¯åº¦èƒ½é‡ï¼ˆåˆ€å£é”åº¦ï¼‰',
            'max_notch_depth': 'æœ€å¤§ç¼ºå£æ·±åº¦'
        }
        
        for idx, (feature, label) in enumerate(focus_features.items()):
            ax = fig.add_subplot(gs[idx])
            
            coil_ids = []
            coil_means = []
            coil_maxes = []
            coil_mins = []
            coil_q25 = []
            coil_q75 = []
            
            # è¿‡æ»¤æ‰ NaN å€¼
            valid_coil_ids = df['coil_id'].dropna().unique()
            for coil_id in sorted(valid_coil_ids):
                coil_df = df[df['coil_id'] == coil_id]
                values = coil_df[feature].values
                
                coil_ids.append(int(coil_id))
                coil_means.append(np.mean(values))
                coil_maxes.append(np.max(values))
                coil_mins.append(np.min(values))
                coil_q25.append(np.percentile(values, 25))
                coil_q75.append(np.percentile(values, 75))
            
            coil_ids = np.array(coil_ids)
            coil_means = np.array(coil_means)
            coil_maxes = np.array(coil_maxes)
            coil_mins = np.array(coil_mins)
            coil_q25 = np.array(coil_q25)
            coil_q75 = np.array(coil_q75)
            
            ax.fill_between(coil_ids, coil_mins, coil_maxes,
                          alpha=0.2, color='gray', label='æœ€å°-æœ€å¤§èŒƒå›´')
            ax.fill_between(coil_ids, coil_q25, coil_q75,
                          alpha=0.3, color='lightblue', label='25%-75%åˆ†ä½æ•°')
            
            ax.plot(coil_ids, coil_means, 'o-', linewidth=4, markersize=12,
                   color='darkblue', label='å‡å€¼', markeredgewidth=2,
                   markeredgecolor='white', zorder=10)
            
            ax.plot(coil_ids, coil_maxes, 's-', linewidth=3, markersize=10,
                   color='darkred', label='æœ€å¤§å€¼', alpha=0.7, zorder=9)
            
            z = np.polyfit(coil_ids, coil_means, 1)
            trend = np.poly1d(z)
            ax.plot(coil_ids, trend(coil_ids), '--', linewidth=3,
                   color='green', label=f'å‡å€¼è¶‹åŠ¿çº¿', alpha=0.8)
            
            change_pct = ((coil_means[-1] - coil_means[0]) / (coil_means[0] + 1e-8)) * 100
            
            if feature == 'avg_gradient_energy':
                is_wear_increasing = (change_pct < 0)
                trend_desc = f'é”åº¦ä¸‹é™{abs(change_pct):.1f}% â†’ ç£¨æŸåŠ é‡' if change_pct < 0 else f'é”åº¦ä¸Šå‡{change_pct:.1f}%'
            else:
                is_wear_increasing = (change_pct > 0)
                trend_desc = f'é€’å¢{change_pct:.1f}% â†’ ç£¨æŸåŠ é‡' if change_pct > 0 else f'é€’å‡{abs(change_pct):.1f}%'
            
            if is_wear_increasing:
                conclusion_text = f'âœ“ {trend_desc}'
                box_color = 'lightgreen'
            else:
                conclusion_text = f'{trend_desc}'
                box_color = 'lightyellow'
            
            ax.text(0.98, 0.98, conclusion_text, transform=ax.transAxes,
                   fontsize=14, fontweight='bold', ha='right', va='top',
                   bbox=dict(boxstyle='round,pad=1', facecolor=box_color,
                            alpha=0.8, edgecolor='black', linewidth=2))
            
            ax.annotate(f'èµ·å§‹\n{coil_means[0]:.2f}',
                       xy=(coil_ids[0], coil_means[0]),
                       xytext=(coil_ids[0]-0.5, coil_means[0]*1.1),
                       fontsize=11, fontweight='bold',
                       bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7),
                       arrowprops=dict(arrowstyle='->', lw=2))
            
            ax.annotate(f'ç»“æŸ\n{coil_means[-1]:.2f}',
                       xy=(coil_ids[-1], coil_means[-1]),
                       xytext=(coil_ids[-1]+0.5, coil_means[-1]*1.1),
                       fontsize=11, fontweight='bold',
                       bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7),
                       arrowprops=dict(arrowstyle='->', lw=2))
            
            ax.set_xlabel('é’¢å·ç¼–å·', fontweight='bold', fontsize=13)
            ax.set_ylabel(label, fontweight='bold', fontsize=13)
            ax.set_title(f'{label} - é€å·æ¼”å˜', fontsize=15, fontweight='bold')
            ax.legend(fontsize=11, loc='best')
            ax.grid(True, alpha=0.3)
            ax.set_xticks(coil_ids)
        
        plt.suptitle(f'{self.analysis_name} - å‰ªåˆ€ç£¨æŸé€å·æ¼”å˜åˆ†æ',
                    fontsize=20, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'coil_progression_detailed.png'), dpi=300, bbox_inches='tight')
        print(f"å·²ä¿å­˜: {viz_dir}/coil_progression_detailed.png")
    
    def _plot_temporal_trends(self, df: pd.DataFrame, save_path: str):
        """ç»˜åˆ¶æ—¶åºè¶‹åŠ¿å›¾"""
        fig, axes = plt.subplots(3, 2, figsize=(16, 12))
        
        features = [
            ('avg_rms_roughness', 'å¹³å‡RMSç²—ç³™åº¦ (åƒç´ )', 'blue'),
            ('max_notch_depth', 'æœ€å¤§ç¼ºå£æ·±åº¦ (åƒç´ )', 'red'),
            ('right_peak_density', 'å‰ªåˆ‡é¢å³°å¯†åº¦ (ä¸ª/å•ä½)', 'green'),
            ('avg_gradient_energy', 'å¹³å‡æ¢¯åº¦èƒ½é‡', 'purple'),
            ('tear_shear_area_ratio', 'æ’•è£‚é¢å æ¯”', 'orange'),
        ]
        
        for idx, (feat, label, color) in enumerate(features):
            ax = axes[idx // 2, idx % 2]
            if feat in df.columns:
                ax.plot(df['frame_id'], df[feat], color=color, alpha=0.5, linewidth=0.5, label='åŸå§‹æ•°æ®')
                
                # å¹³æ»‘æ›²çº¿
                window = min(101, len(df)//10*2+1)
                if window >= 5:
                    smoothed = savgol_filter(df[feat].values, window_length=window, polyorder=3)
                    ax.plot(df['frame_id'], smoothed, color=color, linewidth=2, label='å¹³æ»‘æ›²çº¿')
                
                ax.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
                ax.set_ylabel(label, fontsize=12, fontweight='bold')
                ax.set_title(f'{label}æ—¶åºå˜åŒ–', fontsize=13, fontweight='bold')
                ax.grid(True, alpha=0.3)
                ax.legend()
        
        # éšè—å¤šä½™çš„å­å›¾
        axes[-1, -1].axis('off')
        
        plt.suptitle(f'{self.analysis_name} - ç‰¹å¾æ—¶åºè¶‹åŠ¿åˆ†æ', 
                    fontsize=18, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_feature_correlations(self, df: pd.DataFrame, save_path: str):
        """ç»˜åˆ¶ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ"""
        features = ['avg_rms_roughness', 'max_notch_depth', 'right_peak_density',
                   'avg_gradient_energy', 'tear_shear_area_ratio']
        
        available_features = [f for f in features if f in df.columns]
        
        if len(available_features) < 2:
            print("è­¦å‘Š: ç‰¹å¾æ•°é‡ä¸è¶³ï¼Œè·³è¿‡ç›¸å…³æ€§åˆ†æ")
            return
        
        corr_matrix = df[available_features].corr()
        
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', 
                   center=0, vmin=-1, vmax=1, square=True,
                   cbar_kws={'label': 'ç›¸å…³ç³»æ•°'}, ax=ax)
        
        # è®¾ç½®ç‰¹å¾æ ‡ç­¾ï¼ˆä¸­æ–‡ï¼‰
        feature_labels = {
            'avg_rms_roughness': 'å¹³å‡RMSç²—ç³™åº¦',
            'max_notch_depth': 'æœ€å¤§ç¼ºå£æ·±åº¦',
            'right_peak_density': 'å‰ªåˆ‡é¢å³°å¯†åº¦',
            'avg_gradient_energy': 'å¹³å‡æ¢¯åº¦èƒ½é‡',
            'tear_shear_area_ratio': 'æ’•è£‚é¢å æ¯”'
        }
        labels = [feature_labels.get(f, f) for f in available_features]
        ax.set_xticklabels(labels, rotation=45, ha='right')
        ax.set_yticklabels(labels, rotation=0)
        
        ax.set_title(f'{self.analysis_name} - ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ\n(1=å®Œå…¨æ­£ç›¸å…³, -1=å®Œå…¨è´Ÿç›¸å…³)', 
                    fontsize=16, fontweight='bold', pad=20)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_wear_progression(self, df: pd.DataFrame, save_path: str):
        """ç»˜åˆ¶ç£¨æŸé€’è¿›å›¾ï¼ˆæ»‘åŠ¨çª—å£å¹³å‡ï¼‰"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        
        features = [
            ('avg_rms_roughness', 'å¹³å‡RMSç²—ç³™åº¦'),
            ('max_notch_depth', 'æœ€å¤§ç¼ºå£æ·±åº¦'),
            ('right_peak_density', 'å‰ªåˆ‡é¢å³°å¯†åº¦'),
            ('avg_gradient_energy', 'å¹³å‡æ¢¯åº¦èƒ½é‡'),
            ('tear_shear_area_ratio', 'æ’•è£‚é¢å æ¯”'),
        ]
        
        window_size = max(10, len(df) // 20)  # è‡³å°‘10å¸§
        
        for idx, (feat, label) in enumerate(features):
            ax = axes[idx // 3, idx % 3]
            if feat in df.columns:
                # æ»‘åŠ¨çª—å£å¹³å‡
                rolling_mean = df[feat].rolling(window=window_size, center=True).mean()
                rolling_std = df[feat].rolling(window=window_size, center=True).std()
                
                ax.plot(df['frame_id'], rolling_mean, color='darkblue', linewidth=2, label='æ»‘åŠ¨å¹³å‡')
                ax.fill_between(df['frame_id'], 
                               rolling_mean - rolling_std,
                               rolling_mean + rolling_std,
                               alpha=0.3, color='lightblue', label='Â±1æ ‡å‡†å·®')
                
                ax.set_xlabel('å¸§ç¼–å·', fontsize=11, fontweight='bold')
                ax.set_ylabel(label, fontsize=11, fontweight='bold')
                ax.set_title(label, fontsize=12, fontweight='bold')
                ax.grid(True, alpha=0.3)
                ax.legend()
        
        axes[-1, -1].axis('off')
        
        plt.suptitle(f'{self.analysis_name} - ç£¨æŸé€’è¿›åˆ†æï¼ˆæ»‘åŠ¨çª—å£={window_size}å¸§ï¼‰', 
                    fontsize=18, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_longterm_trend(self, df: pd.DataFrame, save_path: str):
        """ç»˜åˆ¶é•¿æœŸè¶‹åŠ¿å›¾ï¼ˆçº¿æ€§æ‹Ÿåˆï¼‰"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        
        features = [
            ('avg_rms_roughness', 'å¹³å‡RMSç²—ç³™åº¦', 'blue'),
            ('max_notch_depth', 'æœ€å¤§ç¼ºå£æ·±åº¦', 'red'),
            ('right_peak_density', 'å‰ªåˆ‡é¢å³°å¯†åº¦', 'green'),
            ('avg_gradient_energy', 'å¹³å‡æ¢¯åº¦èƒ½é‡', 'purple'),
            ('tear_shear_area_ratio', 'æ’•è£‚é¢å æ¯”', 'orange'),
        ]
        
        for idx, (feat, label, color) in enumerate(features):
            ax = axes[idx // 3, idx % 3]
            if feat in df.columns:
                # åŸå§‹æ•°æ®è¿çº¿ï¼ˆæ˜¾ç¤ºæ—¶é—´è¿ç»­æ€§ï¼‰
                ax.plot(df['frame_id'], df[feat], 
                       alpha=0.3, linewidth=1.2, color=color, 
                       zorder=1, label='é€å¸§æ›²çº¿')
                
                # æ•£ç‚¹æ ‡è®°ï¼ˆæ ‡å‡ºæ•°æ®ç‚¹ï¼‰
                ax.scatter(df['frame_id'], df[feat], 
                          alpha=0.4, s=15, color=color, zorder=2)
                
                # çº¿æ€§æ‹Ÿåˆè¶‹åŠ¿çº¿ï¼ˆçªå‡ºæ•´ä½“è¶‹åŠ¿ï¼‰
                z = np.polyfit(df['frame_id'], df[feat], 1)
                p = np.poly1d(z)
                ax.plot(df['frame_id'], p(df['frame_id']), 
                       color='darkred', linewidth=3, linestyle='--', 
                       zorder=3, label=f'çº¿æ€§è¶‹åŠ¿: y={z[0]:.6f}x+{z[1]:.2f}')
                
                # è®¡ç®—è¶‹åŠ¿æ–¹å‘
                trend = "å¢åŠ " if z[0] > 0 else "å‡å°‘"
                ax.text(0.05, 0.95, f'è¶‹åŠ¿: {trend}', 
                       transform=ax.transAxes, fontsize=11, 
                       verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
                
                ax.set_xlabel('å¸§ç¼–å·', fontsize=11, fontweight='bold')
                ax.set_ylabel(label, fontsize=11, fontweight='bold')
                ax.set_title(label, fontsize=12, fontweight='bold')
                ax.grid(True, alpha=0.3)
                ax.legend()
        
        axes[-1, -1].axis('off')
        
        plt.suptitle(f'{self.analysis_name} - é•¿æœŸç£¨æŸè¶‹åŠ¿åˆ†æï¼ˆçº¿æ€§æ‹Ÿåˆï¼‰', 
                    fontsize=18, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_individual_longterm_trends(self, df: pd.DataFrame, viz_dir: str):
        """
        ç»˜åˆ¶å•ç‹¬çš„é•¿æœŸè¶‹åŠ¿å›¾ï¼ˆæ¯ä¸ªç‰¹å¾ä¸€å¼ å›¾ï¼‰
        
        å°†5ä¸ªå…³é”®ç‰¹å¾çš„é•¿æœŸè¶‹åŠ¿åˆ†åˆ«ä¿å­˜ä¸ºç‹¬ç«‹çš„å›¾ç‰‡æ–‡ä»¶ï¼Œ
        xè½´æ‹‰é•¿ä»¥ä¾¿æ›´æ¸…æ¥šåœ°æŸ¥çœ‹éšæ—¶é—´çš„å˜åŒ–æ›²çº¿
        """
        print("\nç”Ÿæˆå•ç‹¬çš„é•¿æœŸè¶‹åŠ¿å›¾...")
        
        # å®šä¹‰ç‰¹å¾åŠå…¶å¯¹åº”çš„æ ‡ç­¾å’Œé¢œè‰²
        features_to_plot = [
            ('avg_rms_roughness', 'å¹³å‡RMSç²—ç³™åº¦', 'blue'),
            ('max_notch_depth', 'æœ€å¤§ç¼ºå£æ·±åº¦', 'red'),
            ('right_peak_density', 'å‰ªåˆ‡é¢å³°å¯†åº¦', 'green'),
            ('avg_gradient_energy', 'å¹³å‡æ¢¯åº¦èƒ½é‡', 'purple'),
            ('tear_shear_area_ratio', 'æ’•è£‚é¢å æ¯”', 'orange'),
        ]
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = os.path.join(viz_dir, 'individual_trends')
        ensure_dir(output_dir)
        
        for feat, label, color in features_to_plot:
            if feat not in df.columns:
                print(f"  è­¦å‘Š: ç‰¹å¾ '{feat}' ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue
            
            # åˆ›å»ºå•ç‹¬çš„å›¾è¡¨ï¼Œxè½´æ‹‰é•¿è‡³60è‹±å¯¸ï¼ˆä¸split_longterm_trend_charts.pyä¸€è‡´ï¼‰
            fig, ax = plt.subplots(figsize=(60, 6))
            
            # è·å–æ•°æ®
            y_values = df[feat].values
            
            # è®¡ç®—åŒ…ç»œçº¿
            upper_env, lower_env = self.compute_envelope(y_values, window=min(31, len(y_values)//10))
            
            # è®¡ç®—é²æ£’æ‹Ÿåˆæ›²çº¿
            fitted_curve, inlier_mask = self.robust_curve_fit(y_values, percentile_range=(5, 95))
            
            # ç»˜åˆ¶åŒ…ç»œèŒƒå›´ï¼ˆå¡«å……ï¼‰
            ax.fill_between(df['frame_id'], lower_env, upper_env,
                           alpha=0.15, color='gray', label='åŒ…ç»œèŒƒå›´', zorder=1)
            
            # ç»˜åˆ¶ä¸Šä¸‹åŒ…ç»œçº¿
            ax.plot(df['frame_id'], upper_env, ':', linewidth=1.5, 
                   color='red', alpha=0.6, label='ä¸ŠåŒ…ç»œ', zorder=2)
            ax.plot(df['frame_id'], lower_env, ':', linewidth=1.5, 
                   color='green', alpha=0.6, label='ä¸‹åŒ…ç»œ', zorder=2)
            
            # åŸå§‹æ•°æ®è¿çº¿ï¼ˆåŠé€æ˜ï¼‰
            ax.plot(df['frame_id'], y_values,
                   alpha=0.3, linewidth=1.2, color=color,
                   zorder=3, label='é€å¸§æ›²çº¿')
            
            # æ•£ç‚¹æ ‡è®°
            ax.scatter(df['frame_id'], y_values,
                      alpha=0.4, s=15, color=color, zorder=4)
            
            # æ ‡æ³¨ç¦»ç¾¤ç‚¹
            outlier_indices = np.where(~inlier_mask)[0]
            if len(outlier_indices) > 0:
                ax.scatter(df['frame_id'].iloc[outlier_indices], 
                          y_values[outlier_indices],
                          c='orange', s=30, marker='x', alpha=0.7, 
                          label=f'ç¦»ç¾¤ç‚¹({len(outlier_indices)}ä¸ª)', zorder=5)
            
            # é²æ£’æ‹Ÿåˆæ›²çº¿ï¼ˆä¸»è¶‹åŠ¿ï¼‰
            ax.plot(df['frame_id'], fitted_curve,
                   color='purple', linewidth=3, linestyle='-',
                   alpha=0.8, zorder=6, label='é²æ£’æ‹Ÿåˆ')
            
            # çº¿æ€§æ‹Ÿåˆè¶‹åŠ¿çº¿
            z = np.polyfit(df['frame_id'], y_values, 1)
            p = np.poly1d(z)
            ax.plot(df['frame_id'], p(df['frame_id']),
                   color='darkred', linewidth=2.5, linestyle='--',
                   zorder=7, label=f'çº¿æ€§è¶‹åŠ¿: y={z[0]:.6f}x+{z[1]:.2f}')
            
            # è®¡ç®—è¶‹åŠ¿æ–¹å‘å’Œå†…ç‚¹ç‡
            trend = "å¢åŠ " if z[0] > 0 else "å‡å°‘"
            inlier_ratio = inlier_mask.sum() / len(inlier_mask) * 100
            ax.text(0.05, 0.95, f'è¶‹åŠ¿: {trend}\nå†…ç‚¹ç‡: {inlier_ratio:.1f}%',
                   transform=ax.transAxes, fontsize=11,
                   verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
            
            ax.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
            ax.set_ylabel(label, fontsize=12, fontweight='bold')
            ax.set_title(f'{label} é•¿æœŸè¶‹åŠ¿', fontsize=14, fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend()
            
            # è°ƒæ•´xè½´èŒƒå›´ï¼Œç¡®ä¿æ‹‰é•¿æ•ˆæœ
            ax.set_xlim(df['frame_id'].min(), df['frame_id'].max())
            
            # ä¿å­˜å›¾è¡¨
            individual_save_path = os.path.join(output_dir, f'{feat}_trend.png')
            plt.savefig(individual_save_path, dpi=200, bbox_inches='tight')
            plt.close(fig)
            print(f"  å·²ä¿å­˜: {feat}_trend.png")
        
        print(f"âœ“ å•ç‹¬é•¿æœŸè¶‹åŠ¿å›¾å·²ä¿å­˜åˆ°: {output_dir}")
    
    def _plot_combined_trends_6x1(self, df: pd.DataFrame, viz_dir: str):
        """
        ç»˜åˆ¶6Ã—1ç»„åˆå›¾ï¼ˆç»¼åˆæŒ‡æ ‡ + 5ä¸ªç‰¹å¾ä¸Šä¸‹ç½—åˆ—ï¼‰
        
        ç»¼åˆæŒ‡æ ‡ï¼š4ä¸ªç‰¹å¾å½’ä¸€åŒ–å åŠ ï¼ˆä¸å«æ¢¯åº¦èƒ½é‡ï¼‰
        """
        print("\nç”Ÿæˆ6Ã—1ç»„åˆé•¿æœŸè¶‹åŠ¿å›¾...")
        
        # å®šä¹‰ç‰¹å¾åŠå…¶å¯¹åº”çš„æ ‡ç­¾å’Œé¢œè‰²
        features_to_plot = [
            ('avg_rms_roughness', 'å¹³å‡RMSç²—ç³™åº¦', 'blue'),
            ('max_notch_depth', 'æœ€å¤§ç¼ºå£æ·±åº¦', 'red'),
            ('right_peak_density', 'å‰ªåˆ‡é¢å³°å¯†åº¦', 'green'),
            ('avg_gradient_energy', 'å¹³å‡æ¢¯åº¦èƒ½é‡', 'purple'),
            ('tear_shear_area_ratio', 'æ’•è£‚é¢å æ¯”', 'orange'),
        ]
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = os.path.join(viz_dir, 'individual_trends')
        ensure_dir(output_dir)
        
        # åˆ›å»º6Ã—1å­å›¾å¸ƒå±€ï¼Œxè½´è®¾ç½®ä¸º80è‹±å¯¸
        fig, axes = plt.subplots(6, 1, figsize=(80, 29))
        
        # ========== ç¬¬1ä¸ªå­å›¾ï¼šç»¼åˆæŒ‡æ ‡ï¼ˆ4ä¸ªç‰¹å¾å½’ä¸€åŒ–åå åŠ ï¼Œä¸å«æ¢¯åº¦èƒ½é‡ï¼‰ ==========
        ax_composite = axes[0]
        
        # è®¡ç®—ç»¼åˆæŒ‡æ ‡ - æ’é™¤ avg_gradient_energy
        composite_score = np.zeros(len(df))
        valid_features = []
        excluded_features = ['avg_gradient_energy']  # æ’é™¤çš„ç‰¹å¾
        
        for feat, label, color in features_to_plot:
            if feat in df.columns and feat not in excluded_features:
                # å½’ä¸€åŒ–åˆ°0-1
                values = df[feat].values
                if values.max() > values.min():
                    normalized = (values - values.min()) / (values.max() - values.min())
                    composite_score += normalized
                    valid_features.append((feat, label))
        
        # å¹³å‡åŒ–ï¼ˆé¿å…ç®€å•æ±‚å’Œå¯¼è‡´å€¼è¿‡å¤§ï¼‰
        if len(valid_features) > 0:
            composite_score = composite_score / len(valid_features)
        
        # è®¡ç®—åŒ…ç»œçº¿å’Œé²æ£’æ‹Ÿåˆ
        upper_env_comp, lower_env_comp = self.compute_envelope(composite_score, window=min(31, len(composite_score)//10))
        fitted_curve_comp, inlier_mask_comp = self.robust_curve_fit(composite_score, percentile_range=(5, 95))
        
        # ç»˜åˆ¶åŒ…ç»œèŒƒå›´
        ax_composite.fill_between(df['frame_id'], lower_env_comp, upper_env_comp,
                                 alpha=0.15, color='gray', label='åŒ…ç»œèŒƒå›´', zorder=1)
        
        # ç»˜åˆ¶åŒ…ç»œçº¿
        ax_composite.plot(df['frame_id'], upper_env_comp, ':', linewidth=1.5, 
                         color='red', alpha=0.6, label='ä¸ŠåŒ…ç»œ', zorder=2)
        ax_composite.plot(df['frame_id'], lower_env_comp, ':', linewidth=1.5, 
                         color='green', alpha=0.6, label='ä¸‹åŒ…ç»œ', zorder=2)
        
        # ç»˜åˆ¶ç»¼åˆæŒ‡æ ‡ï¼ˆåŠé€æ˜ï¼‰
        ax_composite.plot(df['frame_id'], composite_score,
                         alpha=0.3, linewidth=1.5, color='darkblue',
                         zorder=3, label='ç»¼åˆç£¨æŸæŒ‡æ ‡')
        
        ax_composite.scatter(df['frame_id'], composite_score,
                            alpha=0.4, s=20, color='darkblue', zorder=4)
        
        # æ ‡æ³¨ç¦»ç¾¤ç‚¹
        outlier_indices_comp = np.where(~inlier_mask_comp)[0]
        if len(outlier_indices_comp) > 0:
            ax_composite.scatter(df['frame_id'].iloc[outlier_indices_comp], 
                                composite_score[outlier_indices_comp],
                                c='orange', s=35, marker='x', alpha=0.7, 
                                label=f'ç¦»ç¾¤ç‚¹({len(outlier_indices_comp)}ä¸ª)', zorder=5)
        
        # é²æ£’æ‹Ÿåˆæ›²çº¿
        ax_composite.plot(df['frame_id'], fitted_curve_comp,
                         color='purple', linewidth=3.5, linestyle='-',
                         alpha=0.8, zorder=6, label='é²æ£’æ‹Ÿåˆ')
        
        # çº¿æ€§æ‹Ÿåˆ
        z_comp = np.polyfit(df['frame_id'], composite_score, 1)
        p_comp = np.poly1d(z_comp)
        ax_composite.plot(df['frame_id'], p_comp(df['frame_id']),
                         color='red', linewidth=3, linestyle='--',
                         zorder=7, label=f'çº¿æ€§è¶‹åŠ¿: y={z_comp[0]:.6f}x+{z_comp[1]:.2f}')
        
        # è¶‹åŠ¿æ ‡æ³¨ï¼ˆåŒ…å«å†…ç‚¹ç‡ï¼‰
        trend_comp = "å¢åŠ " if z_comp[0] > 0 else "å‡å°‘"
        trend_color_comp = 'lightgreen' if z_comp[0] > 0 else 'lightcoral'
        inlier_ratio_comp = inlier_mask_comp.sum() / len(inlier_mask_comp) * 100
        ax_composite.text(0.02, 0.98, f'è¶‹åŠ¿: {trend_comp}\nå†…ç‚¹ç‡: {inlier_ratio_comp:.1f}%',
                         transform=ax_composite.transAxes, fontsize=12,
                         verticalalignment='top', fontweight='bold',
                         bbox=dict(boxstyle='round', facecolor=trend_color_comp, alpha=0.7,
                                  edgecolor='black', linewidth=2))
        
        # ç»Ÿè®¡ä¿¡æ¯
        mean_comp = composite_score.mean()
        std_comp = composite_score.std()
        min_comp = composite_score.min()
        max_comp = composite_score.max()
        
        stats_text_comp = f'å‡å€¼: {mean_comp:.3f}\næ ‡å‡†å·®: {std_comp:.3f}\nèŒƒå›´: [{min_comp:.3f}, {max_comp:.3f}]'
        ax_composite.text(0.98, 0.98, stats_text_comp,
                         transform=ax_composite.transAxes, fontsize=10,
                         verticalalignment='top', horizontalalignment='right',
                         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8,
                                  edgecolor='gray', linewidth=1))
        
        # æ·»åŠ ç‰¹å¾è¯´æ˜
        features_text = 'åŒ…å«ç‰¹å¾: ' + ', '.join([label for _, label in valid_features])
        ax_composite.text(0.02, 0.02, features_text,
                         transform=ax_composite.transAxes, fontsize=9,
                         verticalalignment='bottom',
                         bbox=dict(boxstyle='round', facecolor='white', alpha=0.7,
                                  edgecolor='gray', linewidth=0.5))
        
        ax_composite.set_xlabel('å¸§ç¼–å·', fontsize=13, fontweight='bold')
        ax_composite.set_ylabel('ç»¼åˆç£¨æŸæŒ‡æ ‡ (å½’ä¸€åŒ–)', fontsize=13, fontweight='bold')
        ax_composite.set_title('ç»¼åˆç£¨æŸæŒ‡æ ‡ (4ç‰¹å¾å½’ä¸€åŒ–å åŠ : ä¸å«æ¢¯åº¦èƒ½é‡)', fontsize=16, fontweight='bold', pad=15, 
                              bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))
        ax_composite.grid(True, alpha=0.3)
        ax_composite.legend(loc='upper left', fontsize=11)
        ax_composite.set_xlim(df['frame_id'].min(), df['frame_id'].max())
        ax_composite.set_ylim(-0.05, 1.05)
        
        # ========== å5ä¸ªå­å›¾ï¼šå„ä¸ªç‰¹å¾ ==========
        
        for idx, (feat, label, color) in enumerate(features_to_plot):
            ax = axes[idx + 1]  # å› ä¸ºç¬¬0ä¸ªä½ç½®è¢«ç»¼åˆæŒ‡æ ‡å ç”¨
            
            if feat not in df.columns:
                ax.text(0.5, 0.5, f'ç‰¹å¾ "{feat}" ä¸å­˜åœ¨', 
                       ha='center', va='center', fontsize=14, color='red')
                ax.set_title(f'{label} - æ•°æ®ç¼ºå¤±', fontsize=14, fontweight='bold')
                continue
            
            # è·å–æ•°æ®
            y_values = df[feat].values
            
            # è®¡ç®—åŒ…ç»œçº¿å’Œé²æ£’æ‹Ÿåˆ
            upper_env, lower_env = self.compute_envelope(y_values, window=min(31, len(y_values)//10))
            fitted_curve, inlier_mask = self.robust_curve_fit(y_values, percentile_range=(5, 95))
            
            # ç»˜åˆ¶åŒ…ç»œèŒƒå›´
            ax.fill_between(df['frame_id'], lower_env, upper_env,
                           alpha=0.15, color='gray', label='åŒ…ç»œèŒƒå›´', zorder=1)
            
            # ç»˜åˆ¶åŒ…ç»œçº¿
            ax.plot(df['frame_id'], upper_env, ':', linewidth=1.5, 
                   color='red', alpha=0.6, label='ä¸ŠåŒ…ç»œ', zorder=2)
            ax.plot(df['frame_id'], lower_env, ':', linewidth=1.5, 
                   color='green', alpha=0.6, label='ä¸‹åŒ…ç»œ', zorder=2)
            
            # åŸå§‹æ•°æ®è¿çº¿ï¼ˆåŠé€æ˜ï¼‰
            ax.plot(df['frame_id'], y_values,
                   alpha=0.3, linewidth=1.2, color=color,
                   zorder=3, label='é€å¸§æ›²çº¿')
            
            # æ•£ç‚¹æ ‡è®°
            ax.scatter(df['frame_id'], y_values,
                      alpha=0.4, s=15, color=color, zorder=4)
            
            # æ ‡æ³¨ç¦»ç¾¤ç‚¹
            outlier_indices = np.where(~inlier_mask)[0]
            if len(outlier_indices) > 0:
                ax.scatter(df['frame_id'].iloc[outlier_indices], 
                          y_values[outlier_indices],
                          c='orange', s=30, marker='x', alpha=0.7, 
                          label=f'ç¦»ç¾¤ç‚¹({len(outlier_indices)}ä¸ª)', zorder=5)
            
            # é²æ£’æ‹Ÿåˆæ›²çº¿
            ax.plot(df['frame_id'], fitted_curve,
                   color='purple', linewidth=2.5, linestyle='-',
                   alpha=0.8, zorder=6, label='é²æ£’æ‹Ÿåˆ')
            
            # çº¿æ€§æ‹Ÿåˆè¶‹åŠ¿çº¿
            z = np.polyfit(df['frame_id'], y_values, 1)
            p = np.poly1d(z)
            ax.plot(df['frame_id'], p(df['frame_id']),
                   color='darkred', linewidth=2.5, linestyle='--',
                   zorder=7, label=f'çº¿æ€§è¶‹åŠ¿: y={z[0]:.6f}x+{z[1]:.2f}')
            
            # è®¡ç®—è¶‹åŠ¿æ–¹å‘å’Œå†…ç‚¹ç‡
            trend = "å¢åŠ " if z[0] > 0 else "å‡å°‘"
            trend_color = 'lightgreen' if z[0] > 0 else 'lightcoral'
            inlier_ratio = inlier_mask.sum() / len(inlier_mask) * 100
            ax.text(0.02, 0.98, f'è¶‹åŠ¿: {trend}\nå†…ç‚¹ç‡: {inlier_ratio:.1f}%',
                   transform=ax.transAxes, fontsize=11,
                   verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor=trend_color, alpha=0.6,
                            edgecolor='black', linewidth=1))
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            mean_val = df[feat].mean()
            std_val = df[feat].std()
            min_val = df[feat].min()
            max_val = df[feat].max()
            
            stats_text = f'å‡å€¼: {mean_val:.2f}\næ ‡å‡†å·®: {std_val:.2f}\nèŒƒå›´: [{min_val:.2f}, {max_val:.2f}]'
            ax.text(0.98, 0.98, stats_text,
                   transform=ax.transAxes, fontsize=9,
                   verticalalignment='top', horizontalalignment='right',
                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.7,
                            edgecolor='gray', linewidth=0.5))
            
            ax.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
            ax.set_ylabel(label, fontsize=12, fontweight='bold')
            ax.set_title(f'{label} é•¿æœŸè¶‹åŠ¿', fontsize=14, fontweight='bold', pad=10)
            ax.grid(True, alpha=0.3)
            ax.legend(loc='upper left', fontsize=10)
            
            # è°ƒæ•´xè½´èŒƒå›´ï¼Œç¡®ä¿æ‹‰é•¿æ•ˆæœ
            ax.set_xlim(df['frame_id'].min(), df['frame_id'].max())
        
        # è®¾ç½®æ€»æ ‡é¢˜
        fig.suptitle(f'{self.analysis_name} - å‰ªåˆ€ç£¨æŸé•¿æœŸè¶‹åŠ¿ç»¼åˆåˆ†æï¼ˆç»¼åˆæŒ‡æ ‡[4ç‰¹å¾] + 5ç‰¹å¾è¯¦æƒ…ï¼‰', 
                    fontsize=18, fontweight='bold', y=0.996)
        
        # è°ƒæ•´å­å›¾é—´è·
        plt.tight_layout(rect=[0, 0, 1, 0.996])
        
        # ä¿å­˜
        combined_save_path = os.path.join(output_dir, 'all_trends_6x1.png')
        plt.savefig(combined_save_path, dpi=200, bbox_inches='tight')
        plt.close(fig)
        
        print(f"âœ“ 6Ã—1ç»„åˆå›¾å·²ä¿å­˜: all_trends_6x1.png")
    
    def _plot_horizontal_gradient_comparison(self, df: pd.DataFrame, save_path: str):
        """ç»˜åˆ¶æ°´å¹³æ¢¯åº¦èƒ½é‡å¯¹æ¯”å›¾ï¼ˆæ€»æ¢¯åº¦ vs æ°´å¹³æ¢¯åº¦ï¼‰"""
        fig, axes = plt.subplots(2, 2, figsize=(18, 12))
        
        # 1. æ—¶åºå¯¹æ¯”ï¼ˆåŸå§‹æ•°æ® + å¹³æ»‘ + çº¿æ€§è¶‹åŠ¿ï¼‰
        ax1 = axes[0, 0]
        
        window = min(51, len(df)//10*2+1)
        
        # ç»˜åˆ¶æ€»æ¢¯åº¦èƒ½é‡
        if 'avg_gradient_energy' in df.columns:
            ax1.plot(df['frame_id'], df['avg_gradient_energy'], 
                    color='blue', alpha=0.3, linewidth=1, label='æ€»æ¢¯åº¦èƒ½é‡(åŸå§‹)')
            
            # å¹³æ»‘å¤„ç†
            if window >= 5:
                smoothed_total = savgol_filter(df['avg_gradient_energy'].values, 
                                              window_length=window, polyorder=3)
                ax1.plot(df['frame_id'], smoothed_total, 
                        color='blue', linewidth=3, label='æ€»æ¢¯åº¦èƒ½é‡(å¹³æ»‘)')
            
            # çº¿æ€§è¶‹åŠ¿
            z_total = np.polyfit(df['frame_id'], df['avg_gradient_energy'], 1)
            p_total = np.poly1d(z_total)
            ax1.plot(df['frame_id'], p_total(df['frame_id']), 
                    color='darkblue', linewidth=2.5, linestyle='--', alpha=0.8,
                    label=f'æ€»æ¢¯åº¦è¶‹åŠ¿(æ–œç‡={z_total[0]:.2e})')
        
        # ç»˜åˆ¶æ°´å¹³æ¢¯åº¦èƒ½é‡
        ax1.plot(df['frame_id'], df['avg_horizontal_gradient'], 
                color='red', alpha=0.3, linewidth=1, label='æ°´å¹³æ¢¯åº¦èƒ½é‡(åŸå§‹)')
        
        # å¹³æ»‘å¤„ç†
        if window >= 5:
            smoothed_horizontal = savgol_filter(df['avg_horizontal_gradient'].values, 
                                               window_length=window, polyorder=3)
            ax1.plot(df['frame_id'], smoothed_horizontal, 
                    color='red', linewidth=3, label='æ°´å¹³æ¢¯åº¦èƒ½é‡(å¹³æ»‘)')
        
        # çº¿æ€§è¶‹åŠ¿
        z_horizontal = np.polyfit(df['frame_id'], df['avg_horizontal_gradient'], 1)
        p_horizontal = np.poly1d(z_horizontal)
        ax1.plot(df['frame_id'], p_horizontal(df['frame_id']), 
                color='darkred', linewidth=2.5, linestyle='--', alpha=0.8,
                label=f'æ°´å¹³æ¢¯åº¦è¶‹åŠ¿(æ–œç‡={z_horizontal[0]:.2e})')
        
        ax1.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
        ax1.set_ylabel('æ¢¯åº¦èƒ½é‡', fontsize=12, fontweight='bold')
        ax1.set_title('æ€»æ¢¯åº¦ vs æ°´å¹³æ¢¯åº¦ æ—¶åºå¯¹æ¯”ï¼ˆå«çº¿æ€§è¶‹åŠ¿ï¼‰', fontsize=14, fontweight='bold')
        ax1.legend(fontsize=9, loc='best')
        ax1.grid(True, alpha=0.3)
        
        # 2. æŒ‰å·ç»Ÿè®¡å¯¹æ¯”
        ax2 = axes[0, 1]
        
        valid_coil_ids = df['coil_id'].dropna().unique()
        coil_ids_list = sorted(valid_coil_ids)
        
        total_grad_means = []
        horizontal_grad_means = []
        
        for coil_id in coil_ids_list:
            coil_df = df[df['coil_id'] == coil_id]
            if 'avg_gradient_energy' in df.columns:
                total_grad_means.append(coil_df['avg_gradient_energy'].mean())
            horizontal_grad_means.append(coil_df['avg_horizontal_gradient'].mean())
        
        x = np.arange(len(coil_ids_list))
        width = 0.35
        
        if 'avg_gradient_energy' in df.columns and len(total_grad_means) > 0:
            bars1 = ax2.bar(x - width/2, total_grad_means, width, 
                          label='æ€»æ¢¯åº¦èƒ½é‡', color='steelblue', alpha=0.8)
        
        bars2 = ax2.bar(x + width/2 if 'avg_gradient_energy' in df.columns else x, 
                       horizontal_grad_means, width,
                       label='æ°´å¹³æ¢¯åº¦èƒ½é‡', color='coral', alpha=0.8)
        
        ax2.set_xlabel('é’¢å·ç¼–å·', fontsize=12, fontweight='bold')
        ax2.set_ylabel('å¹³å‡æ¢¯åº¦èƒ½é‡', fontsize=12, fontweight='bold')
        ax2.set_title('å„å·æ¢¯åº¦èƒ½é‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax2.set_xticks(x)
        ax2.set_xticklabels([f'å·{int(cid)}' for cid in coil_ids_list])
        ax2.legend(fontsize=11)
        ax2.grid(True, alpha=0.3, axis='y')
        
        # 3. å½’ä¸€åŒ–å¯¹æ¯”ï¼ˆæ›´æ¸…æ¥šåœ°çœ‹è¶‹åŠ¿ + çº¿æ€§æ‹Ÿåˆï¼‰
        ax3 = axes[1, 0]
        
        # å½’ä¸€åŒ–åˆ°0-1
        if 'avg_gradient_energy' in df.columns:
            total_grad_norm = (df['avg_gradient_energy'] - df['avg_gradient_energy'].min()) / \
                             (df['avg_gradient_energy'].max() - df['avg_gradient_energy'].min() + 1e-8)
            if window >= 5:
                total_grad_norm_smooth = savgol_filter(total_grad_norm.values, 
                                                      window_length=window, polyorder=3)
                ax3.plot(df['frame_id'], total_grad_norm_smooth, 
                        color='blue', linewidth=3, label='æ€»æ¢¯åº¦èƒ½é‡(å½’ä¸€åŒ–)')
            
            # çº¿æ€§è¶‹åŠ¿ï¼ˆå½’ä¸€åŒ–åï¼‰
            z_total_norm = np.polyfit(df['frame_id'], total_grad_norm.values, 1)
            p_total_norm = np.poly1d(z_total_norm)
            ax3.plot(df['frame_id'], p_total_norm(df['frame_id']), 
                    color='darkblue', linewidth=2, linestyle='--', alpha=0.7,
                    label=f'æ€»æ¢¯åº¦çº¿æ€§è¶‹åŠ¿(æ–œç‡={z_total_norm[0]:.2e})')
        
        horizontal_grad_norm = (df['avg_horizontal_gradient'] - df['avg_horizontal_gradient'].min()) / \
                              (df['avg_horizontal_gradient'].max() - df['avg_horizontal_gradient'].min() + 1e-8)
        if window >= 5:
            horizontal_grad_norm_smooth = savgol_filter(horizontal_grad_norm.values, 
                                                       window_length=window, polyorder=3)
            ax3.plot(df['frame_id'], horizontal_grad_norm_smooth, 
                    color='red', linewidth=3, label='æ°´å¹³æ¢¯åº¦èƒ½é‡(å½’ä¸€åŒ–)')
        
        # çº¿æ€§è¶‹åŠ¿ï¼ˆå½’ä¸€åŒ–åï¼‰
        z_horizontal_norm = np.polyfit(df['frame_id'], horizontal_grad_norm.values, 1)
        p_horizontal_norm = np.poly1d(z_horizontal_norm)
        ax3.plot(df['frame_id'], p_horizontal_norm(df['frame_id']), 
                color='darkred', linewidth=2, linestyle='--', alpha=0.7,
                label=f'æ°´å¹³æ¢¯åº¦çº¿æ€§è¶‹åŠ¿(æ–œç‡={z_horizontal_norm[0]:.2e})')
        
        ax3.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
        ax3.set_ylabel('å½’ä¸€åŒ–æ¢¯åº¦èƒ½é‡ (0-1)', fontsize=12, fontweight='bold')
        ax3.set_title('å½’ä¸€åŒ–æ¢¯åº¦èƒ½é‡å¯¹æ¯”ï¼ˆå«çº¿æ€§è¶‹åŠ¿ï¼‰', fontsize=14, fontweight='bold')
        ax3.legend(fontsize=9, loc='best')
        ax3.grid(True, alpha=0.3)
        ax3.set_ylim(-0.05, 1.05)
        
        # 4. å˜åŒ–ç‡ç»Ÿè®¡
        ax4 = axes[1, 1]
        
        # è®¡ç®—é¦–å°¾å˜åŒ–ç‡
        def calc_change_rate(values):
            if len(values) > 10:
                first = np.mean(values[:len(values)//10])
                last = np.mean(values[-len(values)//10:])
                if first != 0:
                    return ((last - first) / first) * 100
            return 0
        
        labels = []
        change_rates = []
        colors = []
        
        if 'avg_gradient_energy' in df.columns:
            total_change = calc_change_rate(df['avg_gradient_energy'].values)
            labels.append('æ€»æ¢¯åº¦èƒ½é‡')
            change_rates.append(total_change)
            colors.append('steelblue')
        
        horizontal_change = calc_change_rate(df['avg_horizontal_gradient'].values)
        labels.append('æ°´å¹³æ¢¯åº¦èƒ½é‡')
        change_rates.append(horizontal_change)
        colors.append('coral')
        
        bars = ax4.bar(labels, change_rates, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
        ax4.set_ylabel('å˜åŒ–ç‡ (%)', fontsize=12, fontweight='bold')
        ax4.set_title('é¦–å°¾å˜åŒ–ç‡å¯¹æ¯”\n(è´Ÿå€¼è¡¨ç¤ºä¸‹é™=ç£¨æŸåŠ é‡)', fontsize=14, fontweight='bold')
        ax4.axhline(y=0, color='black', linestyle='--', linewidth=2)
        ax4.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, rate in zip(bars, change_rates):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{rate:.1f}%', ha='center', 
                    va='bottom' if height > 0 else 'top',
                    fontsize=12, fontweight='bold')
        
        plt.suptitle(f'{self.analysis_name} - æ°´å¹³æ¢¯åº¦èƒ½é‡ä¸“é¡¹åˆ†æ\nï¼ˆæ°´å¹³æ¢¯åº¦åªåæ˜ å‚ç›´è¾¹ç¼˜ï¼Œå¯¹åˆ€å£é”åº¦æ›´æ•æ„Ÿï¼‰', 
                    fontsize=16, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_recommended_indicators(self, df: pd.DataFrame, save_path: str):
        """ç»˜åˆ¶æ¨èæŒ‡æ ‡å›¾ï¼ˆç»¼åˆè¯„åˆ†ï¼‰"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # å½’ä¸€åŒ–ç‰¹å¾
        from sklearn.preprocessing import MinMaxScaler
        scaler = MinMaxScaler()
        
        key_features = ['avg_rms_roughness', 'max_notch_depth', 
                       'avg_gradient_energy', 'tear_shear_area_ratio']
        available = [f for f in key_features if f in df.columns]
        
        if len(available) == 0:
            print("è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿçš„ç‰¹å¾ç”Ÿæˆæ¨èæŒ‡æ ‡")
            return
        
        df_norm = pd.DataFrame(
            scaler.fit_transform(df[available]),
            columns=available,
            index=df.index
        )
        
        # è®¡ç®—ç»¼åˆç£¨æŸæŒ‡æ•°
        weights = {'avg_rms_roughness': 0.3, 'max_notch_depth': 0.3,
                  'avg_gradient_energy': 0.2, 'tear_shear_area_ratio': 0.2}
        
        wear_index = np.zeros(len(df))
        for feat in available:
            weight = weights.get(feat, 0.25)
            wear_index += df_norm[feat].values * weight
        
        # 1. ç»¼åˆç£¨æŸæŒ‡æ•°ï¼ˆåŸå§‹ + å¹³æ»‘ï¼‰
        ax1 = axes[0, 0]
        
        # åŸå§‹æ•°æ®ï¼ˆåŠé€æ˜ç»†çº¿ï¼‰
        ax1.plot(df['frame_id'], wear_index, color='darkred', 
                linewidth=1, alpha=0.3, label='åŸå§‹æ•°æ®')
        
        # å¹³æ»‘å¤„ç†
        from scipy.signal import savgol_filter
        window = min(51, len(wear_index)//10*2+1)
        if window >= 5 and len(wear_index) > window:
            wear_index_smooth = savgol_filter(wear_index, window_length=window, polyorder=3)
            # å¹³æ»‘æ›²çº¿ï¼ˆåŠ ç²—ï¼‰
            ax1.plot(df['frame_id'], wear_index_smooth, color='darkred', 
                    linewidth=3, alpha=1.0, label='å¹³æ»‘æ›²çº¿')
            ax1.fill_between(df['frame_id'], 0, wear_index_smooth, alpha=0.2, color='red')
        else:
            # æ•°æ®å¤ªå°‘ï¼Œä¸å¹³æ»‘
            ax1.plot(df['frame_id'], wear_index, color='darkred', linewidth=2, label='ç£¨æŸæŒ‡æ•°')
            ax1.fill_between(df['frame_id'], 0, wear_index, alpha=0.3, color='red')
        
        ax1.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
        ax1.set_ylabel('ç»¼åˆç£¨æŸæŒ‡æ•° (0-1)', fontsize=12, fontweight='bold')
        ax1.set_title('ç»¼åˆç£¨æŸæŒ‡æ•°ï¼ˆç»†çº¿=åŸå§‹ï¼Œç²—çº¿=å¹³æ»‘ï¼‰', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        ax1.axhline(y=0.7, color='orange', linestyle='--', linewidth=2, label='è­¦æˆ’çº¿', alpha=0.8)
        ax1.legend(fontsize=10)
        
        # 2. å„ç‰¹å¾è´¡çŒ®åº¦ï¼ˆåŸå§‹ + å¹³æ»‘ï¼‰
        ax2 = axes[0, 1]
        feature_labels = {
            'avg_rms_roughness': 'RMSç²—ç³™åº¦',
            'max_notch_depth': 'ç¼ºå£æ·±åº¦',
            'avg_gradient_energy': 'æ¢¯åº¦èƒ½é‡',
            'tear_shear_area_ratio': 'æ’•è£‚é¢å æ¯”'
        }
        for feat in available:
            weight = weights.get(feat, 0.25)
            contribution = df_norm[feat].values * weight
            
            # åŸå§‹æ•°æ®ï¼ˆåŠé€æ˜ç»†çº¿ï¼‰
            ax2.plot(df['frame_id'], contribution, 
                    linewidth=0.8, alpha=0.3)
            
            # å¹³æ»‘æ›²çº¿ï¼ˆåŠ ç²—ï¼‰
            if window >= 5 and len(contribution) > window:
                contribution_smooth = savgol_filter(contribution, window_length=window, polyorder=3)
                ax2.plot(df['frame_id'], contribution_smooth,
                        label=feature_labels.get(feat, feat), 
                        linewidth=2.5, alpha=1.0)
            else:
                ax2.plot(df['frame_id'], contribution, 
                        label=feature_labels.get(feat, feat), 
                        linewidth=1.5, alpha=0.8)
        
        ax2.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
        ax2.set_ylabel('è´¡çŒ®åº¦', fontsize=12, fontweight='bold')
        ax2.set_title('å„ç‰¹å¾è´¡çŒ®ï¼ˆç»†çº¿=åŸå§‹ï¼Œç²—çº¿=å¹³æ»‘ï¼‰', fontsize=14, fontweight='bold')
        ax2.legend(fontsize=9)
        ax2.grid(True, alpha=0.3)
        
        # 3. ç£¨æŸé˜¶æ®µåˆ¤æ–­
        ax3 = axes[1, 0]
        stages = []
        for wi in wear_index:
            if wi < 0.3:
                stages.append(0)
            elif wi < 0.6:
                stages.append(1)
            else:
                stages.append(2)
        
        colors = ['green' if s == 0 else 'orange' if s == 1 else 'red' for s in stages]
        ax3.scatter(df['frame_id'], wear_index, c=colors, s=20, alpha=0.6)
        ax3.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
        ax3.set_ylabel('ç»¼åˆç£¨æŸæŒ‡æ•°', fontsize=12, fontweight='bold')
        ax3.set_title('ç£¨æŸé˜¶æ®µåˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax3.axhline(y=0.3, color='green', linestyle='--', alpha=0.5, label='è½»åº¦é˜ˆå€¼')
        ax3.axhline(y=0.6, color='orange', linestyle='--', alpha=0.5, label='ä¸­åº¦é˜ˆå€¼')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ç£¨æŸç»Ÿè®¡
        ax4 = axes[1, 1]
        stage_counts = [stages.count(0), stages.count(1), stages.count(2)]
        colors_bar = ['green', 'orange', 'red']
        bars = ax4.bar(['è½»åº¦ç£¨æŸ', 'ä¸­åº¦ç£¨æŸ', 'ä¸¥é‡ç£¨æŸ'], stage_counts, color=colors_bar, alpha=0.7)
        ax4.set_ylabel('å¸§æ•°', fontsize=12, fontweight='bold')
        ax4.set_title('ç£¨æŸé˜¶æ®µç»Ÿè®¡', fontsize=14, fontweight='bold')
        ax4.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            if height > 0:
                ax4.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height)}\n({height/len(df)*100:.1f}%)',
                        ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        plt.suptitle(f'{self.analysis_name} - æ¨èç£¨æŸæŒ‡æ ‡åˆ†æ', 
                    fontsize=18, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_feature_importance(self, importance_df: pd.DataFrame, save_path: str):
        """å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§æ’åº"""
        if len(importance_df) == 0:
            print("è­¦å‘Š: æ— ç‰¹å¾é‡è¦æ€§æ•°æ®ï¼Œè·³è¿‡")
            return
        
        fig, axes = plt.subplots(1, 3, figsize=(20, 6))
        
        # 1. ç»¼åˆé‡è¦æ€§å¾—åˆ†
        ax1 = axes[0]
        top_features = importance_df.head(10)
        colors = plt.cm.RdYlGn(top_features['importance_score'] / top_features['importance_score'].max())
        bars = ax1.barh(range(len(top_features)), top_features['importance_score'], color=colors)
        ax1.set_yticks(range(len(top_features)))
        ax1.set_yticklabels(top_features['feature'], fontsize=10)
        ax1.set_xlabel('ç»¼åˆé‡è¦æ€§å¾—åˆ†', fontsize=12, fontweight='bold')
        ax1.set_title('Top 10 æœ€é‡è¦ç‰¹å¾', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3, axis='x')
        ax1.invert_yaxis()
        
        # 2. å˜å¼‚ç³»æ•° vs å•è°ƒæ€§
        ax2 = axes[1]
        scatter = ax2.scatter(importance_df['cv'], importance_df['monotonicity'], 
                             s=importance_df['importance_score']*200, 
                             c=importance_df['importance_score'], 
                             cmap='RdYlGn', alpha=0.6, edgecolors='black', linewidth=0.5)
        
        # æ ‡æ³¨top 5
        for idx, row in importance_df.head(5).iterrows():
            ax2.annotate(row['feature'], (row['cv'], row['monotonicity']), 
                        fontsize=8, ha='right', alpha=0.8)
        
        ax2.set_xlabel('å˜å¼‚ç³»æ•° (CV)', fontsize=12, fontweight='bold')
        ax2.set_ylabel('å•è°ƒæ€§ (|Spearmanç›¸å…³|)', fontsize=12, fontweight='bold')
        ax2.set_title('ç‰¹å¾é‡è¦æ€§äºŒç»´åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=ax2, label='é‡è¦æ€§å¾—åˆ†')
        
        # 3. å„ç»´åº¦ç‰¹å¾æ•°é‡
        ax3 = axes[2]
        group_counts = importance_df['group'].value_counts()
        colors_group = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']
        ax3.pie(group_counts.values, labels=group_counts.index, autopct='%1.1f%%',
               colors=colors_group, startangle=90)
        ax3.set_title('ç‰¹å¾ç»´åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        
        plt.suptitle(f'{self.analysis_name} - ç‰¹å¾é‡è¦æ€§åˆ†æ', 
                    fontsize=18, fontweight='bold', y=1.02)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_composite_indicators_comparison(self, df: pd.DataFrame, save_path: str):
        """å¯è§†åŒ–3ç§ç»¼åˆæŒ‡æ ‡çš„å¯¹æ¯”"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # å½’ä¸€åŒ–åˆ°0-1ä¾¿äºå¯¹æ¯”
        scaler = MinMaxScaler()
        
        scores = {
            'weighted_score': 'åŠ æƒå¹³å‡æ³•',
            'pca_score': 'PCAä¸»æˆåˆ†æ³•',
            'overall_score': 'å¤šç»´åº¦æ³•'
        }
        
        # æ£€æŸ¥å“ªäº›å¾—åˆ†å¯ç”¨
        available_scores = {k: v for k, v in scores.items() if k in df.columns}
        
        if len(available_scores) == 0:
            print("è­¦å‘Š: æ— ç»¼åˆæŒ‡æ ‡æ•°æ®ï¼Œè·³è¿‡")
            return
        
        # 1. ä¸‰ç§æ–¹æ³•å¯¹æ¯”æ›²çº¿ï¼ˆåŸå§‹ + å¹³æ»‘ï¼‰
        ax1 = axes[0, 0]
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # è“ã€æ©™ã€ç»¿
        
        for idx, (score_name, score_label) in enumerate(available_scores.items()):
            score_values = df[score_name].values
            # å½’ä¸€åŒ–åˆ°0-1
            if score_values.max() > score_values.min():
                score_norm = (score_values - score_values.min()) / (score_values.max() - score_values.min())
            else:
                score_norm = score_values
            
            color = colors[idx % len(colors)]
            
            # ç»˜åˆ¶åŸå§‹æ•°æ®ï¼ˆåŠé€æ˜ï¼‰
            ax1.plot(df['frame_id'], score_norm, color=color, 
                    linewidth=0.8, alpha=0.3, linestyle='-')
            
            # å¹³æ»‘å¤„ç†
            window = min(51, len(score_norm)//10*2+1)
            if window >= 5:
                from scipy.signal import savgol_filter
                score_smooth = savgol_filter(score_norm, window_length=window, polyorder=3)
                # ç»˜åˆ¶å¹³æ»‘æ›²çº¿
                ax1.plot(df['frame_id'], score_smooth, color=color, 
                        label=score_label, linewidth=2.5, alpha=1.0)
            else:
                ax1.plot(df['frame_id'], score_norm, color=color, 
                        label=score_label, linewidth=2, alpha=0.8)
        
        ax1.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
        ax1.set_ylabel('å½’ä¸€åŒ–å¾—åˆ† (0-1)', fontsize=12, fontweight='bold')
        ax1.set_title('3ç§ç»¼åˆæŒ‡æ ‡å¯¹æ¯”ï¼ˆç»†çº¿=åŸå§‹ï¼Œç²—çº¿=å¹³æ»‘ï¼‰', fontsize=14, fontweight='bold')
        ax1.legend(fontsize=11, loc='best')
        ax1.grid(True, alpha=0.3)
        
        # 2. ç›¸å…³æ€§çŸ©é˜µ
        ax2 = axes[0, 1]
        score_cols = list(available_scores.keys())
        if len(score_cols) >= 2:
            corr_matrix = df[score_cols].corr()
            sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='RdYlGn', 
                       center=0.5, vmin=0, vmax=1, square=True, ax=ax2, 
                       cbar_kws={'label': 'ç›¸å…³ç³»æ•°'})
            ax2.set_title('ç»¼åˆæŒ‡æ ‡ç›¸å…³æ€§', fontsize=14, fontweight='bold')
        else:
            ax2.text(0.5, 0.5, 'æ•°æ®ä¸è¶³', ha='center', va='center', fontsize=14)
            ax2.axis('off')
        
        # 3. åˆ†å¸ƒå¯¹æ¯”ï¼ˆç®±çº¿å›¾ï¼‰
        ax3 = axes[1, 0]
        box_data = [df[score_name].values for score_name in available_scores.keys()]
        box_labels = list(available_scores.values())
        bp = ax3.boxplot(box_data, labels=box_labels, patch_artist=True)
        for patch, color in zip(bp['boxes'], ['lightblue', 'lightgreen', 'lightyellow']):
            patch.set_facecolor(color)
        ax3.set_ylabel('å¾—åˆ†', fontsize=12, fontweight='bold')
        ax3.set_title('ç»¼åˆæŒ‡æ ‡åˆ†å¸ƒå¯¹æ¯”', fontsize=14, fontweight='bold')
        ax3.grid(True, alpha=0.3, axis='y')
        
        # 4. å˜åŒ–ç‡å¯¹æ¯”
        ax4 = axes[1, 1]
        change_rates = []
        for score_name in available_scores.keys():
            values = df[score_name].values
            if len(values) > 10:
                first = np.mean(values[:len(values)//10])
                last = np.mean(values[-len(values)//10:])
                if first != 0:
                    change_rate = ((last - first) / first) * 100
                else:
                    change_rate = 0
                change_rates.append(change_rate)
            else:
                change_rates.append(0)
        
        colors_bar = ['blue' if cr > 0 else 'red' for cr in change_rates]
        bars = ax4.bar(box_labels, change_rates, color=colors_bar, alpha=0.7)
        ax4.set_ylabel('å˜åŒ–ç‡ (%)', fontsize=12, fontweight='bold')
        ax4.set_title('é¦–å°¾å˜åŒ–ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax4.axhline(y=0, color='black', linestyle='--', linewidth=1)
        ax4.grid(True, alpha=0.3, axis='y')
        
        for bar, rate in zip(bars, change_rates):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{rate:.1f}%', ha='center', va='bottom' if height > 0 else 'top',
                    fontsize=10, fontweight='bold')
        
        plt.suptitle(f'{self.analysis_name} - ç»¼åˆæŒ‡æ ‡æ–¹æ³•å¯¹æ¯”', 
                    fontsize=18, fontweight='bold', y=1.00)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_multi_dimension_evolution(self, df: pd.DataFrame, n_coils: int, save_path: str):
        """å¯è§†åŒ–å¤šç»´åº¦å¾—åˆ†çš„æ¼”å˜ï¼ˆé›·è¾¾å›¾ï¼‰"""
        dimensions = ['geometric_score', 'texture_score', 'frequency_score', 'distribution_score']
        dim_labels = ['å‡ ä½•ç‰¹å¾', 'çº¹ç†ç‰¹å¾', 'é¢‘åŸŸç‰¹å¾', 'ç»Ÿè®¡åˆ†å¸ƒ']
        
        # æ£€æŸ¥å“ªäº›ç»´åº¦å¯ç”¨
        available_dims = [d for d in dimensions if d in df.columns]
        available_labels = [dim_labels[i] for i, d in enumerate(dimensions) if d in available_dims]
        
        if len(available_dims) < 2:
            print("è­¦å‘Š: ç»´åº¦å¾—åˆ†æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
            return
        
        # é€‰æ‹©3ä¸ªä»£è¡¨æ€§é˜¶æ®µï¼šå¼€å§‹ã€ä¸­æœŸã€ç»“æŸ
        coil_ids = sorted(df['coil_id'].unique())
        if len(coil_ids) >= 3:
            representative_coils = [coil_ids[0], coil_ids[len(coil_ids)//2], coil_ids[-1]]
            stage_labels = ['å¼€å§‹é˜¶æ®µ', 'ä¸­æœŸé˜¶æ®µ', 'ç»“æŸé˜¶æ®µ']
        else:
            representative_coils = coil_ids
            stage_labels = [f'ç¬¬{int(c)}å·' for c in representative_coils]
        
        fig, axes = plt.subplots(1, len(representative_coils), figsize=(6*len(representative_coils), 6),
                                subplot_kw=dict(projection='polar'))
        
        if len(representative_coils) == 1:
            axes = [axes]
        
        angles = np.linspace(0, 2 * np.pi, len(available_dims), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆ
        
        for idx, (coil_id, stage_label) in enumerate(zip(representative_coils, stage_labels)):
            ax = axes[idx]
            
            # è¯¥å·çš„å¹³å‡å¾—åˆ†
            coil_data = df[df['coil_id'] == coil_id]
            values = [coil_data[dim].mean() for dim in available_dims]
            values += values[:1]  # é—­åˆ
            
            # ç»˜åˆ¶é›·è¾¾å›¾
            ax.plot(angles, values, 'o-', linewidth=2, label=stage_label, color='darkblue')
            ax.fill(angles, values, alpha=0.25, color='blue')
            
            # è®¾ç½®æ ‡ç­¾
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(available_labels, fontsize=11)
            ax.set_ylim(0, 1)
            ax.set_title(f'{stage_label}\nç¬¬{int(coil_id)}å·', fontsize=13, fontweight='bold', pad=20)
            ax.grid(True)
        
        plt.suptitle(f'{self.analysis_name} - å¤šç»´åº¦ç£¨æŸæ¼”å˜åˆ†æ', 
                    fontsize=18, fontweight='bold', y=1.05)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_feature_contribution_heatmap(self, pca_result: dict, save_path: str):
        """å¯è§†åŒ–ç‰¹å¾å¯¹ä¸»æˆåˆ†çš„è´¡çŒ®çƒ­åŠ›å›¾"""
        loadings = pca_result.get('loadings', pd.DataFrame())
        
        if len(loadings) == 0:
            print("è­¦å‘Š: PCAè½½è·æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
            return
        
        fig, ax = plt.subplots(figsize=(12, max(8, len(loadings)*0.3)))
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        sns.heatmap(loadings, annot=True, fmt='.2f', cmap='RdBu_r', 
                   center=0, vmin=-1, vmax=1, cbar_kws={'label': 'è½½è·å€¼'},
                   ax=ax, linewidths=0.5)
        
        ax.set_xlabel('ä¸»æˆåˆ†', fontsize=13, fontweight='bold')
        ax.set_ylabel('ç‰¹å¾åç§°', fontsize=13, fontweight='bold')
        ax.set_title(f'{self.analysis_name} - ç‰¹å¾å¯¹ä¸»æˆåˆ†çš„è´¡çŒ®\n(çº¢è‰²=æ­£è´¡çŒ®, è“è‰²=è´Ÿè´¡çŒ®)', 
                    fontsize=16, fontweight='bold', pad=20)
        
        # æ·»åŠ è§£é‡Šæ–¹å·®
        if 'explained_variance_ratio' in pca_result and len(pca_result['explained_variance_ratio']) > 0:
            explained_var = pca_result['explained_variance_ratio']
            var_text = 'è§£é‡Šæ–¹å·®: ' + ', '.join([f'PC{i+1}={v*100:.1f}%' 
                                                 for i, v in enumerate(explained_var)])
            plt.figtext(0.5, 0.02, var_text, ha='center', fontsize=11, style='italic')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_key_features_samples(self, df: pd.DataFrame, importance_df: pd.DataFrame, save_dir: str):
        """å¯è§†åŒ–å…³é”®ç‰¹å¾çš„æŠ½æ ·å±•ç¤º"""
        if len(importance_df) == 0:
            print("è­¦å‘Š: æ— ç‰¹å¾é‡è¦æ€§æ•°æ®ï¼Œè·³è¿‡æŠ½æ ·å±•ç¤º")
            return
        
        # é€‰æ‹©top 5ç‰¹å¾
        top_features = importance_df.head(5)['feature'].tolist()
        
        # åŸºäºç»¼åˆå¾—åˆ†é€‰æ‹©3ä¸ªä»£è¡¨å¸§ï¼šä½/ä¸­/é«˜ç£¨æŸ
        if 'overall_score' in df.columns:
            score_col = 'overall_score'
        elif 'weighted_score' in df.columns:
            score_col = 'weighted_score'
        else:
            print("è­¦å‘Š: æ— ç»¼åˆå¾—åˆ†ï¼Œä½¿ç”¨frame_idé‡‡æ ·")
            score_col = 'frame_id'
        
        # æŒ‰å¾—åˆ†æ’åºï¼Œå–ä½ã€ä¸­ã€é«˜ä¸‰ä¸ªåˆ†ä½æ•°
        df_sorted = df.sort_values(score_col)
        low_idx = len(df_sorted) // 6
        mid_idx = len(df_sorted) // 2
        high_idx = len(df_sorted) * 5 // 6
        
        sample_indices = [low_idx, mid_idx, high_idx]
        sample_labels = ['ä½ç£¨æŸ', 'ä¸­åº¦ç£¨æŸ', 'é«˜ç£¨æŸ']
        
        for feature in top_features:
            if feature not in df.columns:
                continue
            
            fig, axes = plt.subplots(1, 3, figsize=(18, 5))
            
            for idx, (sample_idx, label) in enumerate(zip(sample_indices, sample_labels)):
                ax = axes[idx]
                
                sample_row = df_sorted.iloc[sample_idx]
                frame_id = int(sample_row['frame_id'])
                feature_value = sample_row[feature]
                
                # ç»˜åˆ¶è¯¥ç‰¹å¾çš„æ•´ä½“æ›²çº¿ï¼Œå¹¶é«˜äº®å½“å‰ç‚¹
                ax.plot(df['frame_id'], df[feature], color='lightgray', linewidth=1, alpha=0.5)
                ax.scatter([frame_id], [feature_value], color='red', s=200, zorder=5, 
                          marker='*', edgecolors='black', linewidth=1.5)
                
                ax.set_xlabel('å¸§ç¼–å·', fontsize=11, fontweight='bold')
                ax.set_ylabel(feature, fontsize=11, fontweight='bold')
                ax.set_title(f'{label}\nå¸§{frame_id}: {feature_value:.3f}', 
                            fontsize=12, fontweight='bold')
                ax.grid(True, alpha=0.3)
            
            plt.suptitle(f'{self.analysis_name} - {feature} ç‰¹å¾æ¼”å˜ä¸å…¸å‹æ ·æœ¬', 
                        fontsize=16, fontweight='bold')
            plt.tight_layout()
            
            # æ–‡ä»¶åå®‰å…¨åŒ–
            safe_feature_name = feature.replace('/', '_').replace('\\', '_')
            feature_save_path = os.path.join(save_dir, f'{safe_feature_name}_samples.png')
            plt.savefig(feature_save_path, dpi=150, bbox_inches='tight')
            plt.close()
        
        print(f"å·²ä¿å­˜: {save_dir} (å…±{len(top_features)}ä¸ªç‰¹å¾)")
    
    def _detect_cycles_advanced(self, values, min_drop=1.5, min_cycle_length=100):
        """
        é«˜çº§å‘¨æœŸæ£€æµ‹ï¼ˆç”¨äºå¹³æ»‘è¶‹åŠ¿åˆ†æï¼‰
        
        Args:
            values: ä¿¡å·å€¼
            min_drop: æœ€å°ä¸‹é™å¹…åº¦ï¼ˆæ ‡å‡†å·®å€æ•°ï¼‰
            min_cycle_length: æœ€å°å‘¨æœŸé•¿åº¦
            
        Returns:
            å‘¨æœŸåˆ—è¡¨ [(start, end), ...]
        """
        # å¯»æ‰¾å±€éƒ¨å³°å€¼
        peaks, _ = find_peaks(values, distance=min_cycle_length//2)
        
        if len(peaks) < 2:
            return [(0, len(values)-1)]
        
        # åŸºäºå³°å€¼é—´çš„è°·åº•åˆ†å‰²å‘¨æœŸ
        cycles = []
        valleys = []
        
        for i in range(len(peaks)-1):
            start_peak = peaks[i]
            end_peak = peaks[i+1]
            
            # æ‰¾åˆ°ä¸¤å³°ä¹‹é—´çš„æœ€ä½ç‚¹
            valley_segment = values[start_peak:end_peak+1]
            valley_idx = start_peak + np.argmin(valley_segment)
            
            # æ£€æŸ¥ä¸‹é™å¹…åº¦
            drop = values[start_peak] - values[valley_idx]
            if drop > min_drop * np.std(values):
                start_idx = 0 if i == 0 else valleys[-1]
                cycles.append((start_idx, valley_idx))
                valleys.append(valley_idx)
        
        # æ·»åŠ æœ€åä¸€æ®µ
        if len(cycles) > 0:
            cycles.append((cycles[-1][1], len(values)-1))
        else:
            cycles.append((0, len(values)-1))
        
        # è¿‡æ»¤å¤ªçŸ­çš„å‘¨æœŸ
        cycles = [(s, e) for s, e in cycles if e - s >= min_cycle_length]
        
        if len(cycles) == 0:
            cycles = [(0, len(values)-1)]
        
        return cycles
    
    def _plot_smooth_longterm_trends(self, df: pd.DataFrame, save_path: str):
        """
        ç»˜åˆ¶å¹³æ»‘é•¿æœŸè¶‹åŠ¿åˆ†æï¼ˆ3ç§æ–¹æ³•å¯¹æ¯”ï¼‰
        
        åŒ…å«ï¼š
        1. ç§»åŠ¨æœ€å¤§å€¼åŒ…ç»œçº¿æ³•
        2. å‘¨æœŸå³°å€¼æ ·æ¡æ’å€¼æ³•
        3. å…¨å±€äºŒæ¬¡æ‹Ÿåˆæ³•
        """
        print("\nç”Ÿæˆå¹³æ»‘é•¿æœŸè¶‹åŠ¿åˆ†æ...")
        
        wear_features = {
            'avg_rms_roughness': 'å¹³å‡RMSç²—ç³™åº¦',
            'max_notch_depth': 'æœ€å¤§ç¼ºå£æ·±åº¦',
            'right_peak_density': 'å³ä¾§å³°å¯†åº¦'
        }
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        fig = plt.figure(figsize=(20, 12))
        gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.25)
        
        for idx, (feature, label) in enumerate(wear_features.items()):
            if feature not in df.columns:
                continue
            
            # å·¦ä¾§ï¼šåŸå§‹æ•°æ® + ä¸‰ç§å¹³æ»‘æ–¹æ³•
            ax_left = fig.add_subplot(gs[idx, 0])
            
            values = df[feature].values
            frames = df['frame_id'].values
            
            # åŸå§‹æ•°æ®ï¼ˆæµ…è‰²ï¼‰
            ax_left.plot(frames, values, '-', alpha=0.15, color='gray', 
                        linewidth=0.5, label='åŸå§‹æ•°æ®')
            
            # === æ–¹æ³•1ï¼šç§»åŠ¨æœ€å¤§å€¼åŒ…ç»œçº¿ ===
            window = min(200, len(values)//5)
            max_envelope = maximum_filter1d(values, size=window, mode='nearest')
            smooth_env = max_envelope  # é»˜è®¤å€¼ï¼Œå¦‚æœåç»­å¤„ç†å¤±è´¥åˆ™ä½¿ç”¨åŸå§‹åŒ…ç»œçº¿
            if len(max_envelope) > 51:
                smooth_env = savgol_filter(max_envelope, 
                                          window_length=min(51, len(max_envelope)//2*2+1), 
                                          polyorder=3)
            if len(smooth_env) > 0:
                ax_left.plot(frames, smooth_env, '-', color='orange', 
                            linewidth=2.5, label='æ–¹æ³•1:åŒ…ç»œçº¿', alpha=0.8)
            
            # === æ–¹æ³•2ï¼šå‘¨æœŸå³°å€¼æ ·æ¡æ’å€¼ ===
            cycle_frames = []
            cycle_maxes = []
            cycles = []
            try:
                cycles = self._detect_cycles_advanced(values)
                
                for start, end in cycles:
                    if end > start:
                        max_idx = start + np.argmax(values[start:end+1])
                        cycle_frames.append(frames[max_idx])
                        cycle_maxes.append(values[max_idx])
                
                if len(cycle_frames) > 3:
                    spline = UnivariateSpline(cycle_frames, cycle_maxes, 
                                              k=min(3, len(cycle_frames)-1), s=5)
                    smooth_frames = np.linspace(frames[0], frames[-1], 500)
                    ax_left.plot(smooth_frames, spline(smooth_frames), '-', 
                                color='green', linewidth=2.5, label='æ–¹æ³•2:æ ·æ¡', alpha=0.8)
            except Exception as e:
                print(f"  è­¦å‘Š: æ ·æ¡æ’å€¼å¤±è´¥ ({feature}): {e}")
            
            # === æ–¹æ³•3ï¼šå…¨å±€äºŒæ¬¡æ‹Ÿåˆ ===
            cycle_key_frames = []
            cycle_key_values = []
            try:
                for start, end in cycles:
                    if end - start > 10:
                        window_size = min(50, (end - start) // 2)
                        if window_size >= 3:
                            seg_smooth = uniform_filter1d(values[start:end+1], size=window_size)
                            max_idx = start + np.argmax(seg_smooth)
                            cycle_key_frames.append(frames[max_idx])
                            cycle_key_values.append(values[max_idx])
                
                if len(cycle_key_frames) > 3:
                    z = np.polyfit(cycle_key_frames, cycle_key_values, 2)
                    poly_trend = np.poly1d(z)
                    ax_left.plot(frames, poly_trend(frames), '-', 
                                color='purple', linewidth=2.5, label='æ–¹æ³•3:äºŒæ¬¡æ‹Ÿåˆ', alpha=0.8)
            except Exception as e:
                print(f"  è­¦å‘Š: äºŒæ¬¡æ‹Ÿåˆå¤±è´¥ ({feature}): {e}")
            
            ax_left.set_xlabel('å¸§ç¼–å·', fontweight='bold', fontsize=11)
            ax_left.set_ylabel(label, fontweight='bold', fontsize=11)
            ax_left.set_title(f'{label}\nä¸‰ç§å¹³æ»‘æ–¹æ³•å¯¹æ¯”', fontsize=13, fontweight='bold')
            ax_left.legend(fontsize=9, loc='best')
            ax_left.grid(True, alpha=0.3)
            
            # å³ä¾§ï¼šè¶‹åŠ¿æ–œç‡å¯¹æ¯”
            ax_right = fig.add_subplot(gs[idx, 1])
            
            slopes = []
            methods = []
            colors_bar = []
            
            # æ–¹æ³•1æ–œç‡
            if len(smooth_env) > 2:
                z1 = np.polyfit(frames, smooth_env, 1)
                slopes.append(z1[0])
                methods.append('åŒ…ç»œçº¿')
                colors_bar.append('orange')
            
            # æ–¹æ³•2æ–œç‡
            if len(cycle_frames) > 3:
                z2 = np.polyfit(cycle_frames, cycle_maxes, 1)
                slopes.append(z2[0])
                methods.append('æ ·æ¡')
                colors_bar.append('green')
            
            # æ–¹æ³•3æ–œç‡
            if len(cycle_key_frames) > 3:
                z3 = np.polyfit(cycle_key_frames, cycle_key_values, 1)
                slopes.append(z3[0])
                methods.append('äºŒæ¬¡æ‹Ÿåˆ')
                colors_bar.append('purple')
            
            if slopes:
                bars = ax_right.barh(methods, slopes, color=colors_bar, alpha=0.7, edgecolor='black', linewidth=1.5)
                ax_right.axvline(x=0, color='black', linestyle='--', linewidth=1)
                ax_right.set_xlabel('è¶‹åŠ¿æ–œç‡', fontweight='bold', fontsize=11)
                ax_right.set_title(f'{label}\næ–¹æ³•æ–œç‡å¯¹æ¯”', fontsize=13, fontweight='bold')
                ax_right.grid(True, alpha=0.3, axis='x')
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, slope in zip(bars, slopes):
                    width = bar.get_width()
                    ax_right.text(width, bar.get_y() + bar.get_height()/2,
                                f'{slope:.2e}', ha='left' if width > 0 else 'right',
                                va='center', fontsize=10, fontweight='bold')
        
        plt.suptitle(f'{self.analysis_name} - å¹³æ»‘é•¿æœŸè¶‹åŠ¿åˆ†æï¼ˆ3ç§æ–¹æ³•å¯¹æ¯”ï¼‰', 
                    fontsize=18, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _plot_deep_trend_analysis(self, df: pd.DataFrame, viz_dir: str):
        """
        æ·±åº¦è¶‹åŠ¿åˆ†æï¼ˆ3ä¸ªå­å›¾ï¼‰
        
        åŒ…å«ï¼š
        1. å³°å€¼åŒ…ç»œçº¿åˆ†æ
        2. åˆ†æ®µè¶‹åŠ¿åˆ†æ
        3. ä½é€šæ»¤æ³¢é•¿æœŸè¶‹åŠ¿
        """
        print("\nç”Ÿæˆæ·±åº¦è¶‹åŠ¿åˆ†æ...")
        
        key_features_deep = {
            'avg_rms_roughness': 'å¹³å‡RMSç²—ç³™åº¦',
            'max_notch_depth': 'æœ€å¤§ç¼ºå£æ·±åº¦',
            'right_peak_density': 'å³ä¾§å³°å¯†åº¦',
            'avg_gradient_energy': 'å¹³å‡æ¢¯åº¦èƒ½é‡'
        }
        
        available_features = {k: v for k, v in key_features_deep.items() if k in df.columns}
        
        if len(available_features) == 0:
            print("  è­¦å‘Š: æ— å¯ç”¨ç‰¹å¾ï¼Œè·³è¿‡æ·±åº¦è¶‹åŠ¿åˆ†æ")
            return
        
        # === 1. å³°å€¼åŒ…ç»œçº¿åˆ†æ ===
        print("  ç”Ÿæˆå³°å€¼åŒ…ç»œçº¿åˆ†æ...")
        
        def extract_envelope(signal, window=300):
            """æå–å³°å€¼åŒ…ç»œçº¿"""
            envelope = []
            frames_env = []
            
            for i in range(0, len(signal), max(1, window//2)):
                window_data = signal[i:min(i+window, len(signal))]
                if len(window_data) > 0:
                    envelope.append(np.max(window_data))
                    frames_env.append(i + window//2)
            
            return np.array(frames_env), np.array(envelope)
        
        fig, axes = plt.subplots(2, 2, figsize=(18, 10))
        axes = axes.flatten()
        
        for idx, (feature, label) in enumerate(list(available_features.items())[:4]):
            ax = axes[idx]
            
            values = df[feature].values
            frames = df['frame_id'].values
            
            # åŸå§‹æ•°æ®
            ax.plot(frames, values, 'o', alpha=0.1, markersize=2, color='gray', label='åŸå§‹æ•°æ®')
            
            # æå–å³°å€¼åŒ…ç»œçº¿
            window_size = min(300, len(values)//5)
            env_frames, envelope = extract_envelope(values, window=window_size)
            ax.plot(env_frames, envelope, 'ro-', linewidth=2, markersize=4, 
                   label='å³°å€¼åŒ…ç»œçº¿', alpha=0.7)
            
            # æ‹ŸåˆåŒ…ç»œçº¿è¶‹åŠ¿
            if len(envelope) > 2:
                z = np.polyfit(env_frames, envelope, 1)
                trend = np.poly1d(z)
                ax.plot(env_frames, trend(env_frames), 'b--', linewidth=2.5, 
                       label=f'è¶‹åŠ¿(æ–œç‡={z[0]:.6f})')
                
                # åˆ¤æ–­è¶‹åŠ¿
                if z[0] > 1e-6:
                    trend_text = f"â†‘ é€’å¢\næ–œç‡: {z[0]:.6f}"
                    color = 'lightgreen'
                elif z[0] < -1e-6:
                    trend_text = f"â†“ é€’å‡\næ–œç‡: {z[0]:.6f}"
                    color = 'lightcoral'
                else:
                    trend_text = f"â†’ å¹³ç¨³\næ–œç‡: {z[0]:.6f}"
                    color = 'lightyellow'
                
                ax.text(0.02, 0.98, trend_text,
                       transform=ax.transAxes, fontsize=11, verticalalignment='top',
                       fontweight='bold',
                       bbox=dict(boxstyle='round', facecolor=color, alpha=0.8, 
                                edgecolor='black', linewidth=1.5))
            
            ax.set_xlabel('å¸§ç¼–å·', fontweight='bold', fontsize=11)
            ax.set_ylabel(label, fontweight='bold', fontsize=11)
            ax.set_title(f'{label}\nå³°å€¼åŒ…ç»œçº¿åˆ†æ', fontsize=12, fontweight='bold')
            ax.legend(fontsize=9)
            ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'{self.analysis_name} - å³°å€¼åŒ…ç»œçº¿æ·±åº¦åˆ†æ', 
                    fontsize=18, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'deep_envelope_analysis.png'), 
                   dpi=150, bbox_inches='tight')
        plt.close()
        
        # === 2. åˆ†æ®µè¶‹åŠ¿åˆ†æ ===
        print("  ç”Ÿæˆåˆ†æ®µè¶‹åŠ¿åˆ†æ...")
        
        def detect_change_points(signal, threshold=2.0):
            """æ£€æµ‹çªå˜ç‚¹"""
            diff = np.abs(np.diff(signal))
            mean_diff = np.mean(diff)
            std_diff = np.std(diff)
            change_points = np.where(diff > mean_diff + threshold * std_diff)[0]
            return change_points
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾æ£€æµ‹å˜ç‚¹
        first_feature = list(available_features.keys())[0]
        values_for_cp = df[first_feature].values
        change_points = detect_change_points(values_for_cp, threshold=1.5)
        
        # åŸºäºå˜ç‚¹åˆ†æ®µ
        segments = []
        start = 0
        for cp in change_points:
            if cp - start > 50:
                segments.append((start, cp))
                start = cp
        segments.append((start, len(values_for_cp)))
        
        fig, axes = plt.subplots(2, 2, figsize=(18, 10))
        axes = axes.flatten()
        
        for idx, (feature, label) in enumerate(list(available_features.items())[:4]):
            ax = axes[idx]
            
            values = df[feature].values
            frames = df['frame_id'].values
            
            # ç»˜åˆ¶åŸå§‹æ•°æ®
            ax.plot(frames, values, 'o', alpha=0.2, markersize=1, color='gray')
            
            # ä¸ºæ¯æ®µè®¡ç®—è¶‹åŠ¿
            colors = plt.cm.rainbow(np.linspace(0, 1, min(len(segments), 10)))
            segment_slopes = []
            
            for seg_idx, (start_idx, end_idx) in enumerate(segments[:10]):
                seg_frames = frames[start_idx:end_idx]
                seg_values = values[start_idx:end_idx]
                
                if len(seg_values) > 2:
                    z = np.polyfit(seg_frames, seg_values, 1)
                    trend = np.poly1d(z)
                    ax.plot(seg_frames, trend(seg_frames), '-', 
                           color=colors[seg_idx], linewidth=2.5, alpha=0.8)
                    segment_slopes.append(z[0])
            
            # ç»Ÿè®¡å„æ®µæ–œç‡
            if segment_slopes:
                avg_slope = np.mean(segment_slopes)
                positive_ratio = sum(1 for s in segment_slopes if s > 0) / len(segment_slopes)
                
                ax.text(0.02, 0.98, 
                       f'æ®µæ•°: {len(segment_slopes)}\n'
                       f'å¹³å‡æ–œç‡: {avg_slope:.6f}\n'
                       f'é€’å¢æ®µå æ¯”: {positive_ratio:.1%}',
                       transform=ax.transAxes, fontsize=10, verticalalignment='top',
                       fontweight='bold',
                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7, 
                                edgecolor='black', linewidth=1.5))
            
            ax.set_xlabel('å¸§ç¼–å·', fontweight='bold', fontsize=11)
            ax.set_ylabel(label, fontweight='bold', fontsize=11)
            ax.set_title(f'{label}\nåˆ†æ®µè¶‹åŠ¿ï¼ˆå‰10æ®µï¼‰', fontsize=12, fontweight='bold')
            ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'{self.analysis_name} - åˆ†æ®µè¶‹åŠ¿æ·±åº¦åˆ†æ', 
                    fontsize=18, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'deep_segment_analysis.png'), 
                   dpi=150, bbox_inches='tight')
        plt.close()
        
        # === 3. ä½é€šæ»¤æ³¢é•¿æœŸè¶‹åŠ¿ ===
        print("  ç”Ÿæˆä½é€šæ»¤æ³¢é•¿æœŸè¶‹åŠ¿...")
        
        fig, axes = plt.subplots(2, 2, figsize=(18, 10))
        axes = axes.flatten()
        
        for idx, (feature, label) in enumerate(list(available_features.items())[:4]):
            ax = axes[idx]
            
            values = df[feature].values
            frames = df['frame_id'].values
            
            # åŸå§‹æ•°æ®
            ax.plot(frames, values, '-', alpha=0.2, linewidth=0.5, color='gray', 
                   label='åŸå§‹æ•°æ®')
            
            # ç§»åŠ¨å¹³å‡ï¼ˆçª—å£=100ï¼‰
            window_ma = min(100, len(values)//10)
            if len(values) >= window_ma and window_ma >= 3:
                ma = uniform_filter1d(values, size=window_ma)
                ax.plot(frames, ma, 'b-', linewidth=2.5, 
                       label=f'ç§»åŠ¨å¹³å‡({window_ma})', alpha=0.8)
                
                # æ‹Ÿåˆé•¿æœŸè¶‹åŠ¿
                z = np.polyfit(frames, ma, 1)
                trend = np.poly1d(z)
                ax.plot(frames, trend(frames), 'r--', linewidth=3, 
                       label=f'é•¿æœŸè¶‹åŠ¿(æ–œç‡={z[0]:.6f})')
                
                # åˆ¤æ–­è¶‹åŠ¿
                if z[0] > 1e-6:
                    trend_text = f"âœ“ é•¿æœŸé€’å¢\næ–œç‡: {z[0]:.6f}"
                    color = 'lightgreen'
                elif z[0] < -1e-6:
                    trend_text = f"âœ— é•¿æœŸé€’å‡\næ–œç‡: {z[0]:.6f}"
                    color = 'lightcoral'
                else:
                    trend_text = f"â†’ é•¿æœŸå¹³ç¨³\næ–œç‡: {z[0]:.6f}"
                    color = 'lightyellow'
                
                ax.text(0.02, 0.98, trend_text,
                       transform=ax.transAxes, fontsize=11, verticalalignment='top',
                       fontweight='bold',
                       bbox=dict(boxstyle='round', facecolor=color, alpha=0.8,
                                edgecolor='black', linewidth=1.5))
            
            ax.set_xlabel('å¸§ç¼–å·', fontweight='bold', fontsize=11)
            ax.set_ylabel(label, fontweight='bold', fontsize=11)
            ax.set_title(f'{label}\nä½é€šæ»¤æ³¢åçš„é•¿æœŸè¶‹åŠ¿', fontsize=12, fontweight='bold')
            ax.legend(fontsize=9)
            ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'{self.analysis_name} - ä½é€šæ»¤æ³¢é•¿æœŸè¶‹åŠ¿åˆ†æ', 
                    fontsize=18, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(os.path.join(viz_dir, 'deep_longterm_filtered.png'), 
                   dpi=150, bbox_inches='tight')
        plt.close()
        
        print("âœ“ æ·±åº¦è¶‹åŠ¿åˆ†æå®Œæˆ")
    
    def _plot_white_patch_analysis(self, df: pd.DataFrame, save_path: str):
        """
        ç»˜åˆ¶æ’•è£‚é¢ç™½æ–‘åˆ†æå›¾
        
        é’ˆå¯¹ç”¨æˆ·è§‚å¯Ÿï¼šæ’•è£‚é¢ç™½è‰²æ–‘å—éšé’¢å·æ•°é‡å¢åŠ è€Œå¢å¤š
        å¯¹æ¯”4ç§æ£€æµ‹æ–¹æ³•çš„æ•ˆæœ
        """
        print("\nç”Ÿæˆæ’•è£‚é¢ç™½æ–‘åˆ†æ...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç™½æ–‘ç‰¹å¾
        white_patch_cols = [col for col in df.columns if col.startswith('white_')]
        if len(white_patch_cols) == 0:
            print("  è­¦å‘Š: æ•°æ®ä¸­æ²¡æœ‰ç™½æ–‘ç‰¹å¾ï¼Œè·³è¿‡")
            return
        
        fig = plt.figure(figsize=(22, 14))
        gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)
        
        methods = ['m1', 'm2', 'm3', 'm4']
        method_names = ['å›ºå®šé˜ˆå€¼', 'Otsuè‡ªé€‚åº”', 'ç›¸å¯¹äº®åº¦', 'å½¢æ€å­¦Top-Hat']
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
        
        # ç¬¬ä¸€è¡Œï¼šé¢ç§¯å æ¯”æ—¶åºæ›²çº¿
        for idx, (method, method_name, color) in enumerate(zip(methods, method_names, colors)):
            ax = fig.add_subplot(gs[0, idx])
            
            col_name = f'white_area_ratio_{method}'
            if col_name not in df.columns:
                continue
            
            values = df[col_name].values
            frames = df['frame_id'].values
            
            # åŸå§‹æ•°æ®
            ax.plot(frames, values, '-', alpha=0.2, color=color, linewidth=0.8)
            
            # å¹³æ»‘æ›²çº¿
            window = min(51, len(values)//10*2+1)
            if window >= 5:
                smoothed = savgol_filter(values, window_length=window, polyorder=3)
                ax.plot(frames, smoothed, '-', color=color, linewidth=2.5, label='å¹³æ»‘æ›²çº¿')
            
            # çº¿æ€§è¶‹åŠ¿
            z = np.polyfit(frames, values, 1)
            trend = np.poly1d(z)
            ax.plot(frames, trend(frames), '--', color='red', linewidth=2, alpha=0.7)
            
            # è®¡ç®—é¦–å°¾å˜åŒ–
            if len(values) > 10:
                first = np.mean(values[:len(values)//10])
                last = np.mean(values[-len(values)//10:])
                change = last - first
                change_pct = (change / (first + 1e-8)) * 100
                
                trend_text = f'å˜åŒ–: {change:+.1f}% ({change_pct:+.0f}%)'
                box_color = 'lightgreen' if change > 0 else 'lightcoral'
                
                ax.text(0.02, 0.98, trend_text, transform=ax.transAxes,
                       fontsize=10, verticalalignment='top', fontweight='bold',
                       bbox=dict(boxstyle='round', facecolor=box_color, alpha=0.7))
            
            ax.set_xlabel('å¸§ç¼–å·', fontsize=10, fontweight='bold')
            ax.set_ylabel('ç™½æ–‘é¢ç§¯å æ¯”(%)', fontsize=10, fontweight='bold')
            ax.set_title(f'{method_name}', fontsize=12, fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend(fontsize=8)
        
        # ç¬¬äºŒè¡Œï¼šæ–‘å—æ•°é‡æ—¶åºæ›²çº¿
        for idx, (method, method_name, color) in enumerate(zip(methods, method_names, colors)):
            ax = fig.add_subplot(gs[1, idx])
            
            col_name = f'white_patch_count_{method}'
            if col_name not in df.columns:
                continue
            
            values = df[col_name].values
            frames = df['frame_id'].values
            
            # åŸå§‹æ•°æ®
            ax.plot(frames, values, '-', alpha=0.2, color=color, linewidth=0.8)
            
            # å¹³æ»‘æ›²çº¿
            window = min(51, len(values)//10*2+1)
            if window >= 5:
                smoothed = savgol_filter(values, window_length=window, polyorder=3)
                ax.plot(frames, smoothed, '-', color=color, linewidth=2.5, label='å¹³æ»‘æ›²çº¿')
            
            # çº¿æ€§è¶‹åŠ¿
            z = np.polyfit(frames, values, 1)
            trend = np.poly1d(z)
            ax.plot(frames, trend(frames), '--', color='red', linewidth=2, alpha=0.7)
            
            ax.set_xlabel('å¸§ç¼–å·', fontsize=10, fontweight='bold')
            ax.set_ylabel('ç™½æ–‘æ•°é‡(ä¸ª)', fontsize=10, fontweight='bold')
            ax.set_title(f'{method_name}', fontsize=12, fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend(fontsize=8)
        
        # ç¬¬ä¸‰è¡Œï¼šæŒ‰å·ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰å·å·ï¼‰
        if 'coil_id' in df.columns:
            for idx, (method, method_name, color) in enumerate(zip(methods, method_names, colors)):
                ax = fig.add_subplot(gs[2, idx])
                
                col_name = f'white_area_ratio_{method}'
                if col_name not in df.columns:
                    continue
                
                coil_ids = sorted(df['coil_id'].unique())
                coil_means = [df[df['coil_id']==cid][col_name].mean() for cid in coil_ids]
                
                x = np.arange(len(coil_ids))
                bars = ax.bar(x, coil_means, color=color, alpha=0.6, edgecolor='black', linewidth=1.5)
                ax.plot(x, coil_means, 'ro-', linewidth=2, markersize=8, zorder=10)
                
                # æ·»åŠ è¶‹åŠ¿çº¿
                z = np.polyfit(x, coil_means, 1)
                trend = np.poly1d(z)
                ax.plot(x, trend(x), 'g--', linewidth=2.5, alpha=0.7, label=f'è¶‹åŠ¿çº¿')
                
                ax.set_xlabel('é’¢å·ç¼–å·', fontsize=10, fontweight='bold')
                ax.set_ylabel('å¹³å‡ç™½æ–‘é¢ç§¯å æ¯”(%)', fontsize=10, fontweight='bold')
                ax.set_title(f'{method_name} - æŒ‰å·ç»Ÿè®¡', fontsize=12, fontweight='bold')
                ax.set_xticks(x)
                ax.set_xticklabels([f'å·{int(c)}' for c in coil_ids])
                ax.grid(True, alpha=0.3, axis='y')
                ax.legend(fontsize=8)
        else:
            # å¦‚æœæ²¡æœ‰å·å·ï¼Œæ˜¾ç¤º4ç§æ–¹æ³•çš„ç›¸å…³æ€§å¯¹æ¯”
            ax = fig.add_subplot(gs[2, :])
            
            # ç»˜åˆ¶4ç§æ–¹æ³•çš„å¯¹æ¯”æ›²çº¿
            for method, method_name, color in zip(methods, method_names, colors):
                col_name = f'white_area_ratio_{method}'
                if col_name not in df.columns:
                    continue
                
                values = df[col_name].values
                frames = df['frame_id'].values
                
                # å½’ä¸€åŒ–
                if values.max() > values.min():
                    values_norm = (values - values.min()) / (values.max() - values.min())
                else:
                    values_norm = values
                
                # å¹³æ»‘
                window = min(51, len(values_norm)//10*2+1)
                if window >= 5:
                    smoothed = savgol_filter(values_norm, window_length=window, polyorder=3)
                    ax.plot(frames, smoothed, '-', color=color, linewidth=2.5, label=method_name)
            
            ax.set_xlabel('å¸§ç¼–å·', fontsize=12, fontweight='bold')
            ax.set_ylabel('å½’ä¸€åŒ–ç™½æ–‘é¢ç§¯å æ¯” (0-1)', fontsize=12, fontweight='bold')
            ax.set_title('4ç§æ–¹æ³•æ£€æµ‹ç»“æœå¯¹æ¯”ï¼ˆå½’ä¸€åŒ–ï¼‰', fontsize=14, fontweight='bold')
            ax.legend(fontsize=11, loc='best')
            ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'{self.analysis_name} - æ’•è£‚é¢ç™½è‰²æ–‘å—åˆ†æ\nï¼ˆç”¨æˆ·è§‚å¯Ÿï¼šç™½æ–‘éšç£¨æŸå¢åŠ è€Œå¢å¤šï¼‰', 
                    fontsize=18, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"å·²ä¿å­˜: {save_path}")
    
    def _extract_left_region_and_mask(self, image: np.ndarray):
        """æå–å·¦ä¾§æ’•è£‚é¢åŒºåŸŸåŠæ©ç """
        height, width = image.shape
        
        # æ‰¾ç™½è‰²åŒºåŸŸä¸­æœ€æš—ç‚¹ä½œä¸ºåˆ†ç•Œçº¿
        mask_white = image > 100
        centerline_x = []
        
        for y in range(height):
            row = image[y, :]
            white_indices = np.where(mask_white[y, :])[0]
            
            if len(white_indices) > 10:
                search_start = white_indices[0] + 5
                search_end = white_indices[-1] - 5
                
                if search_end > search_start:
                    min_idx = search_start + np.argmin(row[search_start:search_end])
                    centerline_x.append(min_idx)
                else:
                    centerline_x.append((white_indices[0] + white_indices[-1]) // 2)
            else:
                centerline_x.append(width // 2)
        
        # å¹³æ»‘ä¸­å¿ƒçº¿
        if len(centerline_x) > 51:
            from scipy.signal import savgol_filter
            centerline_x = savgol_filter(centerline_x, 51, 3)
        centerline_x = np.array(centerline_x, dtype=int)
        
        # åˆ›å»ºå·¦ä¾§æ©ç 
        left_mask = np.zeros_like(image, dtype=np.uint8)
        for y in range(height):
            if y < len(centerline_x):
                left_mask[y, :centerline_x[y]] = 255
        
        left_region = cv2.bitwise_and(image, image, mask=left_mask)
        return left_region, left_mask
    
    def _detect_white_patches_methods(self, image: np.ndarray, mask: np.ndarray):
        """ä½¿ç”¨4ç§æ–¹æ³•æ£€æµ‹ç™½æ–‘ï¼Œè¿”å›4ä¸ªäºŒå€¼å›¾"""
        # æ–¹æ³•1ï¼šå›ºå®šé˜ˆå€¼
        _, binary1 = cv2.threshold(image, 200, 255, cv2.THRESH_BINARY)
        binary1 = cv2.bitwise_and(binary1, binary1, mask=mask)
        
        # æ–¹æ³•2ï¼šOtsu + æœ€å°é˜ˆå€¼çº¦æŸ
        masked_pixels = image[mask > 0]
        if len(masked_pixels) > 0:
            otsu_threshold, _ = cv2.threshold(masked_pixels, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            threshold2 = max(otsu_threshold, 170)
            _, binary2 = cv2.threshold(image, threshold2, 255, cv2.THRESH_BINARY)
            binary2 = cv2.bitwise_and(binary2, binary2, mask=mask)
        else:
            binary2 = np.zeros_like(image)
        
        # æ–¹æ³•3ï¼šç›¸å¯¹äº®åº¦æ³•
        if len(masked_pixels) > 0:
            mean_val = np.mean(masked_pixels)
            std_val = np.std(masked_pixels)
            threshold3 = mean_val + 1.5 * std_val
            _, binary3 = cv2.threshold(image, threshold3, 255, cv2.THRESH_BINARY)
            binary3 = cv2.bitwise_and(binary3, binary3, mask=mask)
        else:
            binary3 = np.zeros_like(image)
        
        # æ–¹æ³•4ï¼šTop-Hat
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
        tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)
        tophat_masked = tophat[mask > 0]
        if len(tophat_masked) > 0 and tophat_masked.max() > 0:
            threshold4, _ = cv2.threshold(tophat_masked, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            _, binary4 = cv2.threshold(tophat, max(threshold4, 1), 255, cv2.THRESH_BINARY)
            binary4 = cv2.bitwise_and(binary4, binary4, mask=mask)
        else:
            binary4 = np.zeros_like(image)
        
        return [binary1, binary2, binary3, binary4]
    
    def _generate_white_patch_markers(self, df: pd.DataFrame, viz_dir: str, sample_interval: int = 100):
        """ç”Ÿæˆç™½æ–‘æ ‡æ³¨å›¾ï¼ˆå¸¦ç›´æ–¹å›¾å¯¹æ¯”ï¼‰"""
        print(f"\nç”Ÿæˆç™½æ–‘æ ‡æ³¨å›¾ï¼ˆæ¯éš”{sample_interval}å¸§ï¼‰...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç™½æ–‘ç‰¹å¾
        if 'white_area_ratio_m1' not in df.columns:
            print("  è­¦å‘Š: æ•°æ®ä¸­æ²¡æœ‰ç™½æ–‘ç‰¹å¾ï¼Œè·³è¿‡")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        markers_dir = os.path.join(viz_dir, 'white_patch_markers')
        ensure_dir(markers_dir)
        
        # é€‰æ‹©è¦å¯è§†åŒ–çš„å¸§ï¼ˆåŸºäºframe_idè€ŒéDataFrameç´¢å¼•ï¼‰
        df_sampled = df[df['frame_id'] % sample_interval == 0].head(20)  # æœ€å¤š20å¼ é¿å…å¤ªå¤š
        method_names_display = ['å›ºå®šé˜ˆå€¼', 'Otsuè‡ªé€‚åº”', 'ç›¸å¯¹äº®åº¦', 'å½¢æ€å­¦Top-Hat']
        
        for _, row in tqdm(df_sampled.iterrows(), total=len(df_sampled), desc="ç”Ÿæˆæ ‡æ³¨å›¾"):
            try:
                frame_id = int(row['frame_id'])
                
                # è¯»å–åŸå›¾
                filepath = os.path.join(self.roi_dir, f'frame_{frame_id:06d}_roi.png')
                image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
                if image is None:
                    continue
                
                # æå–å·¦ä¾§åŒºåŸŸ
                left_region, left_mask = self._extract_left_region_and_mask(image)
                
                # 4ç§æ–¹æ³•æ£€æµ‹
                binaries = self._detect_white_patches_methods(left_region, left_mask)
                
                # åˆ›å»º3x2å¸ƒå±€
                fig = plt.figure(figsize=(18, 24))
                gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)
                
                all_areas = []
                
                # å‰4ä¸ªå­å›¾ï¼šæ ‡æ³¨
                for method_idx, (binary, display_name) in enumerate(zip(binaries, method_names_display)):
                    row = method_idx // 2
                    col = method_idx % 2
                    ax = fig.add_subplot(gs[row, col])
                    
                    display_img = cv2.cvtColor(left_region, cv2.COLOR_GRAY2RGB)
                    
                    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)
                    
                    valid_patches = 0
                    patch_areas = []
                    
                    for i in range(1, num_labels):
                        area = stats[i, cv2.CC_STAT_AREA]
                        if area < 5:
                            continue
                        
                        valid_patches += 1
                        patch_areas.append(area)
                        
                        cx, cy = int(centroids[i][0]), int(centroids[i][1])
                        radius = max(3, min(int(np.sqrt(area) * 0.5), 10))
                        cv2.circle(display_img, (cx, cy), radius, (255, 0, 0), 2)
                        cv2.circle(display_img, (cx, cy), 1, (0, 255, 0), -1)
                    
                    all_areas.append(patch_areas)
                    
                    ax.imshow(display_img)
                    ax.set_title(f'{display_name}\nå¸§{frame_id} - æ£€æµ‹åˆ°{valid_patches}ä¸ªç™½æ–‘', 
                               fontsize=14, fontweight='bold')
                    ax.axis('off')
                    
                    ax.text(0.02, 0.98, f'ç™½æ–‘æ•°: {valid_patches}', 
                           transform=ax.transAxes, fontsize=12, 
                           verticalalignment='top', fontweight='bold',
                           bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))
                
                # ç¬¬5ä¸ªå­å›¾ï¼šäº®åº¦ç›´æ–¹å›¾
                ax_brightness = fig.add_subplot(gs[2, 0])
                tear_pixels = left_region[left_mask > 0]
                if len(tear_pixels) > 0:
                    ax_brightness.hist(tear_pixels, bins=50, color='gray', alpha=0.5, 
                                      label='æ’•è£‚é¢æ•´ä½“äº®åº¦', edgecolor='black', linewidth=0.5)
                    
                    colors_hist = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
                    for idx, binary in enumerate(binaries):
                        white_pixels = left_region[binary > 0]
                        if len(white_pixels) > 0:
                            ax_brightness.hist(white_pixels, bins=50, color=colors_hist[idx], 
                                             alpha=0.3, label=f'æ–¹æ³•{idx+1}ç™½æ–‘', 
                                             edgecolor=colors_hist[idx], linewidth=1)
                
                ax_brightness.set_xlabel('äº®åº¦å€¼', fontsize=12, fontweight='bold')
                ax_brightness.set_ylabel('åƒç´ æ•°é‡', fontsize=12, fontweight='bold')
                ax_brightness.set_title(f'æ’•è£‚é¢äº®åº¦åˆ†å¸ƒå¯¹æ¯”\nå¸§{frame_id}', fontsize=14, fontweight='bold')
                ax_brightness.legend(fontsize=10, loc='best')
                ax_brightness.grid(True, alpha=0.3, axis='y')
                
                # ç¬¬6ä¸ªå­å›¾ï¼šæ–‘å—é¢ç§¯ç›´æ–¹å›¾
                ax_area = fig.add_subplot(gs[2, 1])
                colors_hist = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
                for idx, areas in enumerate(all_areas):
                    if len(areas) > 0:
                        ax_area.hist(areas, bins=20, color=colors_hist[idx], alpha=0.5,
                                   label=f'æ–¹æ³•{idx+1} ({len(areas)}ä¸ª)',
                                   edgecolor=colors_hist[idx], linewidth=1)
                
                ax_area.set_xlabel('æ–‘å—é¢ç§¯ (åƒç´ æ•°)', fontsize=12, fontweight='bold')
                ax_area.set_ylabel('æ–‘å—æ•°é‡', fontsize=12, fontweight='bold')
                ax_area.set_title(f'ç™½æ–‘é¢ç§¯åˆ†å¸ƒå¯¹æ¯”\nå¸§{frame_id}', fontsize=14, fontweight='bold')
                ax_area.legend(fontsize=10, loc='best')
                ax_area.grid(True, alpha=0.3, axis='y')
                
                plt.suptitle(f'{self.analysis_name} - æ’•è£‚é¢ç™½æ–‘ç»¼åˆåˆ†æ - å¸§{frame_id}\nï¼ˆä¸Šï¼šæ ‡æ³¨å›¾ï¼Œä¸‹ï¼šç›´æ–¹å›¾å¯¹æ¯”ï¼‰', 
                           fontsize=18, fontweight='bold')
                plt.tight_layout()
                
                save_path = os.path.join(markers_dir, f'frame_{frame_id:06d}_markers.png')
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                plt.close()
                
            except Exception as e:
                print(f"\n  å¤„ç†å¸§{frame_id}æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"  å·²ä¿å­˜æ ‡æ³¨å›¾åˆ°: {markers_dir}")
    
    def _plot_white_patch_temporal_curves(self, df: pd.DataFrame, save_path: str):
        """ç»˜åˆ¶ç™½æ–‘æ—¶åºæ›²çº¿ï¼ˆ8Ã—4å®Œæ•´ç‰ˆï¼‰"""
        print("\nç”Ÿæˆç™½æ–‘æ—¶åºæ›²çº¿ï¼ˆ8Ã—4ï¼‰...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç™½æ–‘ç‰¹å¾
        if 'white_area_ratio_m1' not in df.columns:
            print("  è­¦å‘Š: æ•°æ®ä¸­æ²¡æœ‰ç™½æ–‘ç‰¹å¾ï¼Œè·³è¿‡")
            return
        
        fig, axes = plt.subplots(8, 4, figsize=(20, 32))
        
        methods = ['m1', 'm2', 'm3', 'm4']
        method_names = ['å›ºå®šé˜ˆå€¼', 'Otsuè‡ªé€‚åº”', 'ç›¸å¯¹äº®åº¦', 'å½¢æ€å­¦Top-Hat']
        metrics = ['area_ratio', 'patch_count', 'avg_brightness', 'brightness_std', 
                  'avg_patch_area', 'composite_index', 'brightness_entropy', 'patch_area_entropy']
        metric_names = ['ç™½æ–‘é¢ç§¯å æ¯”(%)', 'ç™½æ–‘æ•°é‡(ä¸ª)', 'å¹³å‡äº®åº¦', 'äº®åº¦æ ‡å‡†å·®', 
                       'å•ä¸ªç™½æ–‘å¹³å‡é¢ç§¯(%)', 'ç»¼åˆæŒ‡æ ‡(æ•°é‡+std)', 'äº®åº¦ç›´æ–¹å›¾ç†µ', 'æ–‘å—é¢ç§¯åˆ†å¸ƒç†µ']
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
        
        for row_idx, metric in enumerate(metrics):
            for col_idx, (method, method_name, color) in enumerate(zip(methods, method_names, colors)):
                ax = axes[row_idx, col_idx]
                
                col_name = f'white_{metric}_{method}'
                if col_name not in df.columns:
                    continue
                
                values = df[col_name].values
                frames = df['frame_id'].values
                
                # åŸå§‹æ•°æ®
                ax.plot(frames, values, '-', alpha=0.3, color=color, linewidth=0.5)
                
                # å¹³æ»‘æ›²çº¿
                window = min(51, len(values)//10*2+1)
                if window >= 5:
                    smoothed = savgol_filter(values, window_length=window, polyorder=3)
                    ax.plot(frames, smoothed, '-', color=color, linewidth=2.5, label='å¹³æ»‘æ›²çº¿')
                
                # çº¿æ€§è¶‹åŠ¿
                z = np.polyfit(frames, values, 1)
                trend = np.poly1d(z)
                ax.plot(frames, trend(frames), '--', color='red', linewidth=2, alpha=0.7, 
                       label=f'è¶‹åŠ¿(æ–œç‡={z[0]:.2e})')
                
                ax.set_xlabel('å¸§ç¼–å·', fontsize=10)
                ax.set_ylabel(metric_names[row_idx], fontsize=10)
                ax.set_title(f'{method_name} - {metric_names[row_idx]}', fontsize=11, fontweight='bold')
                ax.legend(fontsize=8)
                ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'{self.analysis_name} - æ’•è£‚é¢ç™½æ–‘ç‰¹å¾æ—¶åºæ¼”å˜ï¼ˆ4æ–¹æ³•Ã—8æŒ‡æ ‡ï¼‰', 
                    fontsize=18, fontweight='bold')
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"  å·²ä¿å­˜: {save_path}")
    
    def _generate_white_patch_recommendation(self, df: pd.DataFrame, viz_dir: str):
        """ç”Ÿæˆç™½æ–‘æ–¹æ³•æ¨èæŠ¥å‘Š"""
        print("\nç”Ÿæˆç™½æ–‘æ–¹æ³•æ¨èæŠ¥å‘Š...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç™½æ–‘ç‰¹å¾
        if 'white_area_ratio_m1' not in df.columns:
            print("  è­¦å‘Š: æ•°æ®ä¸­æ²¡æœ‰ç™½æ–‘ç‰¹å¾ï¼Œè·³è¿‡")
            return
        
        from scipy.stats import spearmanr
        
        report_lines = []
        report_lines.append(f"# {self.analysis_name} - æ’•è£‚é¢ç™½æ–‘æ£€æµ‹æ–¹æ³•æ¨èæŠ¥å‘Š\n\n")
        
        methods = ['m1', 'm2', 'm3', 'm4']
        method_names = ['æ–¹æ³•1:å›ºå®šé˜ˆå€¼æ³•', 'æ–¹æ³•2:Otsuè‡ªé€‚åº”æ³•', 'æ–¹æ³•3:ç›¸å¯¹äº®åº¦æ³•', 'æ–¹æ³•4:å½¢æ€å­¦Top-Hatæ³•']
        metrics = ['area_ratio', 'patch_count']
        
        report_lines.append("## æ–¹æ³•è¯„ä¼°\n\n")
        report_lines.append("è¯„ä¼°ç»´åº¦ï¼š\n")
        report_lines.append("1. **å•è°ƒæ€§**ï¼šä¸å¸§åºå·çš„Spearmanç›¸å…³ç³»æ•°ï¼ˆåæ˜ æ˜¯å¦éšç£¨æŸé€’å¢ï¼‰\n")
        report_lines.append("2. **ç¨³å®šæ€§**ï¼šå˜å¼‚ç³»æ•°CVï¼ˆæ ‡å‡†å·®/å‡å€¼ï¼Œè¶Šå°è¶Šç¨³å®šï¼‰\n")
        report_lines.append("3. **çµæ•åº¦**ï¼šæ•°å€¼å˜åŒ–èŒƒå›´\n\n")
        
        evaluation_results = []
        
        for method, method_name in zip(methods, method_names):
            report_lines.append(f"### {method_name}\n\n")
            
            for metric in metrics:
                col_name = f'white_{metric}_{method}'
                if col_name not in df.columns:
                    continue
                
                values = df[col_name].values
                frames = df['frame_id'].values
                
                corr, pval = spearmanr(frames, values)
                mean_val = np.mean(values)
                std_val = np.std(values)
                cv = std_val / mean_val if mean_val > 0 else 0
                value_range = np.max(values) - np.min(values)
                
                metric_cn = 'é¢ç§¯å æ¯”' if metric == 'area_ratio' else 'æ–‘å—æ•°é‡'
                
                report_lines.append(f"**æŒ‡æ ‡: {metric_cn}**\n")
                report_lines.append(f"- å•è°ƒæ€§ï¼ˆSpearmanç›¸å…³ç³»æ•°ï¼‰: {corr:.4f} (p-value={pval:.4e})\n")
                report_lines.append(f"- ç¨³å®šæ€§ï¼ˆå˜å¼‚ç³»æ•°CVï¼‰: {cv:.4f}\n")
                report_lines.append(f"- çµæ•åº¦ï¼ˆæ•°å€¼èŒƒå›´ï¼‰: {value_range:.2f}\n")
                report_lines.append(f"- å‡å€¼: {mean_val:.2f}, æ ‡å‡†å·®: {std_val:.2f}\n\n")
                
                evaluation_results.append({
                    'method': method_name,
                    'metric': metric_cn,
                    'monotonicity': abs(corr),
                    'stability': 1/(cv+0.01),
                    'sensitivity': value_range
                })
        
        # ç»¼åˆæ¨è
        report_lines.append("## ç»¼åˆæ¨è\n\n")
        
        if len(evaluation_results) > 0:
            eval_df = pd.DataFrame(evaluation_results)
            eval_df['ç»¼åˆå¾—åˆ†'] = eval_df['monotonicity'] * 0.5 + eval_df['stability'] * 0.01 + eval_df['sensitivity'] * 0.001
            
            best_method = eval_df.loc[eval_df['ç»¼åˆå¾—åˆ†'].idxmax()]
            
            report_lines.append(f"**æ¨èæ–¹æ³•**: {best_method['method']}\n")
            report_lines.append(f"**æ¨èæŒ‡æ ‡**: {best_method['metric']}\n")
            report_lines.append(f"**ç»¼åˆå¾—åˆ†**: {best_method['ç»¼åˆå¾—åˆ†']:.4f}\n\n")
            
            report_lines.append("**è¯´æ˜**:\n")
            report_lines.append("- è¯¥æ–¹æ³•åœ¨å•è°ƒæ€§ã€ç¨³å®šæ€§å’Œçµæ•åº¦æ–¹é¢å–å¾—äº†æœ€ä½³å¹³è¡¡\n")
            report_lines.append("- å»ºè®®åœ¨åç»­åˆ†æä¸­ä½¿ç”¨è¯¥æ–¹æ³•ä½œä¸ºä¸»è¦æŒ‡æ ‡\n")
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = os.path.join(viz_dir, 'white_patch_recommendation.md')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.writelines(report_lines)
        
        print(f"  å·²ä¿å­˜: {report_path}")
    
    def _generate_report(self, df, key_features, n_coils, analysis_results=None):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print(f"\n{'='*80}")
        print(f"{self.analysis_name} - æŒ‰å·åˆ†æç»“è®º")
        print(f"{'='*80}")
        
        focus_features = {
            'right_peak_density': 'å³ä¾§å³°å¯†åº¦ï¼ˆå‰ªåˆ‡é¢å¾®ç¼ºå£ï¼‰',
            'avg_gradient_energy': 'æ¢¯åº¦èƒ½é‡ï¼ˆåˆ€å£é”åº¦ï¼‰',
            'max_notch_depth': 'æœ€å¤§ç¼ºå£æ·±åº¦'
        }
        
        report_lines = []
        report_lines.append(f"# {self.analysis_name} - æŒ‰å·åˆ†ææŠ¥å‘Š\n")
        report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report_lines.append(f"æ€»å¸§æ•°: {len(df)}\n")
        report_lines.append(f"é’¢å·æ•°: {n_coils}\n\n")
        
        # è¿‡æ»¤æ‰ NaN å€¼
        valid_coil_ids = df['coil_id'].dropna().unique()
        for feature, label in focus_features.items():
            coil_means = []
            coil_ids_list = []
            for coil_id in sorted(valid_coil_ids):
                coil_df = df[df['coil_id'] == coil_id]
                coil_means.append(coil_df[feature].mean())
                coil_ids_list.append(int(coil_id))
            
            change_pct = ((coil_means[-1] - coil_means[0]) / (coil_means[0] + 1e-8)) * 100
            
            print(f"\nã€{label}ã€‘")
            print(f"  ç¬¬{coil_ids_list[0]}å·å‡å€¼: {coil_means[0]:.4f}")
            print(f"  ç¬¬{coil_ids_list[-1]}å·å‡å€¼: {coil_means[-1]:.4f}")
            print(f"  å˜åŒ–ç‡: {change_pct:+.1f}%")
            
            report_lines.append(f"## {label}\n")
            report_lines.append(f"- ç¬¬{coil_ids_list[0]}å·å‡å€¼: {coil_means[0]:.4f}\n")
            report_lines.append(f"- ç¬¬{coil_ids_list[-1]}å·å‡å€¼: {coil_means[-1]:.4f}\n")
            report_lines.append(f"- å˜åŒ–ç‡: {change_pct:+.1f}%\n")
            
            increases = sum(1 for i in range(len(coil_means)-1)
                          if coil_means[i+1] > coil_means[i])
            total = len(coil_means) - 1
            
            print(f"  é€å·é€’å¢æ¬¡æ•°: {increases}/{total} = {increases/total*100:.0f}%")
            report_lines.append(f"- é€å·é€’å¢æ¬¡æ•°: {increases}/{total} = {increases/total*100:.0f}%\n")
            
            if feature == 'avg_gradient_energy':
                if change_pct < 0:
                    conclusion = "âœ“ é”åº¦ä¸‹é™ â†’ åˆ€å£ç£¨é’ï¼Œç¬¦åˆç£¨æŸé¢„æœŸ"
                    print(f"  {conclusion}")
                    report_lines.append(f"- {conclusion}\n")
            else:
                if change_pct > 0:
                    conclusion = "âœ“ æ•°å€¼é€’å¢ â†’ ç£¨æŸåŠ é‡ï¼Œç¬¦åˆé¢„æœŸ"
                    print(f"  {conclusion}")
                    report_lines.append(f"- {conclusion}\n")
            
            report_lines.append("\n")
        
        # === æ·»åŠ ç»¼åˆæŒ‡æ ‡åˆ†æ ===
        if analysis_results is not None:
            report_lines.append("---\n\n")
            report_lines.append("## ç»¼åˆç£¨æŸæŒ‡æ ‡åˆ†æ\n\n")
            
            # æ–¹æ³•å¯¹æ¯”
            report_lines.append("### ç»¼åˆè¯„åˆ†æ–¹æ³•å¯¹æ¯”\n\n")
            for score_name in ['weighted_score', 'pca_score', 'overall_score']:
                if score_name in df.columns:
                    values = df[score_name].values
                    if len(values) > 10:
                        first = np.mean(values[:len(values)//10])
                        last = np.mean(values[-len(values)//10:])
                        if first != 0:
                            change = ((last - first) / first) * 100
                        else:
                            change = 0
                        
                        method_names = {
                            'weighted_score': 'åŠ æƒå¹³å‡æ³•',
                            'pca_score': 'PCAä¸»æˆåˆ†æ³•',
                            'overall_score': 'å¤šç»´åº¦æ³•'
                        }
                        report_lines.append(f"- **{method_names[score_name]}**: å˜åŒ–ç‡={change:+.1f}%\n")
            
            # PCAåˆ†æ
            pca_result = analysis_results.get('pca_result', {})
            if 'explained_variance_ratio' in pca_result and len(pca_result['explained_variance_ratio']) > 0:
                explained_var = pca_result['explained_variance_ratio']
                total_explained = sum(explained_var) * 100
                report_lines.append(f"- PCAç´¯è®¡è§£é‡Šæ–¹å·®: {total_explained:.1f}%\n")
            
            report_lines.append("\n")
            
            # ç‰¹å¾é‡è¦æ€§Top 5
            importance_df = analysis_results.get('importance_df', pd.DataFrame())
            if len(importance_df) > 0:
                report_lines.append("### ç‰¹å¾é‡è¦æ€§æ’åº (Top 5)\n\n")
                for idx, row in importance_df.head(5).iterrows():
                    report_lines.append(f"{idx+1}. **{row['feature']}**: ")
                    report_lines.append(f"é‡è¦æ€§={row['importance_score']:.3f}, ")
                    report_lines.append(f"å•è°ƒæ€§={row['monotonicity']:.3f}, ")
                    report_lines.append(f"å˜å¼‚ç³»æ•°={row['cv']:.3f}\n")
                
                report_lines.append("\n")
                
                # æœ€å¼ºç›¸å…³ç‰¹å¾
                top_feature = importance_df.iloc[0]
                report_lines.append("### ç£¨æŸç›¸å…³æ€§å»ºè®®\n\n")
                report_lines.append(f"åŸºäºå½“å‰æ•°æ®ï¼Œ**{top_feature['feature']}** ")
                report_lines.append(f"æ˜¾ç¤ºå‡ºæœ€æ˜æ˜¾çš„å•è°ƒè¶‹åŠ¿ï¼ˆå•è°ƒæ€§={top_feature['monotonicity']:.3f}ï¼‰ï¼Œ")
                report_lines.append("å»ºè®®ä½œä¸ºä¸»è¦ç›‘æ§æŒ‡æ ‡ã€‚\n")
        
        # === æ·»åŠ ç™½æ–‘åˆ†æç»“è®º ===
        white_patch_cols = [col for col in df.columns if col.startswith('white_area_ratio_')]
        if len(white_patch_cols) > 0:
            report_lines.append("\n---\n\n")
            report_lines.append("## æ’•è£‚é¢ç™½è‰²æ–‘å—åˆ†æ\n\n")
            report_lines.append("åŸºäºç”¨æˆ·è§‚å¯Ÿï¼šæ’•è£‚é¢ç™½è‰²æ–‘å—éšé’¢å·æ•°é‡å¢åŠ è€Œå¢å¤š\n\n")
            
            # åˆ†æ4ç§æ–¹æ³•çš„å˜åŒ–è¶‹åŠ¿
            methods = ['m1', 'm2', 'm3', 'm4']
            method_names = ['å›ºå®šé˜ˆå€¼æ³•', 'Otsuè‡ªé€‚åº”æ³•', 'ç›¸å¯¹äº®åº¦æ³•', 'å½¢æ€å­¦Top-Hatæ³•']
            
            report_lines.append("### å„æ£€æµ‹æ–¹æ³•çš„å˜åŒ–è¶‹åŠ¿\n\n")
            
            for method, method_name in zip(methods, method_names):
                col_name = f'white_area_ratio_{method}'
                if col_name in df.columns:
                    values = df[col_name].values
                    if len(values) > 10:
                        first = np.mean(values[:len(values)//10])
                        last = np.mean(values[-len(values)//10:])
                        change = last - first
                        change_pct = (change / (first + 1e-8)) * 100
                        
                        report_lines.append(f"**{method_name}**:\n")
                        report_lines.append(f"- åˆæœŸç™½æ–‘é¢ç§¯å æ¯”: {first:.2f}%\n")
                        report_lines.append(f"- åæœŸç™½æ–‘é¢ç§¯å æ¯”: {last:.2f}%\n")
                        report_lines.append(f"- å˜åŒ–é‡: {change:+.2f}% (å˜åŒ–ç‡: {change_pct:+.1f}%)\n")
                        
                        if change > 0:
                            report_lines.append(f"- **ç»“è®º**: âœ“ ç™½æ–‘é¢ç§¯æ˜¾è‘—å¢åŠ ï¼Œä¸ç”¨æˆ·è§‚å¯Ÿä¸€è‡´\n")
                        else:
                            report_lines.append(f"- ç»“è®º: ç™½æ–‘é¢ç§¯æœªè§æ˜æ˜¾å¢é•¿\n")
                        
                        report_lines.append("\n")
            
            # ç»¼åˆç»“è®º
            report_lines.append("### ç»¼åˆç»“è®º\n\n")
            avg_changes = []
            for method in methods:
                col_name = f'white_area_ratio_{method}'
                if col_name in df.columns:
                    values = df[col_name].values
                    if len(values) > 10:
                        first = np.mean(values[:len(values)//10])
                        last = np.mean(values[-len(values)//10:])
                        change = last - first
                        avg_changes.append(change)
            
            if len(avg_changes) > 0:
                avg_change = np.mean(avg_changes)
                if avg_change > 0:
                    report_lines.append(f"4ç§æ£€æµ‹æ–¹æ³•çš„å¹³å‡å˜åŒ–é‡ä¸º **{avg_change:+.2f}%**ï¼Œ")
                    report_lines.append("è¡¨æ˜æ’•è£‚é¢ç™½è‰²æ–‘å—ç¡®å®éšç€é’¢å·æ•°é‡å¢åŠ è€Œå¢å¤šï¼Œ")
                    report_lines.append("**éªŒè¯äº†ç”¨æˆ·çš„è§‚å¯Ÿ**ã€‚è¿™ä¸€ç°è±¡å¯èƒ½åæ˜ äº†ï¼š\n\n")
                    report_lines.append("1. å‰ªåˆ€ç£¨æŸå¯¼è‡´æ’•è£‚é¢è´¨é‡ä¸‹é™\n")
                    report_lines.append("2. æ’•è£‚è¿‡ç¨‹ä¸­äº§ç”Ÿæ›´å¤šç™½è‰²é«˜äº®åŒºåŸŸï¼ˆåº”åŠ›é›†ä¸­æˆ–çº¤ç»´æ–­è£‚ï¼‰\n")
                    report_lines.append("3. å¯ä½œä¸ºå‰ªåˆ€ç£¨æŸçš„é‡è¦æŒ‡æ ‡ä¹‹ä¸€\n")
                else:
                    report_lines.append("ç™½æ–‘é¢ç§¯æœªè§æ˜¾è‘—å¢é•¿è¶‹åŠ¿ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´æ£€æµ‹å‚æ•°ã€‚\n")
        
        print(f"\n{'='*80}")
        print("åˆ†æå®Œæˆï¼")
        print(f"{'='*80}")
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = os.path.join(self.output_dir, 'analysis_report.md')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.writelines(report_lines)
        print(f"\nå·²ä¿å­˜åˆ†ææŠ¥å‘Š: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='é€šç”¨çš„å‰ªåˆ€ç£¨æŸæŒ‰å·åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•ï¼ˆä½¿ç”¨æ³¢è°·æ£€æµ‹æ³•è‡ªåŠ¨è¯†åˆ«ï¼Œæ¨èï¼‰
  python coil_wear_analysis.py --roi_dir data/roi_imgs --output_dir data/analysis
  
  # âš¡ æœ€å¿«æ¨¡å¼ï¼šç›´æ¥æŒ‡å®šé’¢å·æ•°ï¼ˆé€Ÿåº¦å¿«10å€ï¼‰
  python coil_wear_analysis.py --roi_dir data/roi_imgs --output_dir data/analysis \
    --n_coils 8 --name "è§†é¢‘1"
  
  # ä½¿ç”¨Peltç®—æ³•æ£€æµ‹ï¼ˆæ›´ç²¾ç¡®ä½†è¾ƒæ…¢ï¼‰
  python coil_wear_analysis.py --roi_dir data/roi_imgs --output_dir data/analysis \
    --detection_method pelt --name "ç¬¬ä¸€å‘¨æœŸ"
  
  # è‡ªå®šä¹‰å¯è§†åŒ–é‡‡æ ·é—´éš”
  python coil_wear_analysis.py --roi_dir data/roi_imgs --output_dir data/analysis \
    --diagnosis_interval 50 --marker_interval 50
  
  # ç»„åˆä½¿ç”¨ï¼šæ³¢è°·æ£€æµ‹+è‡ªå®šä¹‰å‚æ•°
  python coil_wear_analysis.py --roi_dir data/roi_imgs --output_dir data/analysis \
    --detection_method valley --min_coils 6 --max_coils 12 --name "è§†é¢‘2"
  
  # æ‰¹é‡å¤„ç†
  python coil_wear_analysis.py --roi_dir video1/roi_imgs --output_dir video1/analysis --n_coils 8 --name "è§†é¢‘1"
  python coil_wear_analysis.py --roi_dir video2/roi_imgs --output_dir video2/analysis --name "è§†é¢‘2"
        """
    )
    
    parser.add_argument('--roi_dir', required=True, help='ROIå›¾åƒç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', required=True, help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--name', default='è§†é¢‘åˆ†æ', help='åˆ†æåç§° (é»˜è®¤: è§†é¢‘åˆ†æ)')
    parser.add_argument('--min_coils', type=int, default=5, help='æœ€å°é’¢å·æ•°ï¼Œè‡ªåŠ¨æ£€æµ‹æ—¶ä½¿ç”¨ (é»˜è®¤: 5)')
    parser.add_argument('--max_coils', type=int, default=15, help='æœ€å¤§é’¢å·æ•°ï¼Œè‡ªåŠ¨æ£€æµ‹æ—¶ä½¿ç”¨ (é»˜è®¤: 15)')
    parser.add_argument('--n_coils', type=int, default=None,
                       help='âš¡ å¿«é€Ÿæ¨¡å¼ï¼šç›´æ¥æŒ‡å®šé’¢å·æ•°é‡ï¼Œè·³è¿‡è‡ªåŠ¨æ£€æµ‹ï¼ˆé€Ÿåº¦å¿«10å€ï¼‰')
    parser.add_argument('--detection_method', type=str, default='valley', choices=['valley', 'pelt'],
                       help='è‡ªåŠ¨æ£€æµ‹æ–¹æ³•ï¼švalley=æ³¢è°·æ£€æµ‹æ³•ï¼ˆæ¨èï¼Œå¿«é€Ÿï¼‰, pelt=Peltå˜åŒ–ç‚¹æ£€æµ‹ï¼ˆæ…¢ä½†ç²¾ç¡®ï¼‰ï¼ˆé»˜è®¤valleyï¼‰')
    parser.add_argument('--diagnosis_interval', type=int, default=100, 
                       help='å¸§è¯Šæ–­å›¾é‡‡æ ·é—´éš”ï¼Œæ¯éš”å¤šå°‘å¸§ç”Ÿæˆä¸€æ¬¡è¯Šæ–­å›¾ï¼ˆé»˜è®¤100ï¼‰')
    parser.add_argument('--marker_interval', type=int, default=100,
                       help='ç™½æ–‘æ ‡æ³¨å›¾é‡‡æ ·é—´éš”ï¼Œæ¯éš”å¤šå°‘å¸§ç”Ÿæˆä¸€æ¬¡æ ‡æ³¨å›¾ï¼ˆé»˜è®¤100ï¼Œæœ€å¤š20å¼ ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(args.roi_dir):
        print(f"é”™è¯¯: ROIç›®å½•ä¸å­˜åœ¨: {args.roi_dir}")
        return 1
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = UniversalWearAnalyzer(
        roi_dir=args.roi_dir,
        output_dir=args.output_dir,
        analysis_name=args.name,
        min_coils=args.min_coils,
        max_coils=args.max_coils,
        diagnosis_interval=args.diagnosis_interval,
        marker_interval=args.marker_interval,
        n_coils=args.n_coils,
        detection_method=args.detection_method
    )
    
    # æå–ç‰¹å¾
    df = analyzer.extract_features()
    
    # æŒ‰å·åˆ†æï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
    analyzer.analyze_by_coil(df)
    
    print(f"\n{'='*80}")
    print(f"åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")
    print(f"{'='*80}")
    
    return 0


if __name__ == '__main__':
    sys.exit(main())

