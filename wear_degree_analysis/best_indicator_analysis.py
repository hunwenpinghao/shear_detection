"""
æœ€ä½³ç£¨æŸæŒ‡æ ‡è¯„ä¼°ï¼šæ‰¾å‡ºæœ€èƒ½åæ˜ å‰ªåˆ€ç£¨æŸçš„æŒ‡æ ‡
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
from scipy.stats import pearsonr, spearmanr
from scipy.ndimage import uniform_filter1d

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False
matplotlib.rcParams['font.size'] = 12

# è¯»å–æ•°æ®
df = pd.read_csv('results/features/wear_features.csv')

print("="*80)
print("å‰ªåˆ€ç£¨æŸæŒ‡æ ‡è¯„ä¼° - æ‰¾å‡ºæœ€ä½³æŒ‡æ ‡")
print("="*80)

# æ‰€æœ‰å€™é€‰æŒ‡æ ‡
all_features = {
    'avg_rms_roughness': 'RMSç²—ç³™åº¦',
    'avg_gradient_energy': 'æ¢¯åº¦èƒ½é‡ï¼ˆé”åº¦ï¼‰',
    'max_notch_depth': 'æœ€å¤§ç¼ºå£æ·±åº¦',
    'left_peak_density': 'å·¦ä¾§å³°å¯†åº¦',
    'right_peak_density': 'å³ä¾§å³°å¯†åº¦',
    'tear_shear_area_ratio': 'æ’•è£‚/å‰ªåˆ‡é¢ç§¯æ¯”',
    'left_peak_count': 'å·¦ä¾§å³°æ•°é‡',
    'right_peak_count': 'å³ä¾§å³°æ•°é‡',
}

# è¯„ä¼°æ ‡å‡†
evaluation_results = []

for feature, label in all_features.items():
    if feature not in df.columns:
        continue
    
    values = df[feature].values
    frames = df['frame_id'].values
    
    # 1. è¶‹åŠ¿ä¸€è‡´æ€§ï¼ˆä¸æ—¶é—´çš„ç›¸å…³æ€§ï¼‰
    correlation, p_value = spearmanr(frames, values)
    
    # 2. å•è°ƒæ€§ï¼ˆå˜åŒ–æ–¹å‘çš„ä¸€è‡´æ€§ï¼‰
    diffs = np.diff(values)
    positive_changes = np.sum(diffs > 0)
    negative_changes = np.sum(diffs < 0)
    monotonicity = abs(positive_changes - negative_changes) / len(diffs)
    
    # 3. é¦–å°¾å˜åŒ–ç‡
    first_250 = values[:250]
    last_250 = values[-250:]
    
    first_mean = np.mean(first_250)
    last_mean = np.mean(last_250)
    
    if first_mean != 0:
        change_rate = ((last_mean - first_mean) / abs(first_mean)) * 100
    else:
        change_rate = 0
    
    # 4. å¹³æ»‘åçš„è¶‹åŠ¿
    if len(values) >= 100:
        smoothed = uniform_filter1d(values, size=100)
        smooth_correlation, _ = spearmanr(frames, smoothed)
    else:
        smooth_correlation = correlation
    
    # 5. å‘¨æœŸå†…é€’å¢æ¯”ä¾‹ï¼ˆä»ä¹‹å‰åˆ†æå¾—åˆ°ï¼‰
    # ç®€åŒ–ç‰ˆï¼šè®¡ç®—è¿ç»­ä¸Šå‡æ®µçš„æ¯”ä¾‹
    rising_ratio = positive_changes / len(diffs)
    
    # 6. ç‰©ç†æ„ä¹‰è¯„åˆ†ï¼ˆä¸»è§‚è¯„åˆ†ï¼‰
    physical_meaning_score = {
        'avg_gradient_energy': 10,  # é”åº¦æœ€ç›´æ¥
        'left_peak_density': 9,     # å¾®ç¼ºå£æ•°é‡
        'max_notch_depth': 8,       # æŸä¼¤æ·±åº¦
        'tear_shear_area_ratio': 7, # æ’•è£‚ç¨‹åº¦
        'avg_rms_roughness': 6,     # è¡¨é¢è´¨é‡
        'left_peak_count': 8,       # ç¼ºå£æ•°
        'right_peak_density': 7,
        'right_peak_count': 7,
    }.get(feature, 5)
    
    # ç»¼åˆè¯„åˆ†
    # å…³é”®ï¼šæ¢¯åº¦èƒ½é‡ä¸‹é™ä»£è¡¨ç£¨æŸï¼Œæ‰€ä»¥è´Ÿç›¸å…³æ˜¯å¥½çš„
    if feature == 'avg_gradient_energy':
        trend_score = 10 if correlation < -0.1 else 5  # è´Ÿç›¸å…³æ‰å¯¹
    else:
        trend_score = 10 if correlation > 0.1 else 5   # æ­£ç›¸å…³æ‰å¯¹
    
    stability_score = (1 - np.std(values) / (np.mean(values) + 1e-6)) * 10
    stability_score = max(0, min(10, stability_score))
    
    total_score = (
        trend_score * 0.3 +           # è¶‹åŠ¿æ€§ 30%
        monotonicity * 10 * 0.2 +     # å•è°ƒæ€§ 20%
        physical_meaning_score * 0.3 + # ç‰©ç†æ„ä¹‰ 30%
        abs(change_rate) * 0.2        # å˜åŒ–å¹…åº¦ 20%
    )
    
    evaluation_results.append({
        'æŒ‡æ ‡': label,
        'ç‰¹å¾å': feature,
        'æ—¶é—´ç›¸å…³æ€§': correlation,
        'å•è°ƒæ€§': monotonicity,
        'é¦–å°¾å˜åŒ–ç‡(%)': change_rate,
        'å¹³æ»‘ç›¸å…³æ€§': smooth_correlation,
        'ä¸Šå‡æ¯”ä¾‹': rising_ratio,
        'ç‰©ç†æ„ä¹‰': physical_meaning_score,
        'ç»¼åˆå¾—åˆ†': total_score
    })

# æ’åº
results_df = pd.DataFrame(evaluation_results)
results_df = results_df.sort_values('ç»¼åˆå¾—åˆ†', ascending=False)

print("\n" + "="*80)
print("æŒ‡æ ‡è¯„ä¼°ç»“æœï¼ˆæŒ‰ç»¼åˆå¾—åˆ†æ’åºï¼‰")
print("="*80)
print(results_df.to_string(index=False))

# ä¿å­˜ç»“æœ
results_df.to_csv('results/features/indicator_evaluation.csv', 
                  index=False, encoding='utf-8-sig')
print(f"\nå·²ä¿å­˜: results/features/indicator_evaluation.csv")

# ==================== å¯è§†åŒ–å¯¹æ¯” ====================
print("\nç”Ÿæˆæœ€ä½³æŒ‡æ ‡å¯¹æ¯”å¯è§†åŒ–...")

# é€‰æ‹©å‰3åæŒ‡æ ‡
top3_features = results_df.head(3)['ç‰¹å¾å'].values

fig = plt.figure(figsize=(20, 12))
gs = fig.add_gridspec(3, 2, hspace=0.35, wspace=0.25)

for idx, feature in enumerate(top3_features):
    label = all_features[feature]
    rank = idx + 1
    
    values = df[feature].values
    frames = df['frame_id'].values
    
    # å·¦ä¾§ï¼šåŸå§‹æ•°æ® + å¹³æ»‘è¶‹åŠ¿
    ax_left = fig.add_subplot(gs[idx, 0])
    
    # åŸå§‹æ•°æ®
    ax_left.plot(frames, values, '-', alpha=0.2, color='gray', 
                linewidth=0.5, label='åŸå§‹æ•°æ®')
    
    # ç§»åŠ¨å¹³å‡
    if len(values) >= 100:
        smoothed = uniform_filter1d(values, size=100)
        ax_left.plot(frames, smoothed, '-', color='blue', 
                    linewidth=3, label='ç§»åŠ¨å¹³å‡(çª—å£=100)', alpha=0.8)
        
        # çº¿æ€§è¶‹åŠ¿
        z = np.polyfit(frames, smoothed, 1)
        trend = np.poly1d(z)
        ax_left.plot(frames, trend(frames), '--', color='red', 
                    linewidth=3, label=f'çº¿æ€§è¶‹åŠ¿(æ–œç‡={z[0]:.6f})', alpha=0.8)
    
    # æ ‡æ³¨æ’å
    ax_left.text(0.02, 0.98, f'ğŸ† æ’å #{rank}', 
                transform=ax_left.transAxes, fontsize=18, 
                fontweight='bold', va='top',
                bbox=dict(boxstyle='round,pad=1', 
                         facecolor='gold' if rank==1 else 'silver' if rank==2 else '#CD7F32',
                         alpha=0.8))
    
    ax_left.set_xlabel('å¸§ç¼–å·', fontweight='bold')
    ax_left.set_ylabel(label, fontweight='bold')
    ax_left.set_title(f'No.{rank}: {label} - æ—¶åºè¶‹åŠ¿', 
                     fontsize=14, fontweight='bold')
    ax_left.legend(fontsize=10)
    ax_left.grid(True, alpha=0.3)
    
    # å³ä¾§ï¼šç»Ÿè®¡ç‰¹æ€§
    ax_right = fig.add_subplot(gs[idx, 1])
    
    # è·å–è¯¥æŒ‡æ ‡çš„è¯„ä¼°ç»“æœ
    result = results_df[results_df['ç‰¹å¾å'] == feature].iloc[0]
    
    # é›·è¾¾å›¾å¼çš„å±•ç¤º
    categories = ['è¶‹åŠ¿æ€§', 'å•è°ƒæ€§', 'ç‰©ç†æ„ä¹‰', 'å˜åŒ–å¹…åº¦', 'ç»¼åˆå¾—åˆ†']
    
    # å½’ä¸€åŒ–åˆ†æ•°
    scores = [
        (abs(result['æ—¶é—´ç›¸å…³æ€§']) * 10),
        (result['å•è°ƒæ€§'] * 10),
        result['ç‰©ç†æ„ä¹‰'],
        min(abs(result['é¦–å°¾å˜åŒ–ç‡(%)']), 10),
        result['ç»¼åˆå¾—åˆ†']
    ]
    
    # æ¡å½¢å›¾
    y_pos = np.arange(len(categories))
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']
    
    bars = ax_right.barh(y_pos, scores, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, score) in enumerate(zip(bars, scores)):
        ax_right.text(score + 0.2, i, f'{score:.1f}', 
                     va='center', fontweight='bold', fontsize=11)
    
    ax_right.set_yticks(y_pos)
    ax_right.set_yticklabels(categories, fontsize=11, fontweight='bold')
    ax_right.set_xlabel('å¾—åˆ†', fontweight='bold', fontsize=12)
    ax_right.set_xlim(0, 12)
    ax_right.set_title(f'No.{rank}: {label} - è¯„ä¼°ç»´åº¦', 
                      fontsize=14, fontweight='bold')
    ax_right.grid(True, alpha=0.3, axis='x')
    
    # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
    info_text = (f'æ—¶é—´ç›¸å…³æ€§: {result["æ—¶é—´ç›¸å…³æ€§"]:.3f}\n'
                f'é¦–å°¾å˜åŒ–: {result["é¦–å°¾å˜åŒ–ç‡(%)"]:.1f}%\n'
                f'ç»¼åˆå¾—åˆ†: {result["ç»¼åˆå¾—åˆ†"]:.1f}')
    
    ax_right.text(0.98, 0.02, info_text,
                 transform=ax_right.transAxes, fontsize=10,
                 ha='right', va='bottom',
                 bbox=dict(boxstyle='round,pad=0.5', 
                          facecolor='white', alpha=0.8))

plt.suptitle('æœ€ä½³ç£¨æŸæŒ‡æ ‡è¯„ä¼° - Top 3 å¯¹æ¯”', 
            fontsize=20, fontweight='bold', y=0.995)
plt.savefig('results/visualizations/best_indicators_comparison.png', 
           dpi=300, bbox_inches='tight')
print("å·²ä¿å­˜: results/visualizations/best_indicators_comparison.png")

# ==================== æ¨èæŒ‡æ ‡çš„è¯¦ç»†åˆ†æ ====================
print("\n" + "="*80)
print("æ¨èä½¿ç”¨çš„æœ€ä½³ç£¨æŸæŒ‡æ ‡")
print("="*80)

best_feature = results_df.iloc[0]['ç‰¹å¾å']
best_label = results_df.iloc[0]['æŒ‡æ ‡']
best_score = results_df.iloc[0]['ç»¼åˆå¾—åˆ†']

print(f"\nğŸ† æœ€ä½³æŒ‡æ ‡: {best_label} ({best_feature})")
print(f"   ç»¼åˆå¾—åˆ†: {best_score:.2f}/10")
print(f"\næ¨èç†ç”±ï¼š")

if best_feature == 'avg_gradient_energy':
    print("  âœ“ ç‰©ç†æ„ä¹‰æœ€æ˜ç¡®ï¼šç›´æ¥åæ˜ åˆ€å£é”åº¦")
    print("  âœ“ è¶‹åŠ¿æœ€ç¨³å®šï¼šæŒç»­ä¸‹é™ï¼Œç¬¦åˆç£¨æŸé’åŒ–è¿‡ç¨‹")
    print("  âœ“ ä¸å—æ¢å·å½±å“ï¼šæ¢¯åº¦èƒ½é‡å˜åŒ–ç›¸å¯¹å¹³ç¨³")
    print("  âœ“ å®ç”¨æ€§å¼ºï¼šå¯å®æ—¶è®¡ç®—ï¼Œæ˜“äºç›‘æ§")
    print(f"  âœ“ é¦–å°¾å˜åŒ–æ˜æ˜¾ï¼š{results_df.iloc[0]['é¦–å°¾å˜åŒ–ç‡(%)']:.1f}%")
    
elif best_feature in ['left_peak_density', 'left_peak_count']:
    print("  âœ“ åæ˜ å¾®è§‚æŸä¼¤ï¼šç»Ÿè®¡å¾®ç¼ºå£æ•°é‡")
    print("  âœ“ ç´¯ç§¯ç‰¹æ€§ï¼šç¼ºå£åªå¢ä¸å‡")
    print("  âœ“ æ•æ„Ÿåº¦é«˜ï¼šèƒ½æ•æ‰ç»†å¾®ç£¨æŸ")
    
elif best_feature == 'max_notch_depth':
    print("  âœ“ åæ˜ å±€éƒ¨æŸä¼¤ï¼šæœ€ä¸¥é‡çš„ç ´åç¨‹åº¦")
    print("  âœ“ å·¥ç¨‹æ„ä¹‰å¼ºï¼šç›´æ¥å…³è”åˆ°åˆ‡å‰²è´¨é‡")

print("\nğŸ“Š ä½¿ç”¨å»ºè®®ï¼š")
print(f"  1. ä¸»è¦ç›‘æ§æŒ‡æ ‡ï¼š{best_label}")
print(f"  2. è¾…åŠ©ç›‘æ§æŒ‡æ ‡ï¼š")

for i in range(1, min(3, len(results_df))):
    aux_label = results_df.iloc[i]['æŒ‡æ ‡']
    aux_score = results_df.iloc[i]['ç»¼åˆå¾—åˆ†']
    print(f"     - {aux_label} (å¾—åˆ†: {aux_score:.2f})")

print("\nâš ï¸ æ³¨æ„äº‹é¡¹ï¼š")
if best_feature == 'avg_gradient_energy':
    print("  - æ¢¯åº¦èƒ½é‡ä¸‹é™ä»£è¡¨ç£¨æŸåŠ é‡ï¼ˆè´Ÿç›¸å…³ï¼‰")
    print("  - å»ºè®®è®¾ç½®é˜ˆå€¼ï¼šä½äºæŸå€¼æ—¶è§¦å‘ç»´æŠ¤è­¦å‘Š")
    print("  - å¯ä¸å…¶ä»–æŒ‡æ ‡ç»„åˆä½¿ç”¨ä»¥æé«˜å‡†ç¡®æ€§")

print("\n" + "="*80)
print("åˆ†æå®Œæˆï¼")
print("="*80)

# ç”Ÿæˆç®€æ˜æ¨èå¡ç‰‡
fig, ax = plt.subplots(figsize=(12, 8))
ax.axis('off')

# æ ‡é¢˜
title_text = 'ğŸ† å‰ªåˆ€ç£¨æŸç›‘æ§ - æ¨èæŒ‡æ ‡'
ax.text(0.5, 0.95, title_text, 
       ha='center', va='top', fontsize=24, fontweight='bold',
       bbox=dict(boxstyle='round,pad=1', facecolor='gold', alpha=0.8))

# Top 3 æŒ‡æ ‡å¡ç‰‡
y_positions = [0.75, 0.50, 0.25]
medals = ['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰']
colors = ['#FFD700', '#C0C0C0', '#CD7F32']

for i, (y_pos, medal, color) in enumerate(zip(y_positions, medals, colors)):
    result = results_df.iloc[i]
    
    card_text = (f"{medal} ç¬¬{i+1}å: {result['æŒ‡æ ‡']}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"ç»¼åˆå¾—åˆ†: {result['ç»¼åˆå¾—åˆ†']:.1f}/10\n"
                f"æ—¶é—´ç›¸å…³æ€§: {result['æ—¶é—´ç›¸å…³æ€§']:.3f}\n"
                f"é¦–å°¾å˜åŒ–: {result['é¦–å°¾å˜åŒ–ç‡(%)']:.1f}%\n"
                f"ç‰©ç†æ„ä¹‰: {result['ç‰©ç†æ„ä¹‰']}/10")
    
    ax.text(0.5, y_pos, card_text,
           ha='center', va='top', fontsize=14, family='monospace',
           bbox=dict(boxstyle='round,pad=1.5', facecolor=color, 
                    alpha=0.3, edgecolor=color, linewidth=3))

plt.tight_layout()
plt.savefig('results/visualizations/recommended_indicators.png', 
           dpi=300, bbox_inches='tight')
print("\nå·²ä¿å­˜æ¨èå¡ç‰‡: results/visualizations/recommended_indicators.png")

