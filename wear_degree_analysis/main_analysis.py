#!/usr/bin/env python3
"""
å‰ªåˆ€ç£¨æŸç¨‹åº¦ç»¼åˆåˆ†æç³»ç»Ÿ - é€šç”¨ç‰ˆ
æ•´åˆæ‰€æœ‰åˆ†æåŠŸèƒ½çš„ä¸»è„šæœ¬

æ¨¡å‹ä¿¡æ¯ï¼š
- æ¨¡å‹åç§°: Claude Sonnet 4.5
- æ¨¡å‹ç‰ˆæœ¬: claude-sonnet-4-20250514
- æ›´æ–°æ—¥æœŸ: 2025å¹´5æœˆ14æ—¥

ä½¿ç”¨æ–¹æ³•ï¼š
  python main_analysis.py [é€‰é¡¹]
  
ç¤ºä¾‹ï¼š
  # ä½¿ç”¨é»˜è®¤æ•°æ®ç›®å½•
  python main_analysis.py
  
  # æŒ‡å®šæ•°æ®ç›®å½•å’Œè¾“å‡ºç›®å½•
  python main_analysis.py --data_dir /path/to/data --output_dir /path/to/output
  
  # åªè¿è¡Œç‰¹å®šçš„åˆ†ææ¨¡å—
  python main_analysis.py --modules basic enhanced coil
  
  # è·³è¿‡ç‰¹å¾æå–ï¼Œç›´æ¥ä½¿ç”¨å·²æœ‰ç‰¹å¾æ–‡ä»¶
  python main_analysis.py --skip_extraction --features_csv results/features/wear_features.csv
  
  # æŒ‡å®šé’¢å·å‚æ•°
  python main_analysis.py --n_coils 12 --coil_start_id 1
"""

import os
import sys
import cv2
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
from datetime import datetime
from tqdm import tqdm
from math import pi

# ç§‘å­¦è®¡ç®—åº“
from scipy.signal import find_peaks, savgol_filter
from scipy.ndimage import uniform_filter1d, maximum_filter1d
from scipy.interpolate import UnivariateSpline
from scipy.stats import spearmanr

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False
matplotlib.rcParams['font.size'] = 12

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.preprocessor import ImagePreprocessor
from src.geometry_features import GeometryFeatureExtractor
from src.visualizer import WearVisualizer
from src.utils import ensure_dir, save_json, compute_trend_slope, calculate_statistics


class IntegratedWearAnalyzer:
    """æ•´åˆçš„å‰ªåˆ€ç£¨æŸåˆ†æå™¨ - åŒ…å«æ‰€æœ‰åˆ†æåŠŸèƒ½"""
    
    def __init__(self, data_dir: str, output_dir: str, max_frames: int = None,
                 n_coils: int = 9, coil_start_id: int = 4):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data_dir: æ•°æ®ç›®å½•ï¼ˆåŒ…å«frame_*_roi.pngå›¾åƒï¼‰
            output_dir: è¾“å‡ºç›®å½•
            max_frames: æœ€å¤§å¤„ç†å¸§æ•°ï¼ˆNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰å¸§ï¼‰
            n_coils: é’¢å·æ•°é‡
            coil_start_id: èµ·å§‹é’¢å·ç¼–å·
        """
        self.data_dir = data_dir
        self.output_dir = output_dir
        self.n_coils = n_coils
        self.coil_start_id = coil_start_id
        
        # è‡ªåŠ¨æ£€æµ‹å›¾ç‰‡æ€»æ•°
        if max_frames is None:
            import glob
            image_files = glob.glob(os.path.join(data_dir, 'frame_*_roi.png'))
            self.max_frames = len(image_files)
            if self.max_frames > 0:
                print(f"âœ“ è‡ªåŠ¨æ£€æµ‹åˆ° {self.max_frames} å¸§å›¾åƒ")
            else:
                print(f"âš  è­¦å‘Š: æ•°æ®ç›®å½•æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        else:
            self.max_frames = max_frames
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.features_dir = os.path.join(output_dir, 'results', 'features')
        self.viz_dir = os.path.join(output_dir, 'results', 'visualizations')
        self.diagnosis_dir = os.path.join(self.viz_dir, 'frame_diagnosis')
        
        ensure_dir(self.features_dir)
        ensure_dir(self.viz_dir)
        ensure_dir(self.diagnosis_dir)
        
        # åˆå§‹åŒ–å„æ¨¡å—ï¼ˆåªåœ¨éœ€è¦æ—¶åˆå§‹åŒ–ï¼‰
        self.preprocessor = None
        self.feature_extractor = None
        self.visualizer = None
        
        # æ ¸å¿ƒç‰¹å¾å®šä¹‰
        self.core_features = {
            'avg_rms_roughness': 'å¹³å‡RMSç²—ç³™åº¦',
            'avg_gradient_energy': 'å¹³å‡æ¢¯åº¦èƒ½é‡ï¼ˆé”åº¦ï¼‰',
            'max_notch_depth': 'æœ€å¤§ç¼ºå£æ·±åº¦',
            'left_peak_density': 'å·¦ä¾§å³°å¯†åº¦',
            'right_peak_density': 'å³ä¾§å³°å¯†åº¦',
            'tear_shear_area_ratio': 'æ’•è£‚/å‰ªåˆ‡é¢ç§¯æ¯”'
        }
        
        print(f"âœ“ åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"  - æ•°æ®ç›®å½•: {data_dir}")
        print(f"  - è¾“å‡ºç›®å½•: {output_dir}")
        print(f"  - é’¢å·ä¿¡æ¯: ç¬¬{coil_start_id}-{coil_start_id+n_coils-1}å·ï¼ˆå…±{n_coils}å·ï¼‰")
    
    def _init_processors(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å¤„ç†å™¨"""
        if self.preprocessor is None:
            self.preprocessor = ImagePreprocessor()
            self.feature_extractor = GeometryFeatureExtractor()
            self.visualizer = WearVisualizer(self.viz_dir)
    
    # ============================================================================
    # ç‰¹å¾æå–æ¨¡å—
    # ============================================================================
    
    def extract_features(self) -> pd.DataFrame:
        """æå–æ‰€æœ‰å¸§çš„ç‰¹å¾"""
        self._init_processors()
        
        print(f"\n{'='*80}")
        print(f"æ­¥éª¤ 1/7: ç‰¹å¾æå–")
        print(f"{'='*80}")
        print(f"å¼€å§‹å¤„ç† {self.max_frames} å¸§å›¾åƒ...")
        
        all_features = []
        
        for frame_id in tqdm(range(self.max_frames), desc="æå–ç‰¹å¾"):
            save_diagnosis = (frame_id < 10) or (frame_id % 100 == 0)
            
            try:
                filename = f"frame_{frame_id:06d}_roi.png"
                filepath = os.path.join(self.data_dir, filename)
                
                if not os.path.exists(filepath):
                    continue
                
                image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
                if image is None:
                    continue
                
                preprocessed = self.preprocessor.process(image)
                if not preprocessed['success']:
                    continue
                
                features = self.feature_extractor.extract_features(preprocessed)
                features['frame_id'] = frame_id
                all_features.append(features)
                
                if save_diagnosis:
                    diagnosis_path = os.path.join(
                        self.diagnosis_dir, f"frame_{frame_id:06d}_diagnosis.png"
                    )
                    self.visualizer.visualize_single_frame_diagnosis(
                        image, preprocessed, features, frame_id, diagnosis_path
                    )
                    
            except Exception as e:
                print(f"\nâš  è­¦å‘Š: å¤„ç†å¸§ {frame_id} æ—¶å‡ºé”™: {str(e)}")
        
        if len(all_features) == 0:
            raise RuntimeError("âŒ é”™è¯¯: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•å¸§")
        
        df = pd.DataFrame(all_features)
        print(f"\nâœ“ æˆåŠŸå¤„ç† {len(df)} / {self.max_frames} å¸§")
        
        # ä¿å­˜ç‰¹å¾
        csv_path = os.path.join(self.features_dir, 'wear_features.csv')
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ“ ç‰¹å¾æ•°æ®å·²ä¿å­˜: {csv_path}")
        
        return df
    
    # ============================================================================
    # åŸºç¡€å¯è§†åŒ–æ¨¡å—
    # ============================================================================
    
    def generate_basic_visualizations(self, df: pd.DataFrame):
        """ç”ŸæˆåŸºç¡€å¯è§†åŒ–"""
        self._init_processors()
        
        print(f"\n{'='*80}")
        print(f"æ­¥éª¤ 2/7: åŸºç¡€å¯è§†åŒ–")
        print(f"{'='*80}")
        
        self.visualizer.plot_temporal_trends(
            df, os.path.join(self.viz_dir, 'temporal_trends.png')
        )
        print("âœ“ æ—¶åºè¶‹åŠ¿æ›²çº¿")
        
        self.visualizer.plot_feature_correlations(
            df, os.path.join(self.viz_dir, 'feature_correlations.png')
        )
        print("âœ“ ç‰¹å¾ç›¸å…³æ€§åˆ†æ")
        
        self.visualizer.plot_wear_progression(
            df, os.path.join(self.viz_dir, 'wear_progression.png')
        )
        print("âœ“ ç£¨æŸé€’è¿›ç»¼åˆå›¾")
    
    # ============================================================================
    # å¢å¼ºå¯è§†åŒ–æ¨¡å—ï¼ˆé›†æˆ enhanced_visualization.py çš„åŠŸèƒ½ï¼‰
    # ============================================================================
    
    def generate_enhanced_visualizations(self, df: pd.DataFrame):
        """ç”Ÿæˆå¢å¼ºå¯è§†åŒ–"""
        print(f"\n{'='*80}")
        print(f"æ­¥éª¤ 3/7: å¢å¼ºå¯è§†åŒ–")
        print(f"{'='*80}")
        
        # è°ƒç”¨å¢å¼ºå¯è§†åŒ–è„šæœ¬
        import subprocess
        script_path = os.path.join(os.path.dirname(__file__), 'enhanced_visualization.py')
        if os.path.exists(script_path):
            subprocess.run([sys.executable, script_path], cwd=self.output_dir)
            print("âœ“ å¢å¼ºå¯è§†åŒ–å·²ç”Ÿæˆï¼ˆå³°å€¼è¿çº¿ã€å‘¨æœŸå¯¹æ¯”ã€ç´¯ç§¯ç£¨æŸã€é¦–å°¾å¯¹æ¯”ï¼‰")
        else:
            print("âš  è­¦å‘Š: æœªæ‰¾åˆ° enhanced_visualization.pyï¼Œè·³è¿‡æ­¤æ¨¡å—")
    
    # ============================================================================
    # æ·±åº¦è¶‹åŠ¿åˆ†ææ¨¡å—ï¼ˆé›†æˆ deep_trend_analysis.py çš„åŠŸèƒ½ï¼‰
    # ============================================================================
    
    def generate_deep_trend_analysis(self, df: pd.DataFrame):
        """æ·±åº¦è¶‹åŠ¿åˆ†æ"""
        print(f"\n{'='*80}")
        print(f"æ­¥éª¤ 4/7: æ·±åº¦è¶‹åŠ¿åˆ†æ")
        print(f"{'='*80}")
        
        # è°ƒç”¨æ·±åº¦åˆ†æè„šæœ¬
        import subprocess
        script_path = os.path.join(os.path.dirname(__file__), 'deep_trend_analysis.py')
        if os.path.exists(script_path):
            subprocess.run([sys.executable, script_path], cwd=self.output_dir)
            print("âœ“ æ·±åº¦è¶‹åŠ¿åˆ†æå·²å®Œæˆï¼ˆå³°å€¼åŒ…ç»œã€åˆ†æ®µè¶‹åŠ¿ã€ä½é€šæ»¤æ³¢ï¼‰")
        else:
            print("âš  è­¦å‘Š: æœªæ‰¾åˆ° deep_trend_analysis.pyï¼Œè·³è¿‡æ­¤æ¨¡å—")
    
    # ============================================================================
    # æŒ‰å·åˆ†ææ¨¡å—ï¼ˆé›†æˆ coil_by_coil_analysis.py çš„åŠŸèƒ½ï¼‰
    # ============================================================================
    
    def generate_coil_analysis(self, df: pd.DataFrame):
        """æŒ‰å·åˆ†æ"""
        print(f"\n{'='*80}")
        print(f"æ­¥éª¤ 5/7: æŒ‰å·åˆ†æ")
        print(f"{'='*80}")
        
        # è°ƒç”¨æŒ‰å·åˆ†æè„šæœ¬
        import subprocess
        script_path = os.path.join(os.path.dirname(__file__), 'coil_by_coil_analysis.py')
        if os.path.exists(script_path):
            subprocess.run([sys.executable, script_path], cwd=self.output_dir)
            print("âœ“ æŒ‰å·åˆ†æå·²å®Œæˆï¼ˆç®±çº¿å›¾ã€ç»Ÿè®¡å›¾ã€çƒ­åŠ›å›¾ã€é›·è¾¾å›¾ï¼‰")
        else:
            print("âš  è­¦å‘Š: æœªæ‰¾åˆ° coil_by_coil_analysis.pyï¼Œè·³è¿‡æ­¤æ¨¡å—")
    
    # ============================================================================
    # æœ€ä½³æŒ‡æ ‡è¯„ä¼°æ¨¡å—ï¼ˆé›†æˆ best_indicator_analysis.py çš„åŠŸèƒ½ï¼‰
    # ============================================================================
    
    def generate_best_indicator_analysis(self, df: pd.DataFrame):
        """æœ€ä½³æŒ‡æ ‡è¯„ä¼°"""
        print(f"\n{'='*80}")
        print(f"æ­¥éª¤ 6/7: æœ€ä½³æŒ‡æ ‡è¯„ä¼°")
        print(f"{'='*80}")
        
        # è°ƒç”¨æŒ‡æ ‡è¯„ä¼°è„šæœ¬
        import subprocess
        script_path = os.path.join(os.path.dirname(__file__), 'best_indicator_analysis.py')
        if os.path.exists(script_path):
            subprocess.run([sys.executable, script_path], cwd=self.output_dir)
            print("âœ“ æŒ‡æ ‡è¯„ä¼°å·²å®Œæˆ")
        else:
            print("âš  è­¦å‘Š: æœªæ‰¾åˆ° best_indicator_analysis.pyï¼Œè·³è¿‡æ­¤æ¨¡å—")
    
    # ============================================================================
    # å¹³æ»‘é•¿æœŸè¶‹åŠ¿æ¨¡å—ï¼ˆé›†æˆ smooth_longterm_trend.py çš„åŠŸèƒ½ï¼‰
    # ============================================================================
    
    def generate_smooth_longterm_trend(self, df: pd.DataFrame):
        """å¹³æ»‘é•¿æœŸè¶‹åŠ¿åˆ†æ"""
        print(f"\n{'='*80}")
        print(f"æ­¥éª¤ 7/7: å¹³æ»‘é•¿æœŸè¶‹åŠ¿åˆ†æ")
        print(f"{'='*80}")
        
        # è°ƒç”¨å¹³æ»‘è¶‹åŠ¿è„šæœ¬
        import subprocess
        script_path = os.path.join(os.path.dirname(__file__), 'smooth_longterm_trend.py')
        if os.path.exists(script_path):
            subprocess.run([sys.executable, script_path], cwd=self.output_dir)
            print("âœ“ å¹³æ»‘è¶‹åŠ¿åˆ†æå·²å®Œæˆï¼ˆåŒ…ç»œçº¿ã€å³°å€¼æ‹Ÿåˆã€å…¨å±€å¹³æ»‘ï¼‰")
        else:
            print("âš  è­¦å‘Š: æœªæ‰¾åˆ° smooth_longterm_trend.pyï¼Œè·³è¿‡æ­¤æ¨¡å—")
    
    # ============================================================================
    # æŠ¥å‘Šç”Ÿæˆ
    # ============================================================================
    
    def generate_report(self, df: pd.DataFrame) -> str:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        report = []
        report.append("# å‰ªåˆ€ç£¨æŸç¨‹åº¦ç»¼åˆåˆ†ææŠ¥å‘Š\n\n")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        report.append(f"**åˆ†æå¸§æ•°**: {len(df)}\n\n")
        report.append("---\n\n")
        
        # æ•°æ®æ¦‚è§ˆ
        report.append("## 1. æ•°æ®æ¦‚è§ˆ\n\n")
        report.append(f"- æˆåŠŸå¤„ç†å¸§æ•°: {len(df)} / {self.max_frames}\n")
        report.append(f"- å¸§ç¼–å·èŒƒå›´: {df['frame_id'].min()} - {df['frame_id'].max()}\n")
        report.append(f"- é’¢å·ä¿¡æ¯: ç¬¬{self.coil_start_id}-{self.coil_start_id+self.n_coils-1}å·ï¼ˆå…±{self.n_coils}å·ï¼‰\n\n")
        
        # æ ¸å¿ƒç‰¹å¾ç»Ÿè®¡
        report.append("## 2. æ ¸å¿ƒç‰¹å¾ç»Ÿè®¡\n\n")
        for feature_name, feature_label in self.core_features.items():
            if feature_name in df.columns:
                values = df[feature_name].values
                stats = calculate_statistics(values)
                trend_slope = compute_trend_slope(values)
                
                report.append(f"### {feature_label}\n\n")
                report.append(f"| æŒ‡æ ‡ | å€¼ |\n")
                report.append(f"|------|----|\n")
                report.append(f"| å‡å€¼ | {stats['mean']:.6f} |\n")
                report.append(f"| æ ‡å‡†å·® | {stats['std']:.6f} |\n")
                report.append(f"| æœ€å°å€¼ | {stats['min']:.6f} |\n")
                report.append(f"| æœ€å¤§å€¼ | {stats['max']:.6f} |\n")
                report.append(f"| ä¸­ä½æ•° | {stats['median']:.6f} |\n")
                report.append(f"| è¶‹åŠ¿æ–œç‡ | {trend_slope:.8f} |\n\n")
                
                if trend_slope > 1e-6:
                    report.append(f"âœ… **è¶‹åŠ¿**: é€’å¢ï¼ˆç¬¦åˆç£¨æŸé¢„æœŸï¼‰\n\n")
                elif trend_slope < -1e-6:
                    report.append(f"âš ï¸ **è¶‹åŠ¿**: é€’å‡\n\n")
                else:
                    report.append(f"â¡ï¸ **è¶‹åŠ¿**: å¹³ç¨³\n\n")
        
        # ç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶
        report.append("## 3. ç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶\n\n")
        report.append("### åŸºç¡€å¯è§†åŒ–\n")
        report.append("- `temporal_trends.png` - æ—¶åºè¶‹åŠ¿æ›²çº¿\n")
        report.append("- `feature_correlations.png` - ç‰¹å¾ç›¸å…³æ€§åˆ†æ\n")
        report.append("- `wear_progression.png` - ç£¨æŸé€’è¿›ç»¼åˆå›¾\n\n")
        
        report.append("### å¢å¼ºå¯è§†åŒ–\n")
        report.append("- `peaks_trend.png` - å³°å€¼è¿çº¿å›¾\n")
        report.append("- `cycle_comparison.png` - å‘¨æœŸèµ·ç»ˆç‚¹å¯¹æ¯”\n")
        report.append("- `cumulative_wear.png` - ç´¯ç§¯ç£¨æŸæŒ‡æ•°\n")
        report.append("- `first_last_comparison.png` - é¦–å°¾å¯¹æ¯”å›¾\n\n")
        
        report.append("### æ·±åº¦åˆ†æ\n")
        report.append("- `envelope_analysis.png` - å³°å€¼åŒ…ç»œçº¿åˆ†æ\n")
        report.append("- `segment_analysis.png` - åˆ†æ®µè¶‹åŠ¿åˆ†æ\n")
        report.append("- `longterm_trend.png` - ä½é€šæ»¤æ³¢é•¿æœŸè¶‹åŠ¿\n\n")
        
        report.append("### æŒ‰å·åˆ†æ\n")
        report.append("- `coil_by_coil_boxplot.png` - ç®±çº¿å›¾å¯¹æ¯”\n")
        report.append("- `coil_by_coil_bars.png` - ç»Ÿè®¡æŸ±çŠ¶å›¾\n")
        report.append("- `coil_heatmap.png` - ç‰¹å¾çƒ­åŠ›å›¾\n")
        report.append("- `coil_progression_detailed.png` - é€å·é€’è¿›è¶‹åŠ¿\n")
        report.append("- `coil_radar_comparison.png` - é›·è¾¾å›¾å¯¹æ¯”\n\n")
        
        report.append("### æŒ‡æ ‡è¯„ä¼°\n")
        report.append("- `best_indicators_comparison.png` - æœ€ä½³æŒ‡æ ‡å¯¹æ¯”\n")
        report.append("- `recommended_indicators.png` - æ¨èæŒ‡æ ‡å¡ç‰‡\n\n")
        
        report.append("### å¹³æ»‘è¶‹åŠ¿\n")
        report.append("- `smooth_method1_envelope.png` - ç§»åŠ¨æœ€å¤§å€¼åŒ…ç»œ\n")
        report.append("- `smooth_method2_peaks.png` - å‘¨æœŸå³°å€¼æ‹Ÿåˆ\n")
        report.append("- `smooth_method3_global.png` - å…¨å±€äºŒæ¬¡å¹³æ»‘\n")
        report.append("- `smooth_comparison_final.png` - æ–¹æ³•å¯¹æ¯”\n\n")
        
        report.append("---\n\n")
        report.append("*æœ¬æŠ¥å‘Šç”±å‰ªåˆ€ç£¨æŸç»¼åˆåˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*\n")
        
        return ''.join(report)
    
    def save_report(self, report_content: str):
        """ä¿å­˜æŠ¥å‘Š"""
        report_path = os.path.join(self.output_dir, 'results', 'analysis_report.md')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        print(f"\nâœ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    # ============================================================================
    # ä¸»æµç¨‹
    # ============================================================================
    
    def run(self, skip_extraction=False, features_csv=None, modules=None):
        """
        è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
        
        Args:
            skip_extraction: æ˜¯å¦è·³è¿‡ç‰¹å¾æå–
            features_csv: å·²æœ‰ç‰¹å¾æ–‡ä»¶è·¯å¾„
            modules: è¦è¿è¡Œçš„æ¨¡å—åˆ—è¡¨
        """
        print("\n" + "="*80)
        print("å‰ªåˆ€ç£¨æŸç¨‹åº¦ç»¼åˆåˆ†æç³»ç»Ÿ")
        print("="*80)
        
        if modules is None:
            modules = ['all']
        
        if 'all' in modules:
            modules = ['basic', 'enhanced', 'deep', 'coil', 'indicator', 'smooth']
        
        try:
            # 1. ç‰¹å¾æå–æˆ–åŠ è½½
            if skip_extraction and features_csv:
                print(f"\nè·³è¿‡ç‰¹å¾æå–ï¼ŒåŠ è½½ç‰¹å¾æ–‡ä»¶: {features_csv}")
                df = pd.read_csv(features_csv)
                print(f"âœ“ åŠ è½½äº† {len(df)} å¸§çš„ç‰¹å¾æ•°æ®")
            else:
                df = self.extract_features()
            
            # 2. è¿è¡Œå„ä¸ªåˆ†ææ¨¡å—
            if 'basic' in modules:
                self.generate_basic_visualizations(df)
            
            if 'enhanced' in modules:
                self.generate_enhanced_visualizations(df)
            
            if 'deep' in modules:
                self.generate_deep_trend_analysis(df)
            
            if 'coil' in modules:
                self.generate_coil_analysis(df)
            
            if 'indicator' in modules:
                self.generate_best_indicator_analysis(df)
            
            if 'smooth' in modules:
                self.generate_smooth_longterm_trend(df)
            
            # 3. ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report(df)
            self.save_report(report)
            
            print("\n" + "="*80)
            print("âœ… åˆ†æå®Œæˆï¼")
            print("="*80)
            print(f"\nğŸ“ ç»“æœä¿å­˜ç›®å½•: {os.path.join(self.output_dir, 'results')}")
            print(f"  - ç‰¹å¾æ•°æ®: {os.path.join(self.output_dir, 'results/features')}")
            print(f"  - å¯è§†åŒ–å›¾è¡¨: {os.path.join(self.output_dir, 'results/visualizations')}")
            print(f"  - åˆ†ææŠ¥å‘Š: {os.path.join(self.output_dir, 'results/analysis_report.md')}")
            
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å‰ªåˆ€ç£¨æŸç¨‹åº¦ç»¼åˆåˆ†æç³»ç»Ÿ - é€šç”¨ç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤è®¾ç½®å¤„ç†æ•°æ®
  python main_analysis.py
  
  # æŒ‡å®šæ•°æ®ç›®å½•å’Œè¾“å‡ºç›®å½•
  python main_analysis.py --data_dir /path/to/roi_imgs --output_dir /path/to/output
  
  # åªè¿è¡Œç‰¹å®šçš„åˆ†ææ¨¡å—
  python main_analysis.py --modules basic enhanced coil
  
  # è·³è¿‡ç‰¹å¾æå–ï¼Œä½¿ç”¨å·²æœ‰ç‰¹å¾æ–‡ä»¶
  python main_analysis.py --skip_extraction --features_csv results/features/wear_features.csv
  
  # è‡ªå®šä¹‰é’¢å·å‚æ•°
  python main_analysis.py --n_coils 12 --coil_start_id 1
        """
    )
    
    parser.add_argument('--data_dir', type=str, default=None,
                       help='æ•°æ®ç›®å½•ï¼ˆåŒ…å«frame_*_roi.pngå›¾åƒï¼‰ï¼Œé»˜è®¤: ../data/roi_imgs')
    parser.add_argument('--output_dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤: å½“å‰ç›®å½•')
    parser.add_argument('--max_frames', type=int, default=None,
                       help='æœ€å¤§å¤„ç†å¸§æ•°ï¼ˆé»˜è®¤å¤„ç†æ‰€æœ‰å¸§ï¼‰')
    parser.add_argument('--n_coils', type=int, default=9,
                       help='é’¢å·æ•°é‡ï¼ˆé»˜è®¤9ï¼‰')
    parser.add_argument('--coil_start_id', type=int, default=4,
                       help='èµ·å§‹é’¢å·ç¼–å·ï¼ˆé»˜è®¤4ï¼‰')
    parser.add_argument('--skip_extraction', action='store_true',
                       help='è·³è¿‡ç‰¹å¾æå–ï¼Œä½¿ç”¨å·²æœ‰ç‰¹å¾æ–‡ä»¶')
    parser.add_argument('--features_csv', type=str, default=None,
                       help='å·²æœ‰ç‰¹å¾CSVæ–‡ä»¶è·¯å¾„ï¼ˆé…åˆ--skip_extractionä½¿ç”¨ï¼‰')
    parser.add_argument('--modules', nargs='+',
                       choices=['basic', 'enhanced', 'deep', 'coil', 'indicator', 'smooth', 'all'],
                       default=['all'],
                       help='è¦è¿è¡Œçš„åˆ†ææ¨¡å—ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰')
    
    args = parser.parse_args()
    
    # é…ç½®è·¯å¾„
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    if args.data_dir is None:
        data_dir = os.path.join(os.path.dirname(base_dir), 'data', 'roi_imgs')
    else:
        data_dir = args.data_dir
    
    if args.output_dir is None:
        output_dir = base_dir
    else:
        output_dir = args.output_dir
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not args.skip_extraction and not os.path.exists(data_dir):
        print(f"âŒ é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print(f"\næç¤º: è¯·ä½¿ç”¨ --data_dir å‚æ•°æŒ‡å®šæ­£ç¡®çš„æ•°æ®ç›®å½•")
        return
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = IntegratedWearAnalyzer(
        data_dir=data_dir,
        output_dir=output_dir,
        max_frames=args.max_frames,
        n_coils=args.n_coils,
        coil_start_id=args.coil_start_id
    )
    
    analyzer.run(
        skip_extraction=args.skip_extraction,
        features_csv=args.features_csv,
        modules=args.modules
    )


if __name__ == '__main__':
    main()

